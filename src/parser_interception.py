"""
parser_interception.py ‚Äî –ü–∞—Ä—Å–µ—Ä –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç —á–µ—Ä–µ–∑ Network Interception

–ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç API –∑–∞–ø—Ä–æ—Å—ã –≤–æ –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON –æ—Ç–≤–µ—Ç–æ–≤.
–≠—Ç–æ –≤ 10x –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º –ø–∞—Ä—Å–∏–Ω–≥ HTML —á–µ—Ä–µ–∑ Playwright.
"""

from playwright.sync_api import TimeoutError as PlaywrightTimeoutError
import json
import re
import time
import random
from typing import Dict, Any, List, Optional
from urllib.parse import urlparse, parse_qs
import os
from datetime import datetime

from browser_session import BrowserSession, BrowserSessionManager

DEBUG_DIR = os.getenv("DEBUG_DIR", "/app/debug_data")

# –¢–æ–ª—å–∫–æ –∫–ª—é—á–∏, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã–µ –≤ manager.open_session (parser_interception) –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤–æ—Ä–∫–µ—Ä–æ–º.
ALLOWED_SESSION_KWARGS = {
    "headless",
    "cookies",
    "user_agent",
    "viewport",
    "locale",
    "timezone_id",
    "proxy",
    "launch_args",
    "init_scripts",
    "geolocation",
}

def _find_paths(obj: Any, target_keys: List[str], max_depth: int = 6, max_preview_len: int = 120,
                max_results_per_key: int = 20) -> Dict[str, List[Dict[str, str]]]:
    """
    Dev-only —É—Ç–∏–ª–∏—Ç–∞: –Ω–∞–π—Ç–∏ –ø—É—Ç–∏ –∫ –∫–ª—é—á–∞–º target_keys –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–º JSON (dict/list).

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å:
      { key: [ { "path": "payload.company.rubrics[0].name", "preview": "..." }, ... ] }
    """
    targets = set(target_keys)
    results: Dict[str, List[Dict[str, str]]] = {k: [] for k in targets}

    def _add_result(key: str, path: str, value: Any) -> None:
        bucket = results.setdefault(key, [])
        if len(bucket) >= max_results_per_key:
            return
        try:
            if isinstance(value, (dict, list)):
                preview = json.dumps(value, ensure_ascii=False)
            else:
                preview = str(value)
        except Exception:
            preview = repr(value)
        if len(preview) > max_preview_len:
            preview = preview[:max_preview_len] + "‚Ä¶"
        bucket.append({"path": path, "preview": preview})

    def _walk(node: Any, path: str, depth: int) -> None:
        if depth > max_depth:
            return
        if isinstance(node, dict):
            for k, v in node.items():
                new_path = f"{path}.{k}" if path else k
                if k in targets:
                    _add_result(k, new_path, v)
                _walk(v, new_path, depth + 1)
        elif isinstance(node, list):
            for idx, item in enumerate(node):
                new_path = f"{path}[{idx}]" if path else f"[{idx}]"
                _walk(item, new_path, depth + 1)

    _walk(obj, "", 0)
    return {k: v for k, v in results.items() if v}


def _pick_first(d: Any, paths: List[List[str]]) -> Any:
    """
    –î–æ—Å—Ç–∞—Ç—å –ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ –ø—É—Ç–µ–π.
    paths: [["data", "items", "0", "title"], ["data", "name"], ...]
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–ø–∏—Å–∫–æ–≤ ("0", "1").
    """
    for p in paths:
        cur = d
        ok = True
        for k in p:
            if isinstance(cur, list) and k.isdigit():
                idx = int(k)
                if idx < 0 or idx >= len(cur):
                    ok = False
                    break
                cur = cur[idx]
            elif isinstance(cur, dict) and k in cur:
                cur = cur[k]
            else:
                ok = False
                break
        if ok and cur is not None and cur != "":
            return cur
    return None


def _is_empty(val: Any) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–¥–ª—è merge_non_empty)."""
    if val is None:
        return True
    if isinstance(val, str):
        return not val.strip()
    if isinstance(val, (list, dict)):
        return len(val) == 0
    return False


def _is_non_empty(val: Any) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (truthy –¥–ª—è —Å–∫–∞–ª—è—Ä–æ–≤, len>0 –¥–ª—è list/dict)."""
    if val is None:
        return False
    if isinstance(val, str):
        return bool(val.strip())
    if isinstance(val, (list, dict)):
        return len(val) > 0
    return bool(val)


# --- Identity fields & source priority (Part A) ---
IDENTITY_FIELDS = frozenset({"title", "title_or_name", "address", "categories", "rating", "reviews_count"})
IDENTITY_SAFE_SOURCES = frozenset({"search_api", "org_api", "html_fallback"})
# –ù–∞ org_page: location-info —Ä–∞–∑—Ä–µ—à—ë–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è safe-–ø–æ–ª–µ–π
LOCATION_INFO_SAFE_FIELDS = frozenset({"hours", "hours_full", "phone", "site", "url", "coordinates", "ll", "social_links"})


def _is_identity_safe(source: str, org_page: bool) -> bool:
    """
    –ù–∞ org_page: True —Ç–æ–ª—å–∫–æ –¥–ª—è search_api, org_api, html_fallback.
    –ù–∞ non-org: location_info —Ä–∞–∑—Ä–µ—à—ë–Ω.
    """
    if not org_page:
        return True
    return source in IDENTITY_SAFE_SOURCES


def merge_non_empty(
    dst: Dict[str, Any],
    src: Dict[str, Any],
    meta_src: Optional[Dict[str, str]] = None,
    *,
    source: Optional[str] = None,
    org_page: bool = False,
    forbidden_fields: Optional[set] = None,
) -> None:
    """
    –ú–µ—Ä–¥–∂–∏—Ç src –≤ dst –±–µ–∑ –∑–∞—Ç–∏—Ä–∞–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–ª–µ–π –ø—É—Å—Ç—ã–º–∏.
    - –°–∫–∞–ª—è—Ä—ã: –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ src_val truthy –∏ dst –ø—É—Å—Ç–æ.
    - –°–ø–∏—Å–∫–∏: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ len > 0 –∏ dst –ø—É—Å—Ç–æ.
    - Dict: —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ –∫–ª—é—á–∞–º, –Ω–µ –∑–∞—Ç–∏—Ä–∞—Ç—å –Ω–µ–ø—É—Å—Ç–æ–µ –ø—É—Å—Ç—ã–º.
    meta_src: {field: source} ‚Äî –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ–ª—è –∑–∞–ø–∏—Å–∞—Ç—å meta[field+"_source"]=source.
    """
    if not isinstance(src, dict):
        return
    meta = dst.get("meta")
    if not isinstance(meta, dict):
        meta = {}
        dst["meta"] = meta

    blocked = forbidden_fields or set()
    if source and org_page and not _is_identity_safe(source, org_page):
        blocked = blocked | IDENTITY_FIELDS

    for k, v in src.items():
        if k in ("meta", "_search_debug"):
            continue
        if k in blocked:
            continue
        if not _is_non_empty(v):
            continue
        current = dst.get(k)
        if isinstance(v, dict) and not isinstance(v, list):
            if not isinstance(current, dict):
                dst[k] = dict(v)
            else:
                merge_non_empty(current, v, meta_src)
        elif isinstance(v, list):
            if len(v) > 0 and _is_empty(current):
                dst[k] = v
                if meta_src and k in meta_src:
                    meta[k + "_source"] = meta_src[k]
        else:
            if _is_empty(current):
                dst[k] = v
                if meta_src and k in meta_src:
                    meta[k + "_source"] = meta_src[k]


def _normalize_title_fields(payload: Dict[str, Any]) -> None:
    """
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ title_or_name –∏ title, –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫.
    –í—ã–∑—ã–≤–∞—Ç—å –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º payload –ø–µ—Ä–µ–¥ return.
    """
    t = (
        payload.get("title_or_name")
        or payload.get("title")
        or payload.get("name")
        or payload.get("page_title_short")
        or payload.get("og_title")
    )
    if t and isinstance(t, str) and t.strip():
        payload.setdefault("title_or_name", t)
        payload.setdefault("title", t)
        ov = payload.get("overview")
        if isinstance(ov, dict):
            ov.setdefault("title", t)


def _set_if_empty(result: Dict[str, Any], key: str, value: Any) -> None:
    """
    –ü–æ—Å—Ç–∞–≤–∏—Ç—å result[key] —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–∞–º —Å–µ–π—á–∞—Å "–ø—É—Å—Ç–æ" –∏ value –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ.
    –ü—É—Å—Ç–æ: None, '', [], {}.
    """
    if value is None:
        return
    if isinstance(value, str) and not value.strip():
        return

    current = result.get(key)
    if current is None or current == "" or current == [] or current == {}:
        result[key] = value


def _extend_unique(result: Dict[str, Any], key: str, items: List[Any]) -> None:
    """
    –î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–æ–∫ result[key] –±–µ–∑ –¥—É–±–ª–µ–π, –Ω–µ –∑–∞—Ç–∏—Ä–∞—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ.
    """
    if not items:
        return

    # –î–ª—è categories —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–∏–º–µ–Ω/–º–µ—Ç–æ–∫), –±–µ–∑ dict –∏ –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤.
    if key == "categories":
        def _cat_str_from_item(it: Any) -> Optional[str]:
            if isinstance(it, str):
                s = it.strip()
                return s or None
            if isinstance(it, dict):
                for k in ("name", "label", "text", "title"):
                    v = it.get(k)
                    if isinstance(v, str) and v.strip():
                        return v.strip()
            return None

        existing_raw = result.get(key)
        existing_list: List[str] = []
        if isinstance(existing_raw, list):
            for it in existing_raw:
                s = _cat_str_from_item(it)
                if s and s not in existing_list:
                    existing_list.append(s)
        elif isinstance(existing_raw, str) and existing_raw.strip():
            existing_list = [existing_raw.strip()]

        seen = set(existing_list)
        for item in items:
            s = _cat_str_from_item(item)
            if not s or s in seen:
                continue
            existing_list.append(s)
            seen.add(s)

        result[key] = existing_list
        return

    # –û–±—â–∏–π —Å–ª—É—á–∞–π: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∏–ø—ã –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ –∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–µ–π –ø–æ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é.
    existing = result.get(key)
    if existing is None:
        existing_list: List[Any] = []
    elif isinstance(existing, list):
        existing_list = existing
    else:
        existing_list = [existing]

    seen = {str(x) for x in existing_list}
    for item in items:
        s = str(item)
        if s in seen:
            continue
        existing_list.append(item)
        seen.add(s)

    result[key] = existing_list


def _get_nested(obj: Any, path: str) -> Any:
    """
    –î–æ—Å—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—É—Ç–∏ –≤–∏–¥–∞ "payload.company.rubrics[0].name"
    —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω–¥–µ–∫—Å–æ–≤ [0].
    """
    if not path:
        return obj

    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ç–æ—á–∫–∞–º, –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏–Ω–¥–µ–∫—Å—ã [0]
    for part in path.split("."):
        if not part:
            continue
        # –í—ã–¥–µ–ª—è–µ–º –∫–ª—é—á –∏ –∏–Ω–¥–µ–∫—Å—ã.
        # –ü—Ä–∏–º–µ—Ä part: "rubrics[0][1]"
        i = 0
        key = ""
        # –°–æ–±–∏—Ä–∞–µ–º –±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—É—é —á–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–π —Å–∫–æ–±–∫–∏
        while i < len(part) and part[i] != "[":
            key += part[i]
            i += 1

        if key:
            if not isinstance(obj, dict):
                return None
            obj = obj.get(key)
            if obj is None:
                return None

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤–∏–¥–∞ [0]
        while i < len(part):
            if part[i] != "[":
                return None
            j = part.find("]", i)
            if j == -1:
                return None
            index_str = part[i + 1 : j]
            try:
                idx = int(index_str)
            except ValueError:
                return None
            if not isinstance(obj, list) or idx < 0 or idx >= len(obj):
                return None
            obj = obj[idx]
            i = j + 1

    return obj


class YandexMapsInterceptionParser:
    """–ü–∞—Ä—Å–µ—Ä –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç —á–µ—Ä–µ–∑ –ø–µ—Ä–µ—Ö–≤–∞—Ç —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, debug_bundle_id: Optional[str] = None):
        self.api_responses: Dict[str, Any] = {}
        self.api_responses_list: List[tuple] = []  # [(url, json_data), ...] ‚Äî –∂—É—Ä–Ω–∞–ª –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏
        self.location_info_payload: Optional[Dict[str, Any]] = None  # –ª—É—á—à–∏–π org-bound (backward compat)
        self.location_info_candidates: List[tuple] = []  # [(json_data, timestamp), ...] org-bound
        self.reviews_pages: List[Dict[str, Any]] = []
        self.products_pages: List[Dict[str, Any]] = []
        self.search_api_payload: Optional[Dict[str, Any]] = None  # search?business_oid=...
        self._search_api_debug: Optional[Dict[str, Any]] = None  # –¥–ª—è selected_item_debug.json
        self._search_api_contributed_identity: bool = False  # True –µ—Å–ª–∏ search_api –¥–∞–ª title/address/categories
        self.org_id: Optional[str] = None
        self.debug_bundle_id: Optional[str] = debug_bundle_id
        self._identity_debug: Dict[str, Any] = {}  # blocked_candidates, identity, warnings
        _base = os.getenv("DEBUG_DIR", "/app/debug_data")
        self.debug_bundle_dir: Optional[str] = os.path.join(_base, debug_bundle_id) if debug_bundle_id else None
        self._debug_raw_services_count: int = 0
        
    def extract_org_id(self, url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å org_id –∏–∑ URL –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç
        
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã:
        - /org/123456/ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
        - /org/slug/123456/ (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å slug)
        """
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: /org/slug/123456/
        match = re.search(r'/org/[^/]+/(\d+)', url)
        if match:
            return match.group(1)
        
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: /org/123456/
        match = re.search(r'/org/(\d+)', url)
        return match.group(1) if match else None

    @property
    def org_page(self) -> bool:
        """True –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–º org-—Å—Ç—Ä–∞–Ω–∏—Ü—É (/maps/org/... + org_id)."""
        return bool(self.org_id)

    def _extract_business_id_from_url(self, url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å businessId/orgId/oid –∏–∑ URL (query –∏–ª–∏ path)."""
        if not url:
            return None
        parsed = urlparse(url)
        qs = parse_qs(parsed.query)
        for param in ("businessId", "orgId", "business_oid", "oid"):
            vals = qs.get(param, [])
            if vals and vals[0]:
                return str(vals[0]).strip()
        m = re.search(r"business_oid[=:](\d+)", url, re.I)
        if m:
            return m.group(1)
        m = re.search(r"/org/[^/]+/(\d+)", url)
        if m:
            return m.group(1)
        return None

    def _extract_ll_z_from_url(self, url: str) -> tuple:
        """–ò–∑–≤–ª–µ—á—å ll –∏ z –∏–∑ URL –∫–∞—Ä—Ç—ã. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ll, z) –∏–ª–∏ (None, None)."""
        if not url:
            return (None, None)
        try:
            parsed = urlparse(url)
            qs = parse_qs(parsed.query)
            ll = qs.get("ll", [None])[0]
            z = qs.get("z", [None])[0]
            return (ll, z)
        except Exception:
            return (None, None)

    def _build_overview_url(self, base_url: str, ll: Optional[str] = None, z: Optional[str] = None) -> str:
        """–°–æ–±—Ä–∞—Ç—å URL overview –∫–∞—Ä—Ç–æ—á–∫–∏ —Å ll –∏ z."""
        # –£–±–∏—Ä–∞–µ–º /prices/ –∏–∑ URL, –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ path –±–µ–∑ query
        full = re.sub(r"/prices/?", "/", base_url)
        parsed = urlparse(full)
        path = (parsed.path or "").rstrip("/")
        if not path.endswith("/"):
            path += "/"
        base = f"{parsed.scheme or 'https'}://{parsed.netloc or 'yandex.ru'}{path}"
        if ll and z:
            return f"{base}?ll={ll}&z={z}"
        return base

    def _is_location_info_org_bound(self, json_data: Any, request_url: str = "") -> bool:
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–∏–≤—è–∑–∞–Ω –ª–∏ –æ—Ç–≤–µ—Ç location-info –∫ –Ω–∞—à–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (org_id).
        org-bound –µ—Å–ª–∏: —Å–∫–∞–ª—è—Ä == org_id; —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç oid=<org_id>; –ø—É—Ç—å /org/.../<org_id>.
        –õ–∏–º–∏—Ç—ã: depth 20, nodes 50000. –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∫ —Ç–∏–ø–∞–º.
        """
        if not self.org_id or not json_data:
            return False
        target = str(self.org_id)
        oid_pattern = re.compile(r"oid=(\d+)", re.I)
        path_oid_pattern = re.compile(r"/org/[^/]*/" + re.escape(target) + r"(?:/|$)", re.I)

        def _scalar_matches(val: Any) -> bool:
            if val is None:
                return False
            if isinstance(val, (int, float)):
                return str(int(val)) == target
            if isinstance(val, str):
                if val.strip() == target:
                    return True
                m = oid_pattern.search(val)
                if m and m.group(1) == target:
                    return True
                if path_oid_pattern.search(val) or val.endswith("/" + target) or val.endswith("/" + target + "/"):
                    return True
            return False

        def _contains_oid(node: Any, depth: int, nodes_left: List[int]) -> bool:
            nodes_left[0] -= 1
            if nodes_left[0] <= 0 or depth > 20:
                return False
            try:
                if isinstance(node, dict):
                    for k, v in node.items():
                        if _scalar_matches(v):
                            return True
                        if _contains_oid(v, depth + 1, nodes_left):
                            return True
                elif isinstance(node, list):
                    for item in node:
                        if _scalar_matches(item):
                            return True
                        if _contains_oid(item, depth + 1, nodes_left):
                            return True
                else:
                    return _scalar_matches(node)
            except (TypeError, RecursionError, KeyError):
                pass
            return False

        return _contains_oid(json_data, 0, [50000])

    def _extract_org_object_from_location_info(self, json_data: Any) -> Optional[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—ä–µ–∫—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ location-info –ø–æ org_id.
        –ò—â–µ—Ç –≤ items/showcase/features/results ‚Äî –æ–±—ä–µ–∫—Ç —Å id/oid == org_id –∏–ª–∏ uri —Å–æ–¥–µ—Ä–∂–∏—Ç oid=<org_id>.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –æ–±—ä–µ–∫—Ç –∏–ª–∏ None.
        """
        if not self.org_id or not json_data:
            return None
        target = str(self.org_id)

        def _obj_matches(obj: Any) -> bool:
            if not isinstance(obj, dict):
                return False
            oid = obj.get("id") or obj.get("oid") or obj.get("businessOid")
            if oid is not None and str(oid) == target:
                return True
            uri = obj.get("uri") or ""
            if isinstance(uri, str):
                m = re.search(r"oid=(\d+)", uri, re.I)
                if m and m.group(1) == target:
                    return True
            return False

        def _find_in_list(items: List[Any]) -> Optional[Dict[str, Any]]:
            for it in items:
                if _obj_matches(it):
                    return it
                if isinstance(it, dict):
                    for key in ("items", "showcase", "features", "results", "children"):
                        sub = it.get(key)
                        if isinstance(sub, list):
                            found = _find_in_list(sub)
                            if found:
                                return found
            return None

        def _walk(node: Any, depth: int) -> Optional[Dict[str, Any]]:
            if depth > 12:
                return None
            if isinstance(node, list):
                return _find_in_list(node)
            if isinstance(node, dict):
                if _obj_matches(node):
                    return node
                for key in ("data", "items", "showcase", "features", "results", "toponymSearchResult"):
                    sub = node.get(key)
                    if sub is not None:
                        found = _find_in_list(sub) if isinstance(sub, list) else (_walk(sub, depth + 1) if isinstance(sub, dict) else None)
                        if found:
                            return found
            return None

        try:
            return _walk(json_data, 0)
        except (TypeError, RecursionError, KeyError):
            return None

    def _score_location_info_payload(self, data: Any) -> int:
        """–û—Ü–µ–Ω–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ core-–ø–æ–ª–µ–π. +1 –∑–∞ –∫–∞–∂–¥–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –ø–æ–ª–µ."""
        if not isinstance(data, dict):
            return 0
        core_keys = ("phone", "site", "hours", "hours_full", "rating", "description")
        score = 0
        for k in core_keys:
            v = data.get(k)
            if v is None:
                continue
            if isinstance(v, str) and v.strip():
                score += 1
            elif isinstance(v, (list, dict)) and len(v) > 0:
                score += 1
            elif not isinstance(v, (str, list, dict)) and v:
                score += 1
        return score

    def parse_yandex_card(self, url: str, session: BrowserSession) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏—Ç –ø—É–±–ª–∏—á–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç —á–µ—Ä–µ–∑ Network Interception.
        
        Args:
            url: URL –∫–∞—Ä—Ç–æ—á–∫–∏ –±–∏–∑–Ω–µ—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, https://yandex.ru/maps/org/123456/)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ parser.py
        """
        print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Network Interception: {url}")
        print("DEBUG: VERSION 2026-01-29 REDIRECT FIX + TIMEOUTS")
        
        if not url or not url.startswith(('http://', 'https://')):
            raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞: {url}")
        
        self.org_id = self.extract_org_id(url)
        if not self.org_id:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å org_id –∏–∑ URL: {url}")

        # org-centric: llz_anchor —Ñ–∏–∫—Å–∏—Ä—É–µ–º –û–î–ò–ù –†–ê–ó –∏–∑ request URL, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º
        self._llz_anchor = self._extract_ll_z_from_url(url)
        self._overview_url_canonical = self._build_overview_url(url, self._llz_anchor[0], self._llz_anchor[1])
        if self._llz_anchor[0] and self._llz_anchor[1]:
            print(f"üìç llz_anchor: ll={self._llz_anchor[0]}, z={self._llz_anchor[1]} (–∏–∑ request URL)")
        print(f"üìã –ò–∑–≤–ª–µ—á–µ–Ω org_id: {self.org_id}")

        def _is_world_view(page_url: str) -> bool:
            """z<=3 = world-view, area-based location-info –±–µ—Å–ø–æ–ª–µ–∑–µ–Ω."""
            ll, z = self._extract_ll_z_from_url(page_url)
            if z is None:
                return False
            try:
                return int(z) <= 3
            except (ValueError, TypeError):
                return False

        def _is_captcha_page(title: str) -> bool:
            """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ø—á–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ, —Ä—É—Å/–∞–Ω–≥–ª)."""
            t = (title or "").lower()
            return (
                "–æ–π!" in t or "captcha" in t or "robot" in t
                or "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ, —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç" in t
                or "are you not a robot" in t
                or "confirm that you" in t
                or "–∑–∞–ø—Ä–æ—Å—ã –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –≤—ã" in t
            )

        def _is_captcha_url(page_url: str) -> bool:
            u = (page_url or "").lower()
            return "showcaptcha" in u or "/captcha" in u

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º bundle-–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ (–µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ __init__)
        if not self.debug_bundle_id:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.debug_bundle_id = f"yandex_{self.org_id}_{ts}"
        if not self.debug_bundle_dir:
            self.debug_bundle_dir = os.path.join(os.getenv("DEBUG_DIR", "/app/debug_data"), self.debug_bundle_id)
        try:
            if self.debug_bundle_dir:
                os.makedirs(self.debug_bundle_dir, exist_ok=True)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å debug bundle dir {self.debug_bundle_dir}: {e}")
        else:
            if self.debug_bundle_dir:
                print(f"[DEBUG_BUNDLE] {self.debug_bundle_dir}")

        context = session.context
        page = session.page

        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è debug bundle
        initial_url = url
        main_http_status: Optional[int] = None

        # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã
        self.api_responses = {}
        self.api_responses_list = []
        self.location_info_payload = None
        self.location_info_candidates = []
        self.reviews_pages = []
        self.products_pages = []
        self.search_api_payload = None
        self._search_api_debug = None
        self._search_api_contributed_identity = False
        self._identity_debug = {}
        self._search_api_contributed_identity = False
        self._identity_debug = {}

        # –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –æ—Ç–≤–µ—Ç—ã
        def handle_response(response):
            """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
            try:
                url = response.url

                # –ò—â–µ–º API –∑–∞–ø—Ä–æ—Å—ã –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç (yandex.com –ø—Ä–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–µ —Ä–µ–≥–∏–æ–Ω–∞!)
                if any(h in url for h in ("yandex.ru", "yandex.net", "yandex.com")):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ JSON –æ—Ç–≤–µ—Ç?
                    content_type = response.headers.get("content-type", "")
                    if "application/json" in content_type or "json" in url.lower() or "ajax=1" in url:
                        try:
                            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å JSON
                            json_data = response.json()

                            # DEBUG: Save to file for inspection (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ bundle)
                            if self.debug_bundle_dir:
                                try:
                                    os.makedirs(self.debug_bundle_dir, exist_ok=True)
                                    clean_url = url.split("?")[0].replace("/", "_").replace(":", "")[-50:]
                                    timestamp = int(time.time() * 1000)
                                    filename = f"{timestamp}_{clean_url}.json"
                                    filepath = os.path.join(self.debug_bundle_dir, filename)
                                    with open(filepath, "w", encoding="utf-8") as f:
                                        json.dump(json_data, f, ensure_ascii=False, indent=2)
                                except Exception as e:
                                    print(f"Failed to save debug json: {e}")

                            # Check for organization data (search or location-info)
                            if json_data:
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ URL –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                                self.api_responses[url] = {
                                    "data": json_data,
                                    "status": response.status,
                                    "headers": dict(response.headers),
                                }
                                self.api_responses_list.append((url, json_data))
                                # –ê–≥—Ä–µ–≥–∞—Ç—ã: location-info ‚Äî —Ç–æ–ª—å–∫–æ org-bound, –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                                if "location-info" in url:
                                    if self._is_location_info_org_bound(json_data, url):
                                        ts = time.time()
                                        self.location_info_candidates.append((json_data, ts))
                                        if self.location_info_payload is None:
                                            self.location_info_payload = json_data  # backward compat
                                        print(f"‚úÖ [LOCATION_INFO] location_info_accepted_org_bound (org_id –≤ –æ—Ç–≤–µ—Ç–µ)")
                                if "fetchReviews" in url or ("reviews" in url.lower() and "business" in url.lower()):
                                    self.reviews_pages.append(json_data)
                                if "fetchGoods" in url or "prices" in url.lower() or "goods" in url.lower():
                                    self.products_pages.append(json_data)
                                if "search" in url and "business_oid" in url:
                                    self.search_api_payload = json_data
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
                                if any(
                                    keyword in url
                                    for keyword in [
                                        "org",
                                        "organization",
                                        "business",
                                        "company",
                                        "reviews",
                                        "feedback",
                                        "location-info",
                                    ]
                                ):
                                    print(f"‚úÖ –ü–µ—Ä–µ—Ö–≤–∞—á–µ–Ω –≤–∞–∂–Ω—ã–π API –∑–∞–ø—Ä–æ—Å: {url[:100]}...")
                        except Exception:
                            # –ù–µ JSON, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            pass
            except Exception:
                # –ü–æ–≥–ª–æ—â–∞–µ–º –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫–∞, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –≥–ª–∞–≤–Ω—ã–π –ø–æ—Ç–æ–∫
                pass

        page.on("response", handle_response)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É (interception –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –î–û goto ‚Äî –≤—Å–µ –æ—Ç–≤–µ—Ç—ã –±—É–¥—É—Ç –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω—ã)
        print("üåê –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º API –∑–∞–ø—Ä–æ—Å—ã...")
        try:
            main_response = page.goto(url, wait_until="domcontentloaded", timeout=30000)
            try:
                if main_response is not None:
                    main_http_status = main_response.status
            except Exception:
                main_http_status = None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏—è
            for _ in range(24):  # –ñ–¥–µ–º –¥–æ 120 —Å–µ–∫—É–Ω–¥
                try:
                    # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ø—á–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ + —Ä—É—Å/–∞–Ω–≥–ª)
                    title = page.title()
                    is_captcha = (
                        _is_captcha_page(title)
                        or page.get_by_text("–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ, —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç").is_visible()
                        or page.get_by_text("Are you not a robot", exact=False).is_visible()
                        or page.locator(".smart-captcha").count() > 0
                        or page.locator("input[name='smart-token']").count() > 0
                    )

                    if is_captcha:
                        print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞! –ñ–¥–µ–º 15 —Å–µ–∫—É–Ω–¥... (–Ω–µ —Ç—Ä–æ–≥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É)")
                        page.wait_for_timeout(15000)
                    else:
                        break
                except Exception:
                    break
        except PlaywrightTimeoutError:
            print("‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é (—Ç–∞–π–º–∞—É—Ç), –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
        except Exception:
            print("‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")

        # Double check if we are still stuck on Captcha
        title = page.title()
        if _is_captcha_page(title) or _is_captcha_url(page.url):
            print(f"‚ùå –ö–∞–ø—á–∞ –Ω–µ –±—ã–ª–∞ —Ä–µ—à–µ–Ω–∞ –∑–∞ –æ—Ç–≤–µ–¥—ë–Ω–Ω–æ–µ –≤—Ä–µ–º—è. –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –≤–æ—Ä–∫–µ—Ä –∑–Ω–∞–ª –æ –∫–∞–ø—á–µ
            return {"error": "captcha_detected", "captcha_url": page.url}

        try:
            print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç–æ—á–∫–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏...")
            # –ñ–¥–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–¥–æ–±–∞–≤–ª–µ–Ω user selector)
            page.wait_for_selector(
                "h1, div.business-card-title-view, div.card-title-view__title, "
                "div.orgpage-header-view__header, div.orgpage-header-view__header-wrapper > h1",
                timeout=15000,
            )
            print("‚úÖ –ö–∞—Ä—Ç–æ—á–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except PlaywrightTimeoutError:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç–æ—á–∫–∏. –í–æ–∑–º–æ–∂–Ω–æ, –∫–∞–ø—á–∞ –Ω–µ —Ä–µ—à–µ–Ω–∞ –∏–ª–∏ –±–∞–Ω.")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞ –Ω–∞ –≥–ª–∞–≤–Ω—É—é –∏–ª–∏ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        current_url = page.url
        title = page.title()
        print(f"üìç –¢–µ–∫—É—â–∏–π URL: {current_url}, –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")

        if _is_captcha_url(current_url) or _is_captcha_page(title):
            print("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ –∫–∞–ø—á—É –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç–æ—á–∫–∏.")
            return {"error": "captcha_detected", "captcha_url": current_url}

        # org-centric: world-view (z<=3) ‚Äî –∫–∞—Ä—Ç–∞ —Å–ª–æ–º–∞–ª–∞—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞ overview
        if _is_world_view(current_url):
            print("‚ö†Ô∏è World-view (z<=3): –∫–∞—Ä—Ç–∞ —É–ª–µ—Ç–µ–ª–∞. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ overview_url_canonical...")
            try:
                page.goto(self._overview_url_canonical, wait_until="domcontentloaded", timeout=15000)
                page.wait_for_timeout(2000)
                current_url = page.url
                print(f"‚úÖ –í–µ—Ä–Ω—É–ª–∏—Å—å: {current_url}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–µ—Ä–Ω—É—Ç—å—Å—è: {e}")

        # –†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ /prices/ ‚Äî –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ü–µ–Ω –Ω–µ—Ç address/rating/categories. –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞ overview.
        if "/prices/" in current_url or current_url.rstrip("/").endswith("/prices"):
            print("‚ö†Ô∏è –†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ü–µ–Ω (/prices/). –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ overview_url_canonical...")
            overview_url = self._overview_url_canonical
            if not overview_url or "/prices/" in overview_url:
                overview_url = re.sub(r"/prices/?", "/", current_url)
            try:
                # –ñ–¥—ë–º org API –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –Ω–∞ overview
                def _is_org_api_resp(r):
                    u = r.url
                    return any(kw in u for kw in ("org", "location-info", "organization", "business"))
                with page.expect_response(_is_org_api_resp, timeout=20000) as resp_info:
                    page.goto(overview_url, wait_until="domcontentloaded", timeout=15000)
                try:
                    resp_info.value
                    print("‚úÖ Org API –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –Ω–∞ overview")
                except Exception:
                    pass
                page.wait_for_timeout(3000)
                current_url = page.url
                print(f"üìç –ü–æ—Å–ª–µ –ø–µ—Ä–µ—Ö–æ–¥–∞ –Ω–∞ overview: {current_url}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ overview: {e}")

        # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∏—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        is_business_card = False
        try:
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –∏–º–µ–Ω–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–¥–æ–±–∞–≤–ª–µ–Ω user selector)
            is_business_card = (
                page.locator(
                    "h1.orgpage-header-view__header, "
                    "div.business-title-view, "
                    "div.card-title-view__title, "
                    "div.orgpage-header-view__header-wrapper > h1"
                ).count()
                > 0
            )
        except Exception:
            pass

        if (not is_business_card) or ("yandex" in current_url and "/org/" not in current_url):
            print("‚ö†Ô∏è –ù–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫—É –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏! (–†–µ–¥–∏—Ä–µ–∫—Ç?). –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–π—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ —Å–Ω–æ–≤–∞...")

            # Debug: Save bad page (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ bundle)
            if self.debug_bundle_dir:
                try:
                    html_redirect = page.content()
                    os.makedirs(self.debug_bundle_dir, exist_ok=True)
                    with open(os.path.join(self.debug_bundle_dir, "redirect_page.html"), "w", encoding="utf-8") as f:
                        f.write(html_redirect or "")
                except Exception:
                    pass

            page.goto(url, wait_until="domcontentloaded")
            try:
                print("‚è≥ –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏...")
                page.wait_for_selector(
                    "h1.orgpage-header-view__header, "
                    "div.business-title-view, "
                    "div.card-title-view__title, "
                    "h1[itemprop='name'], "
                    "div.orgpage-header-view__header-wrapper > h1",
                    timeout=20000,
                )
                print("‚úÖ –ö–∞—Ä—Ç–æ—á–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (–ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞)")
            except PlaywrightTimeoutError:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ä—Ç–æ—á–∫—É –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞. –í–æ–∑–º–æ–∂–Ω–æ –±–∞–Ω.")
                if self.debug_bundle_dir:
                    try:
                        html_failed = page.content()
                        os.makedirs(self.debug_bundle_dir, exist_ok=True)
                        with open(os.path.join(self.debug_bundle_dir, "failed_page_final.html"), "w", encoding="utf-8") as f:
                            f.write(html_failed or "")
                    except Exception:
                        pass
        else:
            print("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫—É –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏.")

        # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–∫—Ä—É—Ç–∫–∏
        def scroll_page(times: int = 5) -> None:
            for _ in range(times):
                page.mouse.wheel(0, 1000)
                time.sleep(random.uniform(0.5, 1.0))

        def wait_for_location_info(timeout_sec: float = 5.0) -> bool:
            """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ location-info API (–≥–¥–µ title). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω."""
            start = time.time()
            while time.time() - start < timeout_sec:
                if any("location-info" in u for u in self.api_responses):
                    print("‚úÖ [WAIT] location-info –∑–∞–≥—Ä—É–∂–µ–Ω")
                    return True
                time.sleep(0.5)
                try:
                    page.evaluate("window.scrollBy(0, 100)")
                except Exception:
                    pass
            print("‚è±Ô∏è [WAIT] –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è location-info")
            return False

        extra_photos_count = 0
        ui_counts: Dict[str, int] = {"reviews": 0, "photos": 0, "services": 0}

        # 1. –°–∫—Ä–æ–ª–ª–∏–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        print("üìú –°–∫—Ä–æ–ª–ª–∏–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
        scroll_page(3)

        # 1.5 –û–∂–∏–¥–∞–Ω–∏–µ location-info –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ—Ö–æ–¥–æ–º –ø–æ –≤–∫–ª–∞–¥–∫–∞–º (title –±–µ—Ä—ë—Ç—Å—è –æ—Ç—Ç—É–¥–∞)
        if not wait_for_location_info():
            print("‚ö†Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –ø–æ –≤–∫–ª–∞–¥–∫–∞–º –±–µ–∑ location-info ‚Äî title –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å")

        # 2. –ö–ª–∏–∫–∞–µ–º –∏ —Å–∫—Ä–æ–ª–ª–∏–º –û—Ç–∑—ã–≤—ã (Reviews)
        try:
            reviews_tab = page.query_selector("div.tabs-select-view__title._name_reviews")
            if reviews_tab:
                print("üí¨ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤–æ –≤–∫–ª–∞–¥–∫—É –û—Ç–∑—ã–≤—ã...")
                reviews_tab.click(force=True)
                time.sleep(2)

                # –°–∫—Ä–æ–ª–ª–∏–º –æ—Ç–∑—ã–≤—ã (–æ—á–µ–Ω—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
                print("üìú –°–∫—Ä–æ–ª–ª–∏–º –æ—Ç–∑—ã–≤—ã (–≥–ª—É–±–æ–∫–∏–π —Å–∫—Ä–æ–ª–ª - –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö)...")
                for i in range(80):  # Increased to 80
                    # Random scroll amount
                    delta = random.randint(2000, 4000)
                    page.mouse.wheel(0, delta)
                    page.evaluate(f"window.scrollBy(0, {delta//2})")  # JS scroll helper

                    time.sleep(random.uniform(0.5, 1.2))

                    # Small "wobble" (scroll up slightly) to trigger intersection observers
                    if i % 5 == 0:
                        page.mouse.wheel(0, -500)
                        time.sleep(0.5)
                        page.mouse.wheel(0, 500)

                    # Move mouse to trigger hover events
                    page.mouse.move(random.randint(100, 800), random.randint(100, 800))

                    # –ü—ã—Ç–∞–µ–º—Å—è –∫–ª–∏–∫–Ω—É—Ç—å "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â–µ" –µ—Å–ª–∏ –µ—Å—Ç—å
                    try:
                        more_btn = page.query_selector("button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë')") or page.query_selector(
                            "div.reviews-view__more"
                        )
                        if more_btn and more_btn.is_visible():
                            more_btn.click()
                            time.sleep(2)
                    except Exception:
                        pass
            else:
                print("‚ÑπÔ∏è –í–∫–ª–∞–¥–∫–∞ –û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (—Å–µ–ª–µ–∫—Ç–æ—Ä)")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–∑—ã–≤–æ–≤: {e}")

        # 3. –ö–ª–∏–∫–∞–µ–º –∏ —Å–∫—Ä–æ–ª–ª–∏–º –§–æ—Ç–æ (Photos)
        try:
            photos_tab = page.query_selector("div.tabs-select-view__title._name_gallery")
            if photos_tab:
                print("üì∑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤–æ –≤–∫–ª–∞–¥–∫—É –§–æ—Ç–æ...")

                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ
                try:
                    photos_text = photos_tab.inner_text()
                    print(f"‚ÑπÔ∏è –¢–µ–∫—Å—Ç –≤–∫–ª–∞–¥–∫–∏ —Ñ–æ—Ç–æ: {photos_text}")
                    match = re.search(r"(\d+)", photos_text)
                    if match:
                        extra_photos_count = int(match.group(1))
                except Exception:
                    pass

                photos_tab.click(force=True)
                time.sleep(2)
                print("üìú –°–∫—Ä–æ–ª–ª–∏–º —Ñ–æ—Ç–æ...")
                scroll_page(10)
            else:
                print("‚ÑπÔ∏è –í–∫–ª–∞–¥–∫–∞ –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ: {e}")

        # 4. –ö–ª–∏–∫–∞–µ–º –∏ —Å–∫—Ä–æ–ª–ª–∏–º –ù–æ–≤–æ—Å—Ç–∏ (News/Posts)
        try:
            news_tab = page.query_selector("div.tabs-select-view__title._name_posts")
            if news_tab:
                print("üì∞ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤–æ –≤–∫–ª–∞–¥–∫—É –ù–æ–≤–æ—Å—Ç–∏...")
                news_tab.click(force=True)
                time.sleep(2)
                print("üìú –°–∫—Ä–æ–ª–ª–∏–º –Ω–æ–≤–æ—Å—Ç–∏...")
                scroll_page(10)
            else:
                print("‚ÑπÔ∏è –í–∫–ª–∞–¥–∫–∞ –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")

        # 5. –ö–ª–∏–∫–∞–µ–º –∏ —Å–∫—Ä–æ–ª–ª–∏–º –¢–æ–≤–∞—Ä—ã/–£—Å–ª—É–≥–∏ (Prices/Goods)
        # org-centric: –∏—Å–ø–æ–ª—å–∑—É–µ–º llz_anchor (–∏–∑ request URL), –Ω–µ page.url
        overview_url_for_return = self._overview_url_canonical

        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–∞–±–∞ —Ç–æ–≤–∞—Ä–æ–≤
            services_tab = page.query_selector("div.tabs-select-view__title._name_price")
            if not services_tab:
                services_tab = page.query_selector("div.tabs-select-view__title._name_goods")
            if not services_tab:
                # User provided selector (simplified) - 2nd tab in carousel
                services_tab = page.query_selector("div.carousel__content > div:nth-child(2) > div")

            # Fallback –Ω–∞ –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É
            if not services_tab:
                for text in ["–¶–µ–Ω—ã", "–¢–æ–≤–∞—Ä—ã –∏ —É—Å–ª—É–≥–∏", "–£—Å–ª—É–≥–∏", "–¢–æ–≤–∞—Ä—ã", "–ú–µ–Ω—é", "–ü—Ä–∞–π—Å"]:
                    try:
                        found = page.get_by_text(text, exact=False)
                        if found.count() > 0:
                            # Check visibility to avoid hidden elements
                            if found.first.is_visible():
                                services_tab = found.first
                                print(f"‚úÖ –ù–∞—à–ª–∏ —Ç–∞–± —É—Å–ª—É–≥ –ø–æ —Ç–µ–∫—Å—Ç—É: {text}")
                                break
                    except Exception:
                        pass

            if services_tab:
                print("üí∞ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤–æ –≤–∫–ª–∞–¥–∫—É –¶–µ–Ω—ã/–£—Å–ª—É–≥–∏...")
                services_tab.click(force=True)
                time.sleep(3)  # –ß—É—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
                print("üìú –°–∫—Ä–æ–ª–ª–∏–º —É—Å–ª—É–≥–∏...")
                scroll_page(20)  # –ë–æ–ª—å—à–µ —Å–∫—Ä–æ–ª–ª–∞

                # –î–æ–∂–∏–¥–∞–µ–º—Å—è fetchGoods –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º ‚Äî –∏–∑–±–µ–≥–∞–µ–º –≥–æ–Ω–æ–∫
                n0 = len(self.products_pages)
                for _ in range(8):
                    page.wait_for_timeout(200)
                    n = len(self.products_pages)
                    if n > n0:
                        n0 = n
                    elif n0 > 0:
                        page.wait_for_timeout(400)
                        break

                # –í–æ–∑–≤—Ä–∞—Ç –Ω–∞ overview ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç "—É–ª–µ—Ç–∞" –∫–∞—Ä—Ç—ã –Ω–∞ /prices/
                current_after = page.url
                if "/prices/" in current_after or current_after.rstrip("/").endswith("/prices") or _is_world_view(current_after):
                    if overview_url_for_return:
                        try:
                            print("üìç –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞ overview (–∫–∞—Ä—Ç–∞ —É–µ—Ö–∞–ª–∞ –Ω–∞ /prices/)...")
                            page.goto(overview_url_for_return, wait_until="domcontentloaded", timeout=15000)
                            page.wait_for_timeout(2000)
                            print(f"‚úÖ –í–µ—Ä–Ω—É–ª–∏—Å—å –Ω–∞ overview: {page.url}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ overview: {e}")
                    else:
                        # Fallback: —É–±–∏—Ä–∞–µ–º /prices/ –∏–∑ URL
                        fallback = re.sub(r"/prices/?", "/", current_after)
                        if fallback != current_after:
                            try:
                                page.goto(fallback, wait_until="domcontentloaded", timeout=15000)
                                page.wait_for_timeout(2000)
                            except Exception:
                                pass
            else:
                print("‚ÑπÔ∏è –í–∫–ª–∞–¥–∫–∞ –¶–µ–Ω—ã/–£—Å–ª—É–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —É—Å–ª—É–≥: {e}")

        # –°–±–æ—Ä ui_counts –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–∫–ª–∞–¥–æ–∫ (—á—Ç–æ –≤–∏–¥–Ω–æ –Ω–∞ UI: 74 –æ—Ç–∑—ã–≤–∞, 64 —Ñ–æ—Ç–æ, 36 —É—Å–ª—É–≥)
        try:
            for sel, key in [
                ("div.tabs-select-view__title._name_reviews", "reviews"),
                ("div.tabs-select-view__title._name_gallery", "photos"),
                ("div.tabs-select-view__title._name_price", "services"),
            ]:
                tab = page.query_selector(sel) or page.query_selector(
                    "div.tabs-select-view__title._name_goods" if key == "services" else ""
                )
                if tab:
                    txt = tab.inner_text()
                    m = re.search(r"(\d+)", txt)
                    if m:
                        ui_counts[key] = int(m.group(1))
        except Exception:
            pass

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ HTML (—Ç–∞–∫ –∫–∞–∫ –≤ JSON —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø—Ä—è—Ç–∞–Ω–æ)
        is_verified = False
        try:
            verified_selectors = [
                ".business-verified-badge-view",
                "div._name_verified",
                ".business-card-view__verified-badge",
                "span[aria-label='–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ –≤–ª–∞–¥–µ–ª—å—Ü–µ–º']",
                "span.business-verified-badge",
                "div.business-verified-badge",
            ]
            for sel in verified_selectors:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                try:
                    if page.query_selector(sel):
                        is_verified = True
                        print("‚úÖ –ù–∞–π–¥–µ–Ω–∞ –≥–∞–ª–æ—á–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ (HTML)")
                        break
                except Exception:
                    continue
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")

        print(f"üì¶ –ü–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–æ {len(self.api_responses)} API –∑–∞–ø—Ä–æ—Å–æ–≤")

        # org-centric: —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äî /prices/ –∏–ª–∏ world-view ‚Üí goto overview_url_canonical
        current_before_extract = page.url
        if "/prices/" in current_before_extract or current_before_extract.rstrip("/").endswith("/prices") or _is_world_view(current_before_extract):
            try:
                print("üìç –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–∑–≤—Ä–∞—Ç –Ω–∞ overview_url_canonical –ø–µ—Ä–µ–¥ —Å–±–æ—Ä–æ–º payload...")
                page.goto(self._overview_url_canonical, wait_until="domcontentloaded", timeout=15000)
                page.wait_for_timeout(2000)
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞ overview: {e}")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (api_payload)
        api_payload = self._extract_data_from_responses()
        data = dict(api_payload)  # final –±—É–¥–µ—Ç –º–µ—Ä–¥–∂–∏—Ç—å—Å—è —Å html
        data["is_verified"] = is_verified

        # –ñ—ë—Å—Ç–∫–∏–π fail: org API –Ω–µ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω, –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π –Ω–µ—Ç ‚Äî –Ω–µ low_quality, –∞ org_api_not_loaded
        has_org_api = any(
            kw in u for u in self.api_responses
            for kw in ("org", "location-info", "organization", "business", "company")
        )
        has_critical = bool(
            data.get("address") or data.get("rating")
            or (data.get("categories") and len(data.get("categories", [])) > 0)
        )

        if _is_captcha_url(page.url):
            print("‚ùå –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–∞–ø—á–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º captcha_detected.")
            return {"error": "captcha_detected", "captcha_url": page.url}

        if not has_org_api and not has_critical:
            print("‚ùå Org API –Ω–µ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω, –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π –Ω–µ—Ç. –í–æ–∑–≤—Ä–∞—â–∞–µ–º org_api_not_loaded.")
            return {"error": "org_api_not_loaded", "url": page.url}
        if extra_photos_count > 0:
            data["photos_count"] = extra_photos_count

        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ API, fallback –Ω–∞ HTML –ø–∞—Ä—Å–∏–Ω–≥
        # –ü–ï–†–ï–î –≠–¢–ò–ú: Hybrid Mode –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–µ–∫—Ü–∏–π

        # 1. –£—Å–ª—É–≥–∏/–¢–æ–≤–∞—Ä—ã (—á–∞—Å—Ç–æ —Å–∫—Ä—ã—Ç—ã –≤ API)
        if not data.get("products"):
            print("‚ö†Ô∏è –£—Å–ª—É–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —á–µ—Ä–µ–∑ API, –ø—Ä–æ–±—É–µ–º HTML –ø–∞—Ä—Å–∏–Ω–≥ (Hybrid Mode)...")
            try:
                # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
                from yandex_maps_scraper import parse_products

                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º—ã –Ω–∞ –≤–∫–ª–∞–¥–∫–µ —Ç–æ–≤–∞—Ä–æ–≤ (–º—ã —Ç—É–¥–∞ –∫–ª–∏–∫–∞–ª–∏ —Ä–∞–Ω–µ–µ)
                # –ù–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø—Ä–æ–≤–µ—Ä–∏–º
                html_products = parse_products(page)
                if html_products:
                    print(f"‚úÖ –£—Å–ª—É–≥–∏ –Ω–∞–π–¥–µ–Ω—ã —á–µ—Ä–µ–∑ HTML: {len(html_products)}")
                    data["products"] = html_products
                    data["fallback_used"] = True  # MARKER for worker.py warning

                    # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º overview grouped products
                    grouped_products = {}
                    for prod in html_products:
                        cat = prod.get("category", "–î—Ä—É–≥–æ–µ") or "–î—Ä—É–≥–æ–µ"
                        if cat not in grouped_products:
                            grouped_products[cat] = []
                        grouped_products[cat].append(prod)

                    final_products = []
                    for cat, items in grouped_products.items():
                        final_products.append({"category": cat, "items": items})
                    data["products"] = final_products
                else:
                    print("‚ö†Ô∏è HTML –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ª—É–≥ —Ç–æ–∂–µ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Hybrid Mode –¥–ª—è —É—Å–ª—É–≥: {e}")

        # HTML fallback: merge_non_empty ‚Äî –Ω–µ –∑–∞—Ç–∏—Ä–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ API-–ø–æ–ª—è –ø—É—Å—Ç—ã–º–∏
        html_payload = self._extract_from_html_fallback(page)
        meta_src_html = {k: "html_fallback" for k in html_payload if html_payload.get(k)}
        merge_non_empty(data, html_payload, meta_src_html, source="html_fallback", org_page=self.org_page)
        if data.get("title") and (data.get("meta") or {}).get("title_source") == "html_fallback":
            print(f"[IDENTITY] chosen title={data.get('title', '')[:50]} source=html_fallback")

        # –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ user selector (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)
        if not is_verified:
            try:
                verified_el = page.query_selector(
                    "div.orgpage-header-view__header-wrapper > h1 > span.business-verified-badge, "
                    "div.orgpage-header-view__header-wrapper > h1 > span"
                )
                if verified_el:
                    data["is_verified"] = True
                    print("‚úÖ –ù–∞–π–¥–µ–Ω–∞ –≥–∞–ª–æ—á–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ (User CSS)")
            except Exception:
                pass

        # –ü–µ—Ä–µ–¥–∞–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ø–∞—Ä—Å–µ—Ä (products HTML)
        try:
            if not data.get("products"):
                print("üõ† Parsing services via HTML with USER Selectors...")
                products_html: List[Dict[str, Any]] = []
                groups = page.query_selector_all("div.business-full-items-grouped-view__content > div")
                for group in groups:
                    cat_title_el = group.query_selector("div.business-full-items-grouped-view__title")
                    cat_title = cat_title_el.inner_text() if cat_title_el else "–î—Ä—É–≥–æ–µ"
                    items = group.query_selector_all(
                        "div.business-full-items-grouped-view__item, div.related-product-view"
                    )
                    if not items:
                        items = group.query_selector_all("div.business-full-items-grouped-view__items._grid > div")
                    for item in items:
                        try:
                            name_el = item.query_selector("div.related-product-view__title")
                            price_el = item.query_selector("div.related-product-view__price")
                            if name_el:
                                products_html.append({
                                    "name": name_el.inner_text(),
                                    "price": price_el.inner_text() if price_el else "",
                                    "category": cat_title,
                                    "description": "",
                                    "photo": "",
                                })
                        except Exception:
                            pass
                if not products_html:
                    try:
                        from yandex_maps_scraper import parse_products
                        products_html = parse_products(page)
                    except ImportError:
                        pass
                if products_html:
                    print(f"‚úÖ HTML Fallback –Ω–∞—à–µ–ª {len(products_html)} —É—Å–ª—É–≥")
                    current = data.get("products", [])
                    current.extend(products_html)
                    data["products"] = current
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ user-selector HTML parsing: {e}")

        # page_title –¥–ª—è fallback –≤ worker
        try:
            pt = page.title()
            if pt and _is_empty(data.get("page_title")):
                data["page_title"] = pt
        except Exception:
            pass

        # Warnings –ø–æ –ø–æ–ª–Ω–æ—Ç–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (ui_counts vs extracted)
        extracted_reviews = len(data.get("reviews") or [])
        extracted_photos = data.get("photos_count") or len(data.get("photos") or [])
        products_raw = data.get("products") or []
        extracted_services = sum(len(g.get("items", [])) for g in products_raw if isinstance(g, dict)) if products_raw else 0
        if not extracted_services and products_raw:
            extracted_services = len(products_raw)
        warnings_list: List[str] = list(data.get("warnings") or [])
        # Identity warnings –∏–∑ _identity_debug (Part D)
        warnings_list.extend(self._identity_debug.get("warnings") or [])
        warnings_list = list(dict.fromkeys(warnings_list))  # dedup
        if ui_counts.get("reviews", 0) >= 50 and extracted_reviews < ui_counts["reviews"] * 0.8:
            warnings_list.append("reviews_incomplete")
        if ui_counts.get("photos", 0) > 0 and extracted_photos == 0:
            warnings_list.append("photos_not_extracted")
        if ui_counts.get("services", 0) > 0 and extracted_services < ui_counts["services"] * 0.8:
            warnings_list.append("services_incomplete")
        # identity_weak_sources_only: org_page, search_api –Ω–µ –¥–∞–ª identity, —Ç–æ–ª—å–∫–æ html_fallback title
        if self.org_page and not self._search_api_contributed_identity:
            meta = data.get("meta") or {}
            title_src = meta.get("title_source") or meta.get("title_or_name_source")
            if title_src == "html_fallback" and (
                _is_empty(data.get("address")) or _is_empty(data.get("categories"))
            ):
                warnings_list.append("identity_weak_sources_only")
        data["warnings"] = warnings_list

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è title_or_name –ü–ï–†–ï–î return (–∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç)
        _normalize_title_fields(data)

        # org-centric: url –≤ –æ—Ç–≤–µ—Ç–µ ‚Äî canonical overview –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–∏ (–Ω–µ world-view)
        if self._overview_url_canonical:
            data["url"] = self._overview_url_canonical

        # DEBUG BUNDLE (dev): —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≤–æ–¥–∫—É –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ bundle)
        if self.debug_bundle_dir:
            try:
                debug_dir = self.debug_bundle_dir
                os.makedirs(debug_dir, exist_ok=True)

                final_url = page.url
                page_title = ""
                try:
                    page_title = page.title()
                except Exception:
                    pass

                html_content = ""
                try:
                    html_content = page.content()
                except Exception:
                    pass
                html_length = len(html_content or "")

                intercepted_json_count = len(self.api_responses)
                all_urls = list(self.api_responses.keys())
                last_10_urls = all_urls[-10:]

                # –¢–æ–ø-3 —Å–∞–º—ã—Ö –∫—Ä—É–ø–Ω—ã—Ö JSON-–æ—Ç–≤–µ—Ç–∞ –ø–æ –¥–ª–∏–Ω–µ body
                sized = []
                for u, info in self.api_responses.items():
                    try:
                        body = info.get("data")
                        body_str = json.dumps(body, ensure_ascii=False)
                        sized.append((u, len(body_str)))
                    except Exception:
                        continue
                sized.sort(key=lambda x: x[1], reverse=True)
                top_3_urls = [u for (u, _) in sized[:3]]

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ cookies –∏ –¥–æ–º–µ–Ω–∞—Ö
                cookie_domains = set()
                final_host = ""
                try:
                    parsed = urlparse(final_url)
                    final_host = parsed.hostname or ""
                except Exception:
                    final_host = ""

                try:
                    cookies = context.cookies()
                    for c in cookies:
                        dom = c.get("domain")
                        if dom:
                            cookie_domains.add(dom)
                except Exception:
                    pass

                # –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ / –∫–∞–ø—á–∏ (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ, —Ä—É—Å/–∞–Ω–≥–ª)
                blocked_flags = {
                    "has_captcha_text": _is_captcha_page(page_title or ""),
                    "html_contains_captcha": ("smart-captcha" in (html_content or "")),
                }

                timestamp = int(time.time() * 1000)
                safe_org = (self.org_id or "unknown")[:32]
                summary_name = f"debug_{timestamp}_{safe_org}.json"
                html_name = f"debug_{timestamp}_{safe_org}.html"
                screenshot_name = f"debug_{timestamp}_{safe_org}.png"

                summary_path = os.path.join(debug_dir, summary_name)
                html_path = os.path.join(debug_dir, html_name)
                screenshot_path = os.path.join(debug_dir, screenshot_name)

                debug_summary = {
                    "final_url": final_url,
                    "overview_url_canonical": getattr(self, "_overview_url_canonical", None),
                    "org_id": self.org_id,
                    "page_title": page_title,
                    "html_length": html_length,
                    "intercepted_json_count": intercepted_json_count,
                    "last_10_json_urls": last_10_urls,
                    "top_3_largest_json_urls": top_3_urls,
                    "cookie_domains": sorted(cookie_domains),
                    "final_host": final_host,
                    "blocked_flags": blocked_flags,
                }

                # –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –ø—É—Ç–µ–π –≤ –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö JSON-–æ—Ç–≤–µ—Ç–∞—Ö
                target_keys = [
                    "address",
                    "address_name",
                    "fullAddress",
                    "rating",
                    "score",
                    "ratingData",
                    "rubrics",
                    "categories",
                    "rubric",
                ]
                found_key_paths: Dict[str, List[Dict[str, str]]] = {}
                for u in top_3_urls:
                    info = self.api_responses.get(u)
                    if not info:
                        continue
                    raw_json = info.get("data")
                    try:
                        paths = _find_paths(raw_json, target_keys)
                        for key, items in paths.items():
                            bucket = found_key_paths.setdefault(key, [])
                            # –ª–∏–º–∏—Ç–∏—Ä—É–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –ø–æ –∫–ª—é—á—É
                            for item in items:
                                if len(bucket) >= 30:
                                    break
                                bucket.append({"url": u, **item})
                    except Exception:
                        continue

                if found_key_paths:
                    debug_summary["found_key_paths"] = found_key_paths

                with open(summary_path, "w", encoding="utf-8") as f:
                    json.dump(debug_summary, f, ensure_ascii=False, indent=2)

                if html_content:
                    with open(html_path, "w", encoding="utf-8") as f:
                        f.write(html_content)

                try:
                    page.screenshot(path=screenshot_path, full_page=True)
                except Exception:
                    pass

                print(f"üíæ Debug bundle saved: {summary_name}, {html_name}, {screenshot_name}")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to save debug bundle: {e}")

        # DEV-–ª–æ–≥ –ø–æ –∏—Ç–æ–≥–æ–≤—ã–º –ø–æ–ª—è–º
        try:
            cats = data.get("categories") or []
            if isinstance(cats, list):
                categories_count = len(cats)
            elif cats:
                categories_count = 1
            else:
                categories_count = 0

            quality_score = None
            meta = data.get("_meta")
            if isinstance(meta, dict):
                quality_score = meta.get("quality_score")

            print(
                f"DEV summary: title='{str(data.get('title', ''))[:80]}', "
                f"address_present={bool(data.get('address'))}, "
                f"rating='{data.get('rating', '')}', "
                f"reviews_count={data.get('reviews_count')}, "
                f"categories_count={categories_count}, "
                f"quality_score={quality_score}"
            )
        except Exception:
            pass

        # –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π debug bundle –¥–ª—è —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π:
        # request_url.txt, final_url.txt, http_status.txt, page.html, payload.json
        if self.debug_bundle_dir:
            try:
                bundle_dir = self.debug_bundle_dir
                os.makedirs(bundle_dir, exist_ok=True)

                # HTML –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                try:
                    page_html = page.content()
                except Exception:
                    page_html = html_content or ""
                with open(os.path.join(bundle_dir, "page.html"), "w", encoding="utf-8") as f:
                    f.write(page_html or "")

                # –ò—Å—Ö–æ–¥–Ω—ã–π URL
                try:
                    with open(os.path.join(bundle_dir, "request_url.txt"), "w", encoding="utf-8") as f:
                        f.write(initial_url or "")
                except Exception:
                    pass

                # –§–∏–Ω–∞–ª—å–Ω—ã–π URL
                try:
                    with open(os.path.join(bundle_dir, "final_url.txt"), "w", encoding="utf-8") as f:
                        f.write(final_url or "")
                except Exception:
                    pass

                # HTTP —Å—Ç–∞—Ç—É—Å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                try:
                    with open(os.path.join(bundle_dir, "http_status.txt"), "w", encoding="utf-8") as f:
                        f.write("" if main_http_status is None else str(main_http_status))
                except Exception:
                    pass

                # api_extract.json ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç extractor'–∞ –∏–∑ API (–¥–æ HTML merge)
                try:
                    api_extract = {
                        "title": api_payload.get("title"),
                        "title_or_name": api_payload.get("title_or_name"),
                        "address": api_payload.get("address"),
                        "categories": api_payload.get("categories"),
                        "rating": api_payload.get("rating"),
                        "reviews_count": api_payload.get("reviews_count"),
                    }
                    # location-info structure helper: top-level keys –∏ 1‚Äì2 —É—Ä–æ–≤–Ω—è
                    li_struct = None
                    if self.location_info_payload:
                        li = self.location_info_payload
                        li_keys = list(li.keys())[:20] if isinstance(li, dict) else []
                        li_nested = {}
                        if isinstance(li, dict) and "data" in li:
                            d = li["data"]
                            li_nested["data_keys"] = list(d.keys())[:25] if isinstance(d, dict) else []
                            if isinstance(d, dict) and "toponymSearchResult" in d:
                                tsr = d["toponymSearchResult"]
                                li_nested["toponymSearchResult_keys"] = list(tsr.keys())[:15] if isinstance(tsr, dict) else []
                        li_struct = {"top_keys": li_keys, "nested": li_nested}
                    api_extract["location_info_structure"] = li_struct
                    with open(os.path.join(bundle_dir, "api_extract.json"), "w", encoding="utf-8") as f:
                        json.dump(api_extract, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to write api_extract.json: {e}")

                # payload.json (legacy) –∏ final_payload.json ‚Äî —Ç–æ, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∏–∑ parse_yandex_card
                try:
                    with open(os.path.join(bundle_dir, "payload.json"), "w", encoding="utf-8") as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    with open(os.path.join(bundle_dir, "final_payload.json"), "w", encoding="utf-8") as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to write payload.json/final_payload.json: {e}")

                # selected_item_debug.json ‚Äî search API: —Å–∫–æ–ª—å–∫–æ items, –∫–∞–∫–æ–π –≤—ã–±—Ä–∞–Ω, –ø–æ –∫–∞–∫–æ–º—É –∫–ª—é—á—É
                try:
                    if getattr(self, "_search_api_debug", None):
                        with open(os.path.join(bundle_dir, "selected_item_debug.json"), "w", encoding="utf-8") as f:
                            json.dump(self._search_api_debug, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to write selected_item_debug.json: {e}")

                # identity_sources.json ‚Äî –∏—Å—Ç–æ—á–Ω–∏–∫–∏ identity-–ø–æ–ª–µ–π, blocked_candidates (Part E)
                try:
                    meta = data.get("meta") or {}
                    identity_map = {}
                    for f in IDENTITY_FIELDS:
                        val = data.get(f)
                        if _is_non_empty(val):
                            src = meta.get(f"{f}_source") or (meta.get("title_or_name_source") or meta.get("title_source") if f == "title_or_name" else None) or "unknown"
                            identity_map[f] = {"value": val if not isinstance(val, list) else val[:10], "source": src}
                    identity_sources = {
                        "org_id": self.org_id,
                        "identity": identity_map,
                        "blocked_candidates": self._identity_debug.get("blocked_candidates") or [],
                        "warnings": list(data.get("warnings") or []),
                    }
                    with open(os.path.join(bundle_dir, "identity_sources.json"), "w", encoding="utf-8") as f:
                        json.dump(identity_sources, f, ensure_ascii=False, indent=2, default=str)
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to write identity_sources.json: {e}")

                # –°—á—ë—Ç—á–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å UI
                try:
                    services_list = data.get("products") or []
                    if isinstance(services_list, list):
                        services_count = sum(len(g.get("items", [])) for g in services_list if isinstance(g, dict)) or len(services_list)
                    else:
                        services_count = 0
                    counts = {
                        "extracted": {
                            "services": services_count,
                            "reviews": len(data.get("reviews") or []),
                            "photos": data.get("photos_count") or len(data.get("photos") or []),
                        },
                        "raw_before_dedup": {
                            "services": getattr(self, "_debug_raw_services_count", 0),
                        },
                    }
                    with open(os.path.join(bundle_dir, "counts_comparison.json"), "w", encoding="utf-8") as f:
                        json.dump(counts, f, ensure_ascii=False, indent=2)
                except Exception as ce:
                    print(f"‚ö†Ô∏è Failed to write counts_comparison.json: {ce}")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to write canonical debug bundle files: {e}")

        # [PHOTOS_COUNT]
        photos_count = data.get("photos_count") or len(data.get("photos") or [])
        print(f"[PHOTOS_COUNT] extracted={photos_count}")

        # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: API –Ω–µ –æ—Ç–¥–∞—ë—Ç, –¥–æ–ø–æ–ª–Ω—è–µ–º –∏–∑ HTML (—Å–µ–∫—Ü–∏—è ¬´–ü–æ—Ö–æ–∂–∏–µ –º–µ—Å—Ç–∞¬ª)
        if not (data.get("competitors") or []):
            try:
                from yandex_maps_scraper import parse_competitors
                comps = parse_competitors(page)
                if comps:
                    data["competitors"] = comps
                    print(f"üìä –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã –∏–∑ HTML: {len(comps)}")
            except Exception as ce:
                print(f"‚ö†Ô∏è parse_competitors: {ce}")

        # DATA_TRACE
        print(f"[DATA_TRACE] data.title: {data.get('title')}, title_or_name: {data.get('title_or_name')}")

        print(
            f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ: –Ω–∞–∑–≤–∞–Ω–∏–µ='{data.get('title', '')}', –∞–¥—Ä–µ—Å='{data.get('address', '')}'"
        )
        return data
    
    def _extract_data_from_responses(self) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö API –æ—Ç–≤–µ—Ç–æ–≤"""
        data = {
            'url': '',
            'title': '',
            'address': '',
            'phone': '',
            'site': '',
            'description': '',
            'rating': '',
            'ratings_count': 0,
            'reviews_count': 0,
            'reviews': [],
            'news': [],
            'photos': [],
            'photos_count': 0,
            'rubric': '',
            'categories': [],
            'hours': '',
            'hours_full': '',
            'social_links': [],
            'features_full': {},
            'competitors': [],
            'products': [],
            'overview': {}
        }
        
        # 1) –°–ù–ê–ß–ê–õ–ê search API (business_oid) ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è title/address –Ω–∞ org-—Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö
        for url, response_info in self.api_responses.items():
            if 'search' in url and 'business_oid' in url:
                json_data = response_info['data']
                search_data = self._extract_search_api_business(json_data)
                if search_data:
                    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ search API (business_oid)")
                    _search_debug = search_data.pop("_search_debug", None)
                    if _search_debug is not None:
                        self._search_api_debug = _search_debug
                    meta_src = search_data.pop("meta", None) or {}
                    merge_non_empty(data, search_data, meta_src, source="search_api", org_page=self.org_page)
                    if any(_is_non_empty(search_data.get(f)) for f in IDENTITY_FIELDS):
                        self._search_api_contributed_identity = True
                    # [IDENTITY] log
                    if search_data.get("title"):
                        print(f"[IDENTITY] chosen title={search_data.get('title', '')[:50]} source=search_api")
                break  # –æ–¥–∏–Ω search API –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

        # 2.1) location-info: —Å–æ–±–∏—Ä–∞–µ–º org-bound, –∏–∑–≤–ª–µ–∫–∞–µ–º –æ–±—ä–µ–∫—Ç, –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –ø–æ score
        location_info_scored: List[tuple] = []  # [(org_data, score, idx)]
        api_urls = list(self.api_responses.keys())
        for idx, url in enumerate(api_urls):
            if 'location-info' not in url:
                continue
            json_data = self.api_responses[url].get('data')
            if not self._is_location_info_org_bound(json_data, url):
                self._identity_debug.setdefault("warnings", []).append("location_info_rejected_not_org_bound")
                print(f"‚ö†Ô∏è [LOCATION_INFO] location_info_rejected_not_org_bound (area-based)")
                continue
            org_obj = self._extract_org_object_from_location_info(json_data)
            if org_obj is None:
                self._identity_debug.setdefault("warnings", []).append("location_info_org_object_not_found_in_payload")
                print(f"‚ö†Ô∏è [LOCATION_INFO] location_info_org_object_not_found_in_payload ‚Äî reject –¥–ª—è core")
                continue
            org_data = self._extract_location_info(org_obj)
            if not org_data:
                continue
            score = self._score_location_info_payload(org_data)
            location_info_scored.append((org_data, score, idx))
            print(f"‚úÖ [LOCATION_INFO] location_info_org_bound_scored (score={score})")

        if location_info_scored:
            best = max(location_info_scored, key=lambda x: (x[1], x[2]))  # max score, tie-break: last (higher idx)
            org_data, score, idx = best
            # backward compat –¥–ª—è debug
            if idx < len(api_urls):
                self.location_info_payload = self.api_responses[api_urls[idx]].get("data")
            print(f"‚úÖ [LOCATION_INFO] location_info_org_bound_selected_best (score={score})")
            self._identity_debug.setdefault("warnings", []).append("location_info_org_object_extracted")
            blocked = []
            if self.org_page:
                for f in IDENTITY_FIELDS:
                    val = org_data.get(f)
                    if _is_non_empty(val):
                        blocked.append({
                            "source": "location_info",
                            "field": f,
                            "value": val[:80] + "‚Ä¶" if isinstance(val, str) and len(val) > 80 else val,
                            "reason": "org_page_identity_forbidden",
                        })
                        if f in ("title", "title_or_name"):
                            print(f"[IDENTITY] blocked location-info title={str(val)[:50]} (org_page)")
                for f in list(org_data.keys()):
                    if f in IDENTITY_FIELDS:
                        org_data.pop(f, None)
                if org_data:
                    org_data = {k: v for k, v in org_data.items() if k in LOCATION_INFO_SAFE_FIELDS and _is_non_empty(v)}
                if blocked:
                    self._identity_debug.setdefault("blocked_candidates", []).extend(blocked)
                    self._identity_debug.setdefault("warnings", []).append("identity_mismatch:location_info")
                if org_data:
                    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ location-info (safe fields only)")
            else:
                print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ location-info API")
            if org_data:
                meta_src = {k: "location_info" for k in org_data if k not in ("meta",) and org_data.get(k)}
                merge_non_empty(data, org_data, meta_src, source="location_info", org_page=self.org_page)

        # 2.2) –û—Å—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (reviews, products, org_api, posts) ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é
        accumulated_reviews: List[Dict[str, Any]] = []
        seen_review_keys: set[str] = set()
        accumulated_photos: List[Dict[str, Any]] = []
        seen_photo_keys: set[str] = set()
        review_only_photo_keys: set[str] = set()

        def _photo_key(photo: Dict[str, Any]) -> Optional[str]:
            if not isinstance(photo, dict):
                return None
            pid = photo.get("id")
            if pid:
                return f"id:{pid}"
            purl = photo.get("url")
            if purl:
                return f"url:{purl}"
            return None

        def _merge_photos(photos_batch: List[Dict[str, Any]]) -> None:
            if not photos_batch:
                return
            for p in photos_batch:
                if not isinstance(p, dict):
                    continue
                key = _photo_key(p) or str(p)
                if key in seen_photo_keys:
                    continue
                seen_photo_keys.add(key)
                accumulated_photos.append(p)
            if accumulated_photos:
                data["photos"] = accumulated_photos
                data["photos_count"] = max(len(accumulated_photos), int(data.get("photos_count") or 0))

        def _extract_review_photos(payload: Any) -> List[Dict[str, Any]]:
            out: List[Dict[str, Any]] = []
            if not isinstance(payload, dict):
                return out
            reviews_arr = _pick_first(payload, [["data", "reviews"], ["reviews"], ["result", "reviews"]])
            if not isinstance(reviews_arr, list):
                return out
            for rev in reviews_arr:
                if not isinstance(rev, dict):
                    continue
                for ph in rev.get("photos") or []:
                    if not isinstance(ph, dict):
                        continue
                    purl = ph.get("url") or ph.get("urlTemplate") or ph.get("href")
                    if not purl:
                        continue
                    out.append({"url": str(purl), "id": ph.get("id", "")})
            return out

        def _merge_review_photos_count(photos_batch: List[Dict[str, Any]]) -> None:
            if not photos_batch:
                return
            for p in photos_batch:
                if not isinstance(p, dict):
                    continue
                key = _photo_key(p) or str(p)
                if key in seen_photo_keys or key in review_only_photo_keys:
                    continue
                review_only_photo_keys.add(key)
            if review_only_photo_keys:
                data["photos_count"] = max(
                    int(data.get("photos_count") or 0),
                    len(accumulated_photos) + len(review_only_photo_keys),
                )

        def _merge_reviews(reviews_batch: List[Dict[str, Any]], source_payload: Any = None) -> None:
            if not reviews_batch:
                return
            for r in reviews_batch:
                if not isinstance(r, dict):
                    continue
                review_id = r.get("id") or r.get("review_id") or r.get("external_review_id")
                if review_id:
                    key = f"id:{review_id}"
                else:
                    key = (
                        f"{(r.get('author') or '').strip()}|"
                        f"{(r.get('date') or '').strip()}|"
                        f"{(r.get('text') or '').strip()[:120]}"
                    )
                if key in seen_review_keys:
                    continue
                seen_review_keys.add(key)
                accumulated_reviews.append(r)

            api_count = None
            if source_payload is not None:
                api_count = _pick_first(
                    source_payload,
                    [["data", "params", "count"], ["params", "count"], ["result", "params", "count"]],
                )
            try:
                api_count_int = int(api_count) if api_count is not None else 0
            except (TypeError, ValueError):
                api_count_int = 0

            data["reviews"] = accumulated_reviews
            data["reviews_count"] = max(len(accumulated_reviews), int(data.get("reviews_count") or 0), api_count_int)

        for url, response_info in self.api_responses.items():
            json_data = response_info['data']
            if 'location-info' in url:
                continue  # —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—ã—à–µ
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è fetchReviews API
            if 'fetchReviews' in url or 'reviews' in url.lower():
                if self.org_page:
                    url_bid = self._extract_business_id_from_url(url)
                    if url_bid and str(url_bid) != str(self.org_id):
                        self._identity_debug.setdefault("warnings", []).append("identity_mismatch:reviews_url_business")
                    else:
                        reviews = self._extract_reviews_from_api(json_data, url)
                        if reviews:
                            _merge_reviews(reviews, json_data)
                else:
                    reviews = self._extract_reviews_from_api(json_data, url)
                    if reviews:
                        _merge_reviews(reviews, json_data)
                review_photos = _extract_review_photos(json_data)
                if review_photos:
                    _merge_review_photos_count(review_photos)
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è fetchGoods/Prices API
            elif 'fetchGoods' in url or 'prices' in url.lower() or 'goods' in url.lower() or 'product' in url.lower() or 'search' in url.lower() or 'catalog' in url.lower():
                if self.org_page:
                    url_bid = self._extract_business_id_from_url(url)
                    if url_bid and str(url_bid) != str(self.org_id):
                        print(f"‚ö†Ô∏è [PRODUCTS] fetchGoods URL businessId={url_bid} != org_id={self.org_id}, ignore")
                        self._identity_debug.setdefault("warnings", []).append("identity_mismatch:products_url_business")
                    else:
                        products = self._extract_products_from_api(json_data)
                        if products:
                            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(products)} —É—Å–ª—É–≥/—Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ API –∑–∞–ø—Ä–æ—Å–∞")
                            current_products = data.get('products', [])
                            current_products.extend(products)
                            data['products'] = current_products
                else:
                    products = self._extract_products_from_api(json_data)
                    if products:
                        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(products)} —É—Å–ª—É–≥/—Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ API –∑–∞–ø—Ä–æ—Å–∞")
                        current_products = data.get('products', [])
                        current_products.extend(products)
                        data['products'] = current_products
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (org_api)
            elif self._is_organization_data(json_data):
                org_data = self._extract_organization_data(json_data)
                if org_data:
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ orgId –≤ –æ—Ç–≤–µ—Ç–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    resp_oid = _pick_first(json_data, [["data", "orgId"], ["orgId"], ["organizationId"], ["data", "organizationId"]])
                    if self.org_page and resp_oid and str(resp_oid) != str(self.org_id):
                        print(f"‚ö†Ô∏è [ORG_API] orgId –≤ –æ—Ç–≤–µ—Ç–µ={resp_oid} != org_id={self.org_id}, identity –Ω–µ –º–µ—Ä–¥–∂–∏–º")
                        self._identity_debug.setdefault("warnings", []).append("identity_mismatch:org_api_org_id")
                        for f in list(org_data.keys()):
                            if f in IDENTITY_FIELDS:
                                org_data.pop(f, None)
                    if org_data:
                        meta_src = {k: "org_api" for k in org_data if k not in ("meta",) and org_data.get(k)}
                        merge_non_empty(data, org_data, meta_src, source="org_api", org_page=self.org_page)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –æ—Ç–∑—ã–≤—ã (–æ–±—â–∏–π –ø–æ–∏—Å–∫)
            elif self._is_reviews_data(json_data):
                reviews = self._extract_reviews(json_data)
                if reviews:
                    _merge_reviews(reviews, json_data)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏/–ø–æ—Å—Ç—ã
            elif self._is_posts_data(json_data):
                posts = self._extract_posts(json_data)
                if posts:
                    data['news'] = posts

            # getByBusinessId ‚Äî org-bound —Ñ–æ—Ç–æ (id= –≤ URL)
            elif 'getByBusinessId' in url:
                if self.org_page:
                    url_bid = re.search(r'[?&]id=(\d+)', url)
                    url_bid = url_bid.group(1) if url_bid else None
                    if url_bid and str(url_bid) != str(self.org_id):
                        pass
                    else:
                        photos = self._extract_photos_from_api(json_data)
                        if photos:
                            _merge_photos(photos)
                            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(photos)} —Ñ–æ—Ç–æ –∏–∑ getByBusinessId")
                else:
                    photos = self._extract_photos_from_api(json_data)
                    if photos:
                        _merge_photos(photos)
                        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(photos)} —Ñ–æ—Ç–æ –∏–∑ getByBusinessId")
        
        # 2. –ï—Å–ª–∏ –ø—Ä–æ–¥—É–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ URL, –∏—â–µ–º –≤–æ –í–°–ï–• –æ—Ç–≤–µ—Ç–∞—Ö (Brute Force)
        if not data.get('products'):
            print("‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ URL —Ñ–∏–ª—å—Ç—Ä—É, –∏—â–µ–º –≤–æ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–∞—Ö...")
            for url, response_info in self.api_responses.items():
                try:
                    if self.org_page:
                        url_bid = self._extract_business_id_from_url(url)
                        if url_bid and str(url_bid) != str(self.org_id):
                            continue  # skip wrong business
                    json_data = response_info['data']
                    products = self._extract_products_from_api(json_data)
                    if products:
                        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(products)} —É—Å–ª—É–≥ –∏–∑ API (Brute Force): {url[-50:]}")
                        current_products = data.get('products', [])
                        current_products.extend(products)
                        data['products'] = current_products
                        break
                except Exception:
                    pass
        
        # Deduplicate products by name and price
        raw_services_count = 0
        if data.get('products'):
            raw_services_count = len(data['products'])
            self._debug_raw_services_count = raw_services_count
            unique_products = {}
            for p in data['products']:
                # Key: Name + Price (to distinguish "Haircut" 500 vs "Haircut" 1000)
                # Normalize name to lower case to catch case sensitivity issues
                key = (p.get('name', '').strip(), p.get('price', '').strip())
                if key not in unique_products:
                    unique_products[key] = p
            data['products'] = list(unique_products.values())
            unique_count = len(data['products'])
            print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—Å–ª—É–≥ –ø–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {unique_count}")
            print(f"[SERVICES_COUNT] raw_extracted={raw_services_count}, after_dedup={unique_count}")
            if raw_services_count != unique_count:
                print(f"[SERVICES_DUPLICATES] found {raw_services_count - unique_count} duplicates")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Ç—á–µ—Ç–æ–º)
        if data.get('products'):
            raw_products = data['products']
            grouped_products = {}
            for prod in raw_products:
                cat = prod.get('category', '–î—Ä—É–≥–æ–µ')
                if not cat:
                    cat = '–î—Ä—É–≥–æ–µ'
                if cat not in grouped_products:
                    grouped_products[cat] = []
                grouped_products[cat].append(prod)
            
            final_products = []
            for cat, items in grouped_products.items():
                final_products.append({
                    'category': cat,
                    'items': items
                })
            data['products'] = final_products

        # –†–µ–π—Ç–∏–Ω–≥: fallback –∏–∑ —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ –æ—Ç–∑—ã–≤–∞–º, –µ—Å–ª–∏ core –ø—É—Å—Ç–æ–π
        if not data.get('rating') or str(data.get('rating', '')).strip() in ('', '0', '0.0'):
            reviews = data.get('reviews') or []
            ratings = []
            for r in reviews:
                if isinstance(r, dict):
                    rt = r.get('rating') or r.get('score')
                    if rt is not None:
                        try:
                            ratings.append(float(rt))
                        except (ValueError, TypeError):
                            pass
            if ratings:
                avg = sum(ratings) / len(ratings)
                data['rating'] = str(round(avg, 1))
                print(f"‚úÖ –†–µ–π—Ç–∏–Ω–≥ –∏–∑ –æ—Ç–∑—ã–≤–æ–≤: {data['rating']} (n={len(ratings)})")
        
        # –°–æ–∑–¥–∞–µ–º overview
        overview_keys = [
            'title', 'address', 'phone', 'site', 'description',
            'rubric', 'categories', 'hours', 'hours_full', 'rating', 
            'ratings_count', 'reviews_count', 'social_links'
        ]
        data['overview'] = {k: data.get(k, '') for k in overview_keys}
        data['overview']['reviews_count'] = data.get('reviews_count', 0)

        reviews_count = len(data.get('reviews', []))
        print(f"[REVIEWS_COUNT] extracted={reviews_count}")
        if reviews_count < 50:
            print(f"[REVIEWS_MISSING] possible pagination or filtering issue (count={reviews_count})")
        
        return data
    
    def _is_organization_data(self, json_data: Any) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ JSON –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"""
        if not isinstance(json_data, dict):
            return False
        
        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        org_fields = ['name', 'title', 'address', 'rating', 'orgId', 'organizationId', 'company']
        return any(field in json_data for field in org_fields) or \
               any(isinstance(v, dict) and any(f in v for f in org_fields) for v in json_data.values() if isinstance(v, dict))
    
    def _extract_search_api_data(self, json_data: Any) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ search API"""
        result = {}
        
        def extract_nested(data):
            if isinstance(data, dict):
                # –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö
                if 'data' in data and isinstance(data['data'], dict):
                    data = data['data']
                
                if 'result' in data and isinstance(data['result'], dict):
                    data = data['result']
                
                # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                title_cand = ''
                if 'name' in data:
                    title_cand = data['name']
                elif 'title' in data:
                    title_cand = data['title']
                
                # Filter out generic toponyms
                if title_cand and title_cand not in ['–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–†–æ—Å—Å–∏—è', '–Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã', '–ú–æ—Å–∫–≤–∞']:
                    result['title'] = title_cand
                
                # –ò—â–µ–º –∞–¥—Ä–µ—Å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á + –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤)
                addr_val = None
                if 'address' in data:
                    addr = data['address']
                    if isinstance(addr, dict):
                        addr_val = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
                    else:
                        addr_val = str(addr)
                if not addr_val:
                    addr_val = data.get('address_name') or data.get('fullAddress') or data.get('full_address') or ''
                if addr_val and isinstance(addr_val, str) and len(addr_val.strip()) > 2:
                    _set_if_empty(result, "address", addr_val.strip())
                
                # –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                if 'rating' in data:
                    rating = data['rating']
                    if isinstance(rating, (int, float)):
                        _set_if_empty(result, "rating", str(rating))
                    elif isinstance(rating, dict):
                        _set_if_empty(
                            result,
                            "rating",
                            str(rating.get('value', rating.get('score', rating.get('val', '')))),
                        )
                elif 'score' in data:
                    _set_if_empty(result, "rating", str(data['score']))
                
                # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
                if 'reviewsCount' in data:
                    try:
                        _set_if_empty(result, "reviews_count", int(data['reviewsCount']))
                    except (TypeError, ValueError):
                        pass
                elif 'reviews_count' in data:
                    try:
                        _set_if_empty(result, "reviews_count", int(data['reviews_count']))
                    except (TypeError, ValueError):
                        pass
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                for value in data.values():
                    if isinstance(value, (dict, list)):
                        extract_nested(value)
        
        extract_nested(json_data)
        return result
    
    def _extract_from_html_fallback(self, page) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç title/address –∏–∑ HTML (og:title, page title, h1).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–µ—Ä–¥–∂–∏—Ç—Å—è –≤ final, —Ç–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω—è—è –ø—É—Å—Ç—ã–µ —Å–ª–æ—Ç—ã.
        """
        out: Dict[str, Any] = {}
        try:
            og_title = page.locator("meta[property='og:title']").get_attribute("content")
            if og_title:
                out["og_title"] = og_title
                clean = og_title.replace(" ‚Äî –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").replace(" - –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").split("|")[0].split(",")[0].strip()
                t = clean or og_title.split("|")[0].strip()
                if t:
                    out["title_or_name"] = t
                    out["title"] = t
                    print(f"‚úÖ [HTML_FALLBACK] og:title -> {t[:50]}")
            if not out.get("title"):
                pt = page.title()
                if pt:
                    out["page_title"] = pt
                    t = pt.replace(" ‚Äî –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").replace(" - –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").split("|")[0].split("-")[0].strip()
                    if t:
                        out["title_or_name"] = t
                        out["title"] = t
                        print(f"‚úÖ [HTML_FALLBACK] page_title -> {t[:50]}")
            if not out.get("title"):
                h1 = page.query_selector("div.orgpage-header-view__header-wrapper > h1, h1.orgpage-header-view__header")
                if h1:
                    t = h1.inner_text().strip()
                    if t:
                        out["title_or_name"] = t
                        out["title"] = t
                        print(f"‚úÖ [HTML_FALLBACK] h1 -> {t[:50]}")
            # –ê–¥—Ä–µ—Å (–∫–æ—Ä–æ—Ç–∫–∏–π —Ç–∞–π–º–∞—É—Ç ‚Äî meta –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º og:title)
            meta_addr = None
            try:
                loc = page.locator("meta[property='business:contact_data:street_address']")
                loc.set_default_timeout(2000)
                meta_addr = loc.get_attribute("content")
            except Exception:
                pass
            if meta_addr:
                out["address"] = meta_addr
            elif not out.get("address"):
                addr_el = page.query_selector("div.orgpage-header-view__address, a.orgpage-header-view__address, div.business-contacts-view__address-link")
                if addr_el:
                    out["address"] = addr_el.inner_text().strip()
        except Exception as e:
            print(f"‚ö†Ô∏è [HTML_FALLBACK] error: {e}")
        return out

    def _extract_search_api_business(self, json_data: Any) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –±–∏–∑–Ω–µ—Å–∞ –∏–∑ search API (business_oid=...).
        –í—ã–±–∏—Ä–∞–µ—Ç item, –≥–¥–µ id/oid/businessOid —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å self.org_id.
        –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π result (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º search API).
        """
        result: Dict[str, Any] = {}
        expected_oid = self.org_id
        items = _pick_first(json_data, [["data", "items"], ["items"]])
        if not isinstance(items, list) or not items:
            return result

        # –ù–∞–π—Ç–∏ item —Å —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º org_id (id, oid, businessOid, uri oid=)
        def _item_oid(it: Any) -> Optional[str]:
            if not isinstance(it, dict):
                return None
            oid = it.get("id") or it.get("oid") or it.get("businessOid")
            if oid is not None:
                return str(oid)
            uri = it.get("uri") or ""
            if isinstance(uri, str) and "oid=" in uri:
                m = re.search(r"oid=(\d+)", uri)
                if m:
                    return m.group(1)
            return None

        item = None
        matched_key = None
        selected_index = -1
        for i, it in enumerate(items):
            oid = _item_oid(it)
            if oid and expected_oid and str(oid) == str(expected_oid):
                item = it
                selected_index = i
                if it.get("id") is not None and str(it.get("id")) == str(expected_oid):
                    matched_key = "id"
                elif it.get("oid") is not None and str(it.get("oid")) == str(expected_oid):
                    matched_key = "oid"
                elif it.get("businessOid") is not None and str(it.get("businessOid")) == str(expected_oid):
                    matched_key = "businessOid"
                else:
                    matched_key = "uri"
                break

        if not item or not isinstance(item, dict):
            return result

        # meta –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–ª–µ–π
        meta_src: Dict[str, str] = {}
        BLACKLIST = ("–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–†–æ—Å—Å–∏—è", "–Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "–ú–æ—Å–∫–≤–∞")
        title = item.get("title") or item.get("shortTitle") or item.get("name")
        if title and str(title).strip() not in BLACKLIST:
            result["title"] = str(title).strip()
            result["title_or_name"] = result["title"]
            meta_src["title"] = meta_src["title_or_name"] = "search_api"
        addr = item.get("fullAddress") or item.get("address")
        if addr and isinstance(addr, str) and len(addr.strip()) > 2:
            result["address"] = addr.strip()
            meta_src["address"] = "search_api"
        if item.get("categories"):
            cats = []
            for c in item["categories"]:
                if isinstance(c, dict) and c.get("name"):
                    cats.append(str(c["name"]))
                elif isinstance(c, str):
                    cats.append(c)
            if cats:
                result["categories"] = cats
                meta_src["categories"] = "search_api"
        rd = item.get("ratingData")
        if isinstance(rd, dict):
            rv = rd.get("ratingValue") or rd.get("rating") or rd.get("value")
            if rv is not None and rv != 0:
                result["rating"] = str(rv)
                meta_src["rating"] = "search_api"
            rc = rd.get("reviewCount") or rd.get("reviewsCount") or rd.get("count")
            if rc is not None:
                try:
                    result["reviews_count"] = int(rc)
                    meta_src["reviews_count"] = "search_api"
                except (TypeError, ValueError):
                    pass
        # Fallback: –∏–Ω–æ–≥–¥–∞ —Ä–µ–π—Ç–∏–Ω–≥ –ª–µ–∂–∏—Ç –≤ modularPin.subtitleHints[].text, –Ω–∞–ø—Ä–∏–º–µ—Ä "4.8"
        if not result.get("rating"):
            subtitle_hints = _pick_first(item, [["modularPin", "subtitleHints"]])
            if isinstance(subtitle_hints, list):
                for hint in subtitle_hints:
                    if not isinstance(hint, dict):
                        continue
                    text_val = str(hint.get("text") or "").strip()
                    hint_type = str(hint.get("type") or "").upper()
                    if not text_val:
                        continue
                    if hint_type != "RATING" and not re.search(r"\b[0-5][\.,]\d\b", text_val):
                        continue
                    m = re.search(r"\b([0-5][\.,]\d)\b", text_val)
                    if m:
                        result["rating"] = m.group(1).replace(",", ".")
                        meta_src["rating"] = "search_api"
                        break
        # org-centric: phones, urls, hours –∏–∑ search API (org-bound, –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –∫–∞—Ä—Ç—ã)
        phones = item.get("phones")
        if isinstance(phones, list) and phones:
            p0 = phones[0]
            if isinstance(p0, dict):
                phone_val = p0.get("number") or p0.get("formatted") or p0.get("value")
            else:
                phone_val = str(p0)
            if phone_val:
                result["phone"] = str(phone_val).strip()
                meta_src["phone"] = "search_api"
        urls = item.get("urls")
        if isinstance(urls, list) and urls:
            site_val = urls[0] if isinstance(urls[0], str) else None
            if site_val:
                result["site"] = str(site_val).strip()
                meta_src["site"] = "search_api"
        hours_text = item.get("workingTimeText")
        if hours_text and isinstance(hours_text, str) and hours_text.strip():
            result["hours"] = hours_text.strip()
            meta_src["hours"] = "search_api"
        working_time = item.get("workingTime")
        if isinstance(working_time, list) and working_time:
            result["hours_full"] = working_time
            if "hours" not in result and hours_text:
                result["hours"] = hours_text.strip()
        result["meta"] = meta_src
        result["_search_debug"] = {
            "items_count": len(items),
            "selected_index": selected_index,
            "matched_key": matched_key,
            "expected_oid": expected_oid,
        }
        return result

    def _extract_location_info(self, json_data: Any) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ location-info API.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç _pick_first —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏ –∏–∑ JSON.
        location-info: data.toponymSearchResult.items[0].title (–≥–æ—Ä–æ–¥), –±–∏–∑–Ω–µ—Å –≤ showcase.
        search API ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è org-—Å—Ç—Ä–∞–Ω–∏—Ü.
        """
        result = {}
        BLACKLIST = ("–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–†–æ—Å—Å–∏—è", "–Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "–ú–æ—Å–∫–≤–∞")

        # –ü—Ä—è–º—ã–µ –ø—É—Ç–∏ –∏–∑ location-info (–ø–æ —Ä–µ–∞–ª—å–Ω—ã–º bundle)
        title = _pick_first(json_data, [
            ["data", "toponymSearchResult", "items", "0", "toponymDiscovery", "categories", "0", "showcase", "0", "title"],
            ["data", "toponymSearchResult", "exactResult", "toponymDiscovery", "categories", "0", "showcase", "0", "title"],
            ["data", "toponymSearchResult", "items", "0", "title"],
            ["data", "toponymSearchResult", "exactResult", "title"],
        ])
        if title and str(title).strip() not in BLACKLIST:
            result["title"] = str(title).strip()
            result["title_or_name"] = result["title"]

        addr = _pick_first(json_data, [
            ["data", "toponymSearchResult", "items", "0", "toponymDiscovery", "categories", "0", "showcase", "0", "fullAddress"],
            ["data", "toponymSearchResult", "items", "0", "toponymDiscovery", "categories", "0", "showcase", "0", "address"],
            ["data", "toponymSearchResult", "items", "0", "fullAddress"],
            ["data", "toponymSearchResult", "items", "0", "address"],
            ["data", "toponymSearchResult", "exactResult", "address"],
        ])
        if addr and isinstance(addr, str) and len(addr.strip()) > 2 and addr.strip() not in BLACKLIST:
            result["address"] = addr.strip()

        # ratingData –∏–∑ showcase
        rd = _pick_first(json_data, [
            ["data", "toponymSearchResult", "items", "0", "toponymDiscovery", "categories", "0", "showcase", "0", "ratingData"],
            ["data", "toponymSearchResult", "items", "0", "ratingData"],
        ])
        if isinstance(rd, dict):
            rv = rd.get("ratingValue") or rd.get("rating") or rd.get("value")
            if rv is not None:
                result["rating"] = str(rv)
            rc = rd.get("reviewCount") or rd.get("reviewsCount") or rd.get("count")
            if rc is not None:
                try:
                    result["reviews_count"] = int(rc)
                except (TypeError, ValueError):
                    pass

        def extract_nested(data):
            if isinstance(data, dict):
                # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                title_cand = ''
                if 'name' in data:
                    title_cand = data['name']
                elif 'title' in data:
                    title_cand = data['title']
                
                # Filter out generic toponyms
                if title_cand:
                    if title_cand in ['–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–†–æ—Å—Å–∏—è', '–Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã', '–ú–æ—Å–∫–≤–∞']:
                        # print(f"‚ö†Ô∏è [Parser] Ignored title '{title_cand}' (in blacklist)") 
                        pass # Don't spam, but we skip it
                    else:
                        # print(f"‚úÖ [Parser] Found title: {title_cand}")
                        result['title'] = title_cand
                
                # –ò—â–µ–º –∞–¥—Ä–µ—Å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á + –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤)
                addr_val = None
                if 'address' in data:
                    addr = data['address']
                    if isinstance(addr, dict):
                        addr_val = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
                    else:
                        addr_val = str(addr)
                if not addr_val:
                    addr_val = data.get('address_name') or data.get('fullAddress') or data.get('full_address') or ''
                if addr_val and isinstance(addr_val, str) and len(addr_val.strip()) > 2:
                    result['address'] = addr_val.strip()
                
                # –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                if 'rating' in data:
                    rating = data['rating']
                    if isinstance(rating, (int, float)):
                        result['rating'] = str(rating)
                    elif isinstance(rating, dict):
                        result['rating'] = str(rating.get('value', rating.get('score', '')))
                
                # Fallback rating
                elif 'score' in data:
                     result['rating'] = str(data['score'])

                # –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥ –≤–Ω—É—Ç—Ä–∏ ratingData (—á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç –≤ location-info)
                elif 'ratingData' in data:
                    rd = data['ratingData']
                    if isinstance(rd, dict):
                         val = rd.get('rating') or rd.get('value') or rd.get('score')
                         if val: result['rating'] = str(val)
                         
                         count = rd.get('count') or rd.get('reviewCount')
                         if count: result['reviews_count'] = int(count)
                
                # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
                if 'reviewsCount' in data:
                    result['reviews_count'] = int(data['reviewsCount'])
                elif 'reviews_count' in data:
                    result['reviews_count'] = int(data['reviews_count'])
                
                # –ò—â–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ / —Ä—É–±—Ä–∏–∫–∏
                if 'rubrics' in data and isinstance(data['rubrics'], list):
                    names = []
                    for r in data['rubrics']:
                        if isinstance(r, dict):
                            n = r.get('name') or r.get('label')
                            if n:
                                names.append(str(n))
                    if names:
                        result['categories'] = names
                elif 'categories' in data:
                    cats = data['categories']
                    if isinstance(cats, list) and cats:
                        # –£–∂–µ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏–ª–∏ –æ–±—ä–µ–∫—Ç–æ–≤
                        result['categories'] = cats
                    elif isinstance(cats, dict) and cats:
                        result['categories'] = [cats]
                elif 'rubric' in data:
                    rub = data['rubric']
                    if isinstance(rub, str) and rub.strip():
                        result['categories'] = [rub.strip()]
                    elif isinstance(rub, dict):
                        n = rub.get('name') or rub.get('label')
                        if n:
                            result['categories'] = [str(n)]
                
                # –ò—â–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ / —Ä—É–±—Ä–∏–∫–∏
                if 'rubrics' in data and isinstance(data['rubrics'], list):
                    names = []
                    for r in data['rubrics']:
                        if isinstance(r, dict):
                            n = r.get('name') or r.get('label')
                            if n:
                                names.append(str(n))
                    if names:
                        _extend_unique(result, 'categories', names)
                elif 'categories' in data:
                    cats = data['categories']
                    if isinstance(cats, list) and cats:
                        _extend_unique(result, 'categories', cats)
                    elif isinstance(cats, dict) and cats:
                        _extend_unique(result, 'categories', [cats])
                elif 'rubric' in data:
                    rub = data['rubric']
                    if isinstance(rub, str) and rub.strip():
                        _extend_unique(result, 'categories', [rub.strip()])
                    elif isinstance(rub, dict):
                        n = rub.get('name') or rub.get('label')
                        if n:
                            _extend_unique(result, 'categories', [str(n)])
                
                # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω
                if 'phones' in data:
                    phones = data['phones']
                    if isinstance(phones, list) and phones:
                        phone_obj = phones[0]
                        if isinstance(phone_obj, dict):
                            result['phone'] = phone_obj.get('formatted', '') or phone_obj.get('number', '')
                        else:
                            result['phone'] = str(phone_obj)
                    elif isinstance(phones, dict):
                        result['phone'] = phones.get('formatted', '') or phones.get('number', '')
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                for value in data.values():
                    extract_nested(value)
        
        extract_nested(json_data)

        # Fallback –ø–æ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –ø—É—Ç—è–º (payload.company.*)
        try:
            addr_nested = (
                _get_nested(json_data, "payload.company.address.formatted")
                or _get_nested(json_data, "payload.company.address_name")
                or _get_nested(json_data, "payload.company.fullAddress")
            )
            _set_if_empty(result, "address", addr_nested)
        except Exception:
            pass

        try:
            rating_nested = (
                _get_nested(json_data, "payload.company.ratingData.rating")
                or _get_nested(json_data, "payload.company.ratingData.score")
            )
            _set_if_empty(result, "rating", rating_nested)
        except Exception:
            pass

        try:
            cnt = _get_nested(json_data, "payload.company.ratingData.count")
            if isinstance(cnt, (int, float, str)):
                try:
                    cnt_int = int(cnt)
                    _set_if_empty(result, "reviews_count", cnt_int)
                except ValueError:
                    pass
        except Exception:
            pass

        try:
            rubrics = _get_nested(json_data, "payload.company.rubrics") or []
            names = []
            if isinstance(rubrics, list):
                for r in rubrics:
                    if isinstance(r, dict):
                        n = r.get("name") or r.get("label")
                        if n:
                            names.append(str(n))
            if names:
                _extend_unique(result, "categories", names)
        except Exception:
            pass

        return result
    
    def _extract_organization_data(self, json_data: Any) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ JSON"""
        result = {}
        
        def extract_nested(data, path=''):
            """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
            if isinstance(data, dict):
                # –ü—Ä—è–º—ã–µ –ø–æ–ª—è
                if 'name' in data or 'title' in data:
                    result['title'] = data.get('name') or data.get('title', '')
                
                # –ê–¥—Ä–µ—Å: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á + –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã (—Ä–∞–∑–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –Ø–Ω–¥–µ–∫—Å–∞)
                addr_val = None
                if 'address' in data:
                    addr = data['address']
                    if isinstance(addr, dict):
                        addr_val = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
                    else:
                        addr_val = str(addr)
                if not addr_val and 'address_name' in data:
                    addr_val = data.get('address_name') or ''
                if not addr_val and 'fullAddress' in data:
                    addr_val = data.get('fullAddress') or ''
                if not addr_val and 'full_address' in data:
                    addr_val = data.get('full_address') or ''
                if addr_val and isinstance(addr_val, str) and len(addr_val.strip()) > 2:
                    _set_if_empty(result, "address", addr_val.strip())
                
                if 'rating' in data:
                    rating = data['rating']
                    if isinstance(rating, (int, float)):
                        _set_if_empty(result, "rating", str(rating))
                    elif isinstance(rating, dict):
                         _set_if_empty(
                             result,
                             "rating",
                             str(rating.get('value', rating.get('score', rating.get('val', '')))),
                         )
                elif 'score' in data:
                    _set_if_empty(result, "rating", str(data['score']))
                
                # Support modularPin rating (Yandex Update)
                if 'modularPin' in data and isinstance(data['modularPin'], dict):
                    hints = data['modularPin'].get('subtitleHints', [])
                    for hint in hints:
                        if hint.get('type') == 'RATING':
                             result['rating'] = str(hint.get('text', ''))
                             break
                
                if 'reviewsCount' in data or 'reviews_count' in data:
                    try:
                        _set_if_empty(
                            result,
                            "reviews_count",
                            int(data.get('reviewsCount') or data.get('reviews_count', 0)),
                        )
                    except (TypeError, ValueError):
                        pass
                
                if 'phones' in data:
                    phones = data['phones']
                    if isinstance(phones, list) and phones:
                        result['phone'] = phones[0].get('formatted', '') or phones[0].get('number', '')
                    elif isinstance(phones, dict):
                        result['phone'] = phones.get('formatted', '') or phones.get('number', '')
                
                if 'site' in data or 'website' in data:
                    result['site'] = data.get('site') or data.get('website', '')
                
                if 'description' in data or 'about' in data:
                    result['description'] = data.get('description') or data.get('about', '')
                
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ / —Ä—É–±—Ä–∏–∫–∏
                if 'rubrics' in data and isinstance(data['rubrics'], list):
                    names = []
                    for r in data['rubrics']:
                        if isinstance(r, dict):
                            n = r.get('name') or r.get('label')
                            if n:
                                names.append(str(n))
                    if names:
                        _extend_unique(result, 'categories', names)
                elif 'categories' in data:
                    cats = data['categories']
                    if isinstance(cats, list) and cats:
                        _extend_unique(result, 'categories', cats)
                    elif isinstance(cats, dict) and cats:
                        _extend_unique(result, 'categories', [cats])
                elif 'rubric' in data:
                    rub = data['rubric']
                    if isinstance(rub, str) and rub.strip():
                        _extend_unique(result, 'categories', [rub.strip()])
                    elif isinstance(rub, dict):
                        n = rub.get('name') or rub.get('label')
                        if n:
                            _extend_unique(result, 'categories', [str(n)])
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                for key, value in data.items():
                    extract_nested(value, f"{path}.{key}")
            
            elif isinstance(data, list):
                for item in data:
                    extract_nested(item, path)
        
        extract_nested(json_data)

        # Fallback –ø–æ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –ø—É—Ç—è–º (payload.company.*)
        try:
            addr_nested = (
                _get_nested(json_data, "payload.company.address.formatted")
                or _get_nested(json_data, "payload.company.address_name")
                or _get_nested(json_data, "payload.company.fullAddress")
            )
            _set_if_empty(result, "address", addr_nested)
        except Exception:
            pass

        try:
            rating_nested = (
                _get_nested(json_data, "payload.company.ratingData.rating")
                or _get_nested(json_data, "payload.company.ratingData.score")
            )
            _set_if_empty(result, "rating", rating_nested)
        except Exception:
            pass

        try:
            cnt = _get_nested(json_data, "payload.company.ratingData.count")
            if isinstance(cnt, (int, float, str)):
                try:
                    cnt_int = int(cnt)
                    _set_if_empty(result, "reviews_count", cnt_int)
                except ValueError:
                    pass
        except Exception:
            pass

        try:
            rubrics = _get_nested(json_data, "payload.company.rubrics") or []
            names = []
            if isinstance(rubrics, list):
                for r in rubrics:
                    if isinstance(r, dict):
                        n = r.get("name") or r.get("label")
                        if n:
                            names.append(str(n))
            if names:
                _extend_unique(result, "categories", names)
        except Exception:
            pass

        return result
    
    def _is_reviews_data(self, json_data: Any) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ JSON –¥–∞–Ω–Ω—ã–µ –æ–± –æ—Ç–∑—ã–≤–∞—Ö"""
        if not isinstance(json_data, dict):
            return False
        
        review_fields = ['reviews', 'items', 'feedback', 'comments']
        return any(field in json_data for field in review_fields) or \
               (isinstance(json_data, list) and len(json_data) > 0 and isinstance(json_data[0], dict) and 
                any(k in json_data[0] for k in ['text', 'comment', 'rating', 'author']))
    
    def _extract_reviews_from_api(self, json_data: Any, url: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Ç–∑—ã–≤—ã –∏–∑ API –∑–∞–ø—Ä–æ—Å–∞ fetchReviews (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç)"""
        reviews = []
        
        def extract_review_item(item: dict) -> Optional[Dict[str, Any]]:
            """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–¥–∏–Ω –æ—Ç–∑—ã–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã API"""
            if not isinstance(item, dict):
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞
            author_name = ''
            if 'author' in item:
                author = item['author']
                if isinstance(author, dict):
                    author_name = author.get('name') or author.get('displayName') or author.get('username', '')
                else:
                    author_name = str(author)
            else:
                author_name = item.get('authorName', item.get('author_name', ''))
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥ (–º–æ–∂–µ—Ç –±—ã—Ç—å —á–∏—Å–ª–æ–º –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–π)
            rating = item.get('rating') or item.get('score') or item.get('grade') or item.get('stars')
            if rating:
                # –ï—Å–ª–∏ —ç—Ç–æ —á–∏—Å–ª–æ, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                if isinstance(rating, (int, float)):
                    rating = str(rating)
                else:
                    rating = str(rating)
            else:
                rating = ''
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            text = item.get('text') or item.get('comment') or item.get('message') or item.get('content', '')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö)
            date_fields = [
                'date', 'publishedAt', 'published_at', 'createdAt', 'created_at',
                'time', 'timestamp', 'created', 'published',
                'dateCreated', 'datePublished', 'reviewDate', 'review_date',
                'updatedTime'
            ]
            date_raw = next((item.get(field) for field in date_fields if item.get(field)), None)

            date = ''
            if date_raw:
                # –ï—Å–ª–∏ —ç—Ç–æ timestamp (—á–∏—Å–ª–æ)
                if isinstance(date_raw, (int, float)):
                    try:
                        from datetime import datetime
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ —Å–µ–∫—É–Ω–¥–∞—Ö
                        if date_raw > 1e10:  # –í–µ—Ä–æ—è—Ç–Ω–æ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                            date = datetime.fromtimestamp(date_raw / 1000.0).isoformat()
                        else:  # –°–µ–∫—É–Ω–¥—ã
                            date = datetime.fromtimestamp(date_raw).isoformat()
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ timestamp {date_raw}: {e}")
                        date = str(date_raw)
                # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ ISO —Ñ–æ—Ä–º–∞—Ç–∞
                elif isinstance(date_raw, str):
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ ISO
                    try:
                        from datetime import datetime
                        # –£–±–∏—Ä–∞–µ–º Z –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ +00:00
                        date_clean = date_raw.replace('Z', '+00:00')
                        datetime.fromisoformat(date_clean)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                        date = date_clean
                    except:
                        # –ï—Å–ª–∏ –Ω–µ ISO, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–±—É–¥–µ—Ç –ø–∞—Ä—Å–∏—Ç—å—Å—è –≤ worker.py)
                        date = date_raw
                else:
                    date = str(date_raw)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–∞—Ç—É –æ—Ç–∑—ã–≤–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 5 –æ—Ç–∑—ã–≤–æ–≤)
            if date and len(reviews) < 5:
                print(f"üìÖ –î–∞—Ç–∞ –æ—Ç–∑—ã–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∞: {date}")
            elif not date and len(reviews) < 5:
                print(f"‚ö†Ô∏è –î–∞—Ç–∞ –æ—Ç–∑—ã–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª—è: {list(item.keys())}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã)
            response_text = None
            response_date = None
            owner_comment = (
                item.get('businessComment') or
                item.get('business_comment') or
                item.get('ownerComment') or 
                item.get('owner_comment') or 
                item.get('response') or 
                item.get('reply') or
                item.get('organizationResponse') or
                item.get('organization_response') or
                item.get('companyResponse') or
                item.get('company_response') or
                item.get('ownerResponse') or
                item.get('owner_response') or
                item.get('answer') or
                item.get('answers')  # –ú–æ–∂–µ—Ç –±—ã—Ç—å –º–∞—Å—Å–∏–≤
            )
            
            if owner_comment:
                if isinstance(owner_comment, list) and len(owner_comment) > 0:
                    # –ï—Å–ª–∏ —ç—Ç–æ –º–∞—Å—Å–∏–≤, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–µ–ø—É—Å—Ç–æ–π —ç–ª–µ–º–µ–Ω—Ç
                    first_non_empty = None
                    for candidate in owner_comment:
                        if not candidate:
                            continue
                        if isinstance(candidate, dict):
                            if any(candidate.get(k) for k in ("text", "comment", "message", "content")):
                                first_non_empty = candidate
                                break
                        else:
                            candidate_text = str(candidate).strip()
                            if candidate_text and candidate_text.lower() not in ("none", "null"):
                                first_non_empty = candidate
                                break
                    owner_comment = first_non_empty if first_non_empty is not None else owner_comment[0]
                
                if isinstance(owner_comment, dict):
                    response_text = (
                        owner_comment.get('text') or 
                        owner_comment.get('comment') or 
                        owner_comment.get('message') or
                        owner_comment.get('content') or
                        str(owner_comment)
                    )
                    response_date = (
                        owner_comment.get('date') or 
                        owner_comment.get('createdAt') or
                        owner_comment.get('created_at') or
                        owner_comment.get('publishedAt') or
                        owner_comment.get('published_at')
                    )
                    if response_text:
                        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: {response_text[:100]}...")
                else:
                    response_text = str(owner_comment)
                    if response_text:
                        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (—Å—Ç—Ä–æ–∫–∞): {response_text[:100]}...")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–∞—Ç—É –æ—Ç–∑—ã–≤–∞
            if date:
                print(f"üìÖ –î–∞—Ç–∞ –æ—Ç–∑—ã–≤–∞: {date}")
            
            if text:
                review_id = (
                    item.get('id') or
                    item.get('reviewId') or
                    item.get('review_id') or
                    item.get('uuid')
                )
                review_data = {
                    'id': str(review_id) if review_id is not None else None,
                    'author': author_name or '–ê–Ω–æ–Ω–∏–º–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å',
                    'rating': rating,
                    'text': text,
                    'date': date,
                    'org_reply': response_text,  # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞ org_reply –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å worker.py
                    'response_text': response_text,  # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    'response_date': response_date,
                    'has_response': bool(response_text)
                }
                if response_text:
                    print(f"‚úÖ –û—Ç–∑—ã–≤ —Å –æ—Ç–≤–µ—Ç–æ–º: –∞–≤—Ç–æ—Ä={author_name}, —Ä–µ–π—Ç–∏–Ω–≥={rating}, –æ—Ç–≤–µ—Ç={response_text[:50]}...")
                return review_data
            return None
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –º–∞—Å—Å–∏–≤ –æ—Ç–∑—ã–≤–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö
        if isinstance(json_data, dict):
            # –í–∞—Ä–∏–∞–Ω—Ç 1: –ø—Ä—è–º–æ–π –º–∞—Å—Å–∏–≤ –≤ –∫–ª—é—á–µ reviews
            if 'reviews' in json_data and isinstance(json_data['reviews'], list):
                for item in json_data['reviews']:
                    review = extract_review_item(item)
                    if review:
                        reviews.append(review)
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –≤ data.reviews
            elif 'data' in json_data and isinstance(json_data['data'], dict):
                if 'reviews' in json_data['data'] and isinstance(json_data['data']['reviews'], list):
                    for item in json_data['data']['reviews']:
                        review = extract_review_item(item)
                        if review:
                            reviews.append(review)
            
            # –í–∞—Ä–∏–∞–Ω—Ç 3: –≤ result.reviews
            elif 'result' in json_data and isinstance(json_data['result'], dict):
                if 'reviews' in json_data['result'] and isinstance(json_data['result']['reviews'], list):
                    for item in json_data['result']['reviews']:
                        review = extract_review_item(item)
                        if review:
                            reviews.append(review)
            
            # –í–∞—Ä–∏–∞–Ω—Ç 4: –≤ items
            elif 'items' in json_data and isinstance(json_data['items'], list):
                for item in json_data['items']:
                    review = extract_review_item(item)
                    if review:
                        reviews.append(review)
            
            # –í–∞—Ä–∏–∞–Ω—Ç 5: —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
            else:
                for key, value in json_data.items():
                    if isinstance(value, list) and len(value) > 0:
                        if isinstance(value[0], dict) and any(k in value[0] for k in ['text', 'comment', 'rating', 'author']):
                            for item in value:
                                review = extract_review_item(item)
                                if review:
                                    reviews.append(review)
        
        elif isinstance(json_data, list):
            # –ï—Å–ª–∏ —Å–∞–º JSON - —ç—Ç–æ –º–∞—Å—Å–∏–≤ –æ—Ç–∑—ã–≤–æ–≤
            for item in json_data:
                review = extract_review_item(item)
                if review:
                    reviews.append(review)
        
        return reviews
    
    def _extract_reviews(self, json_data: Any) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Ç–∑—ã–≤—ã –∏–∑ JSON (–æ–±—â–∏–π –º–µ—Ç–æ–¥)"""
        reviews = []
        
        def find_reviews(data):
            if isinstance(data, dict):
                # –ò—â–µ–º –º–∞—Å—Å–∏–≤ –æ—Ç–∑—ã–≤–æ–≤
                for key in ['reviews', 'items', 'feedback', 'comments']:
                    if key in data and isinstance(data[key], list):
                        for item in data[key]:
                            if isinstance(item, dict):
                                review = {
                                    'author': item.get('author', {}).get('name', '') if isinstance(item.get('author'), dict) else item.get('author', ''),
                                    'rating': str(item.get('rating', item.get('score', ''))),
                                    'text': item.get('text', item.get('comment', item.get('message', ''))),
                                    'date': item.get('date', item.get('createdAt', ''))
                                }
                                if review['text']:
                                    reviews.append(review)
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                for value in data.values():
                    find_reviews(value)
            
            elif isinstance(data, list):
                for item in data:
                    find_reviews(item)
        
        find_reviews(json_data)
        return reviews
    
    def _is_posts_data(self, json_data: Any) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ JSON –¥–∞–Ω–Ω—ã–µ –æ –ø–æ—Å—Ç–∞—Ö/–Ω–æ–≤–æ—Å—Ç—è—Ö (getPosts: data.items)"""
        if not isinstance(json_data, dict):
            return False
        post_fields = ['posts', 'publications', 'news', 'items']
        if any(field in json_data for field in post_fields):
            return True
        # getPosts: {"data": {"count": 7, "items": [...]}}
        inner = json_data.get("data")
        if isinstance(inner, dict) and any(f in inner for f in post_fields):
            return True
        return False
    
    def _extract_posts(self, json_data: Any) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å—Ç—ã/–Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ JSON"""
        posts = []
        
        def find_posts(data):
            if isinstance(data, dict):
                for key in ['posts', 'publications', 'news', 'items']:
                    if key in data and isinstance(data[key], list):
                        # LOGGING STRUCTURE
                        if len(data[key]) > 0:
                            item0 = data[key][0]
                            if isinstance(item0, dict):
                                print(f"üîç DEBUG POSTS: Found list in '{key}', Item keys: {list(item0.keys())}")

                        for item in data[key]:
                            if isinstance(item, dict):
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö)
                                date_fields = [
                                    'date', 'publishedAt', 'published_at', 'createdAt', 'created_at',
                                    'publicationTime', 'time', 'timestamp', 'created', 'published',
                                    'dateCreated', 'datePublished', 'updatedTime'
                                ]
                                
                                date_raw = None
                                for field in date_fields:
                                    val = item.get(field)
                                    if val:
                                        date_raw = val
                                        break
                                
                                # Fallback: check for nested date object (e.g. date: { value: ... })
                                if not date_raw and isinstance(item.get('date'), dict):
                                    date_raw = item.get('date').get('value')

                                date = ''
                                if date_raw:
                                    # –ï—Å–ª–∏ —ç—Ç–æ timestamp (—á–∏—Å–ª–æ)
                                    if isinstance(date_raw, (int, float)):
                                        try:
                                            from datetime import datetime
                                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ —Å–µ–∫—É–Ω–¥–∞—Ö
                                            if date_raw > 1e10:  # –í–µ—Ä–æ—è—Ç–Ω–æ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                                                date = datetime.fromtimestamp(date_raw / 1000.0).isoformat()
                                            else:  # –°–µ–∫—É–Ω–¥—ã
                                                date = datetime.fromtimestamp(date_raw).isoformat()
                                        except Exception as e:
                                            print(f"‚ö†Ô∏è Error parsing timestamp {date_raw}: {e}")
                                    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ ISO —Ñ–æ—Ä–º–∞—Ç–∞
                                    elif isinstance(date_raw, str):
                                        try:
                                            # –£–±–∏—Ä–∞–µ–º Z –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ +00:00
                                            date_clean = date_raw.replace('Z', '+00:00')
                                            date = date_clean
                                        except:
                                            date = date_raw
                                
                                if not date:
                                    print(f"‚ö†Ô∏è DEBUG POSTS: No date found for item. Keys: {list(item.keys())}")
                                    if 'date' in item:
                                        print(f"   Date field content: {item['date']}")

                                post = {
                                    'title': item.get('title', ''),
                                    'text': item.get('text', item.get('content', item.get('message', ''))),
                                    'date': date,
                                    'url': item.get('url', '')
                                }
                                if post['text'] or post['title']:
                                    posts.append(post)
                
                for value in data.values():
                    find_posts(value)
            
            elif isinstance(data, list):
                for item in data:
                    find_posts(item)
        
        find_posts(json_data)
        if posts:
            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(posts)} –Ω–æ–≤–æ—Å—Ç–µ–π/–ø–æ—Å—Ç–æ–≤")
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é –Ω–æ–≤–æ—Å—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            print(f"üì∞ –ü—Ä–∏–º–µ—Ä –Ω–æ–≤–æ—Å—Ç–∏: {posts[0].get('title', '')[:50]}... ({posts[0].get('date', '–Ω–µ—Ç –¥–∞—Ç—ã')})")
        return posts

    def _extract_photos_from_api(self, json_data: Any) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–æ—Ç–æ –∏–∑ getByBusinessId: {"data": [{url, id, ...}, ...]}"""
        photos = []
        arr = json_data.get("data") if isinstance(json_data, dict) else None
        if not isinstance(arr, list):
            return photos
        for item in arr:
            if not isinstance(item, dict):
                continue
            url_val = item.get("url") or item.get("urlTemplate") or item.get("href")
            if url_val:
                photos.append({"url": str(url_val), "id": item.get("id", "")})
        return photos

    def _extract_products_from_api(self, json_data: Any) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–≤–∞—Ä—ã/—É—Å–ª—É–≥–∏ –∏–∑ API"""
        products = []
        
        def find_products(data):
            if isinstance(data, dict):
                # LOGGING: Print all keys if we suspect this dictates products but we missed it
                if any(k in data for k in ['data', 'result', 'search', 'goods', 'items']):
                    # Too verbose to print everything, just keys
                    pass 

                # –ò—â–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
                # –ò—â–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
                # –£–±—Ä–∞–ª–∏ 'features' (—ç—Ç–æ —Å–≤–æ–π—Å—Ç–≤–∞ –∫–∞—Ä—Ç—ã) –∏ 'items' (—Å–ª–∏—à–∫–æ–º –æ–±—â–µ–µ, —á–∞—Å—Ç–æ —ç—Ç–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏)
                # 'items' –æ—Å—Ç–∞–≤–∏–º, –Ω–æ —Å –∂–µ—Å—Ç–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                target_keys = ['goods', 'products', 'prices', 'searchResult', 'results', 'catalog', 'menu', 'services', 'items', 'categoryItems']
                
                for key in target_keys:
                    if key in data and isinstance(data[key], list):
                         if len(data[key]) > 0:
                            item0 = data[key][0]
                            if isinstance(item0, dict):
                                 # Debug log
                                 if any(k in item0 for k in ['name', 'title', 'price', 'text']):
                                     pass # print(f"üîç DEBUG PRODUCTS: Found list in '{key}'...")
                        
                         for item in data[key]:
                            if isinstance(item, dict):
                                # 1. –ü–†–û–í–ï–†–ö–ê: –≠—Ç–æ —Ç–æ–≤–∞—Ä –∏–ª–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è/—Ñ–∏—á–∞?
                                # –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –æ–±—ã—á–Ω–æ –∏–º–µ—é—Ç ratingData, workingTime, geoId
                                if any(k in item for k in ['ratingData', 'workingTime', 'geoId', 'rubricId', 'stops']):
                                    continue
                                
                                # –§–∏—á–∏ –∫–∞—Ä—Ç—ã (features) —á–∞—Å—Ç–æ –∏–º–µ—é—Ç 'id', 'value', 'type', –Ω–æ –Ω–µ –∏–º–µ—é—Ç price
                                if 'type' in item and 'value' in item and 'price' not in item:
                                    continue
                                
                                # Check if it's a product
                                name = item.get('name', item.get('title', ''))
                                
                                # Deep search for name if not found at top level
                                if not name and 'name' in item.get('data', {}):
                                    name = item.get('data', {}).get('name')

                                if not name:
                                    text_val = item.get('text', '')
                                    if text_val and len(text_val) < 100: 
                                         name = text_val
                                
                                if not name:
                                    continue
                                
                                # --- SEMI-STRICT PRICE CHECK ---
                                # Relaxed Rule (2026-01-30): Allow items without price IF they are not obvious map features.
                                # Previously we required price for 'items', 'searchResult', etc. to avoid "Toilets", "Entrances".
                                # Now we use a blacklist and name length check.
                                
                                has_price = False
                                price_val = ''
                                
                                price_obj = item.get('minPrice', {}) or item.get('price', {})
                                if isinstance(price_obj, dict):
                                     val = price_obj.get('value')
                                     text = price_obj.get('text')
                                     if val or text:
                                         has_price = True
                                         price_val = text or str(val)
                                elif 'price' in item:
                                     val = item['price']
                                     if val:
                                         has_price = True
                                         price_val = str(val)
                                
                                if key in ['items', 'searchResult', 'results', 'categoryItems'] and not has_price:
                                    # Check blacklist for common map features
                                    junk_terms = ['–≤—Ö–æ–¥', '—Ç—É–∞–ª–µ—Ç', '–ø–∞—Ä–∫–æ–≤–∫–∞', '–±–∞–Ω–∫–æ–º–∞—Ç', '–æ–ø–ª–∞—Ç–∞', 'entrance', 'toilet', 'parking', 'atm', 'wc', '—ç—Ç–∞–∂']
                                    name_lower = name.lower()
                                    
                                    # If name matches junk or is very short (likely not a service), skip
                                    is_junk = any(term in name_lower for term in junk_terms)
                                    if is_junk or len(name) < 3:
                                         continue
                                    
                                    # Otherwise, allow it (Oliver has services without prices)
                                    pass
                                
                                # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
                                category = ''
                                if isinstance(item.get('category'), dict):
                                    category = item.get('category').get('name', '')
                                else:
                                    category = str(item.get('category', ''))
                                
                                # –û–ø–∏—Å–∞–Ω–∏–µ
                                description = item.get('description', '')
                                
                                # –§–æ—Ç–æ
                                photo = ''
                                if isinstance(item.get('image'), dict):
                                    photo = item.get('image').get('url', '')
                                elif isinstance(item.get('photos'), list) and len(item['photos']) > 0:
                                     photo = item['photos'][0].get('urlTemplate', '')

                                products.append({
                                    'name': name,
                                    'price': price_val,
                                    'description': description,
                                    'category': category,
                                    'photo': photo
                                })
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
                for key, value in data.items():
                    if isinstance(value, (dict, list)):
                        find_products(value)
            
            elif isinstance(data, list):
                for item in data:
                    find_products(item)
                    
        find_products(json_data)
        if len(products) > 0:
            print(f"üì¶ DEBUG PRODUCTS: Extracted {len(products)} total items")
        return products
    
    def _fallback_html_parsing(self, page, url: str) -> Dict[str, Any]:
        """Fallback –Ω–∞ HTML –ø–∞—Ä—Å–∏–Ω–≥, –µ—Å–ª–∏ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª"""
        print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback HTML –ø–∞—Ä—Å–∏–Ω–≥...")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
        try:
            from yandex_maps_scraper import parse_overview_data, parse_reviews, parse_news, parse_photos, get_photos_count, parse_features, parse_competitors, parse_products
            
            data = parse_overview_data(page)
            data['url'] = url
            
            reviews_data = parse_reviews(page)
            data['reviews'] = reviews_data.get('items', [])
            data['news'] = parse_news(page)
            data['photos_count'] = get_photos_count(page)
            data['photos'] = parse_photos(page)
            data['features_full'] = parse_features(page)
            data['competitors'] = parse_competitors(page)
            data['products'] = parse_products(page)
            
            overview_keys = [
                'title', 'address', 'phone', 'site', 'description',
                'rubric', 'categories', 'hours', 'hours_full', 'rating', 
                'ratings_count', 'reviews_count', 'social_links'
            ]
            data['overview'] = {k: data.get(k, '') for k in overview_keys}
            data['overview']['reviews_count'] = data.get('reviews_count', '')
            
            return data
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ fallback –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            return {'error': str(e), 'url': url}


def parse_yandex_card(
    url: str,
    keep_open_on_captcha: bool = False,
    session_registry: Optional[Dict[str, BrowserSession]] = None,
    session_id: Optional[str] = None,
    debug_bundle_id: Optional[str] = None,
    **session_kwargs: Any,
) -> Dict[str, Any]:
    """
    –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç c –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π human-in-the-loop.

    - —É–ø—Ä–∞–≤–ª—è–µ—Ç –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º BrowserSession —á–µ—Ä–µ–∑ BrowserSessionManager
    - —Å–∞–º –ø–∞—Ä—Å–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –≥–æ—Ç–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π (session.page/session.context)
    """
    manager = BrowserSessionManager()
    session: Optional[BrowserSession] = None

    # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö kwargs –¥–ª—è —Å–µ—Å—Å–∏–∏
    unknown = set(session_kwargs.keys()) - ALLOWED_SESSION_KWARGS
    if unknown:
        msg = f"Unknown session kwargs in parse_yandex_card: {unknown}"
        env = os.getenv("FLASK_ENV", "").lower()
        is_debug_env = env in ("development", "dev", "debug", "test", "testing")
        if is_debug_env:
            raise ValueError(msg)
        else:
            print(f"‚ö†Ô∏è {msg}")
            # –í production ‚Äî –ø—Ä–æ—Å—Ç–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª—é—á–∏
            for k in list(unknown):
                session_kwargs.pop(k, None)

    # 1. –†–µ–∂–∏–º resume: –±–µ—Ä—ë–º —Å–µ—Å—Å–∏—é –∏–∑ registry –ø–æ session_id
    if session_id and session_registry is not None:
        session = manager.get(session_registry, session_id)
        if session is None:
            return {
                "error": "captcha_session_lost",
                "captcha_session_id": session_id,
            }
    else:
        # 2. –ü–µ—Ä–≤—ã–π –∑–∞—Ö–æ–¥: –æ—Ç–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
        session = manager.open_session(
            headless=session_kwargs.get("headless", True),
            cookies=session_kwargs.get("cookies"),
            user_agent=session_kwargs.get("user_agent"),
            viewport=session_kwargs.get("viewport"),
            locale=session_kwargs.get("locale", "ru-RU"),
            timezone_id=session_kwargs.get("timezone_id", "Europe/Moscow"),
            proxy=session_kwargs.get("proxy"),
            launch_args=session_kwargs.get("launch_args"),
            init_scripts=session_kwargs.get("init_scripts"),
            keep_open=keep_open_on_captcha,
            geolocation=session_kwargs.get("geolocation"),
        )

    parser = YandexMapsInterceptionParser(debug_bundle_id=debug_bundle_id)

    result: Dict[str, Any]
    try:
        result = parser.parse_yandex_card(url, session=session)
    except Exception:
        # –ü—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ ‚Äî –≤—Å–µ–≥–¥–∞ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é (–æ–Ω–∞ –±–æ–ª—å—à–µ –Ω–µ –ø—Ä–∏–≥–æ–¥–Ω–∞)
        if session:
            manager.close_session(session)
            if session_registry is not None and session_id:
                session_registry.pop(session_id, None)
        raise

    # –ö–∞–ø—á–∞ + human-in-the-loop
    if isinstance(result, dict) and result.get("error") == "captcha_detected":
        # –ï—Å–ª–∏ –º–æ–∂–Ω–æ –¥–µ—Ä–∂–∞—Ç—å —Å–µ—Å—Å–∏—é –æ—Ç–∫—Ä—ã—Ç–æ–π –∏ –µ—Å—Ç—å registry ‚Äî –ø–∞—Ä–∫—É–µ–º
        if keep_open_on_captcha and session_registry is not None and session:
            parked_id = manager.park(session_registry, session)
            result["captcha_session_id"] = parked_id
            result["captcha_needs_human"] = True
            return result

        # –ò–Ω–∞—á–µ: –Ω–µ–∫—É–¥–∞ –ø–∞—Ä–∫–æ–≤–∞—Ç—å ‚Äî –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é, –Ω–æ –ø–æ–º–µ—á–∞–µ–º, —á—Ç–æ –Ω—É–∂–µ–Ω —á–µ–ª–æ–≤–µ–∫
        if session:
            manager.close_session(session)
            if session_registry is not None and session_id:
                session_registry.pop(session_id, None)
        result["captcha_needs_human"] = True
        return result

    # –û–±—ã—á–Ω—ã–π –∫–µ–π—Å: —Å–µ—Å—Å–∏—é –≤—Å–µ–≥–¥–∞ –∑–∞–∫—Ä—ã–≤–∞–µ–º
    if session:
        manager.close_session(session)
        # –ï—Å–ª–∏ —ç—Ç–æ resume ‚Äî —á–∏—Å—Ç–∏–º registry
        if session_registry is not None and session_id:
            session_registry.pop(session_id, None)

    return result


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    test_url = "https://yandex.ru/maps/org/gagarin/180566191872/"
    result = parse_yandex_card(test_url)
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞:")
    print(json.dumps(result, ensure_ascii=False, indent=2))
