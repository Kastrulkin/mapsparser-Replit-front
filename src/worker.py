import time
import uuid
import json
import re
import os
import traceback
from datetime import datetime, timedelta
import signal
import sys
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv

from browser_session import BrowserSession, BrowserSessionManager
from parser_config_cookies import get_yandex_cookies

load_dotenv()

# New imports
from database_manager import DatabaseManager
from parsequeue_status import (
    STATUS_CAPTCHA,
    STATUS_COMPLETED,
    STATUS_ERROR,
    STATUS_PENDING,
    STATUS_PROCESSING,
)
from yandex_business_sync_worker import YandexBusinessSyncWorker
from external_sources import ExternalReview, ExternalSource, ExternalPost, ExternalStatsPoint, make_stats_id
from dateutil import parser as date_parser
from parsed_payload_validation import (
    build_parsing_meta,
    FIELDS_CRITICAL,
    SOURCE_YANDEX_BUSINESS,
)

# –†–µ–µ—Å—Ç—Ä –∞–∫—Ç–∏–≤–Ω—ã—Ö Playwright-—Å–µ—Å—Å–∏–π –¥–ª—è human-in-the-loop
ACTIVE_CAPTCHA_SESSIONS: Dict[str, BrowserSession] = {}
BROWSER_SESSION_MANAGER = BrowserSessionManager()
CAPTCHA_TTL_MINUTES = 30


def get_db_connection():
    """Runtime worker –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç PostgreSQL —á–µ—Ä–µ–∑ pg_db_utils."""
    from pg_db_utils import get_db_connection as _get_pg_connection

    return _get_pg_connection()

def _handle_worker_error(queue_id: str, error_msg: str):
    """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –Ω–∞ error —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            """
            UPDATE parsequeue
            SET status = %s,
                error_message = %s,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
            """,
            (STATUS_ERROR, error_msg, queue_id),
        )
        conn.commit()
        cursor.close()
        conn.close()
    except Exception as ex:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–∫–∏ –¥–ª—è {queue_id}: {ex}")


def _upsert_map_parse_from_card(
    conn,
    business_id: str,
    *,
    url: str = "",
    rating: float | None = None,
    reviews_count: int = 0,
    photos_count: int = 0,
    news_count: int = 0,
    products: list | None = None,
    competitors: list | None = None,
):
    """–ó–∞–ø–∏—Å–∞—Ç—å —Å—Ä–µ–∑ –≤ MapParseResults –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Progress/growth_api."""
    import uuid as _uuid
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT column_name FROM information_schema.columns
            WHERE table_schema = 'public' AND table_name = 'mapparseresults'
        """)
        cols = {r[0] for r in cursor.fetchall()}
        # –¢–∞–±–ª–∏—Ü–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/–Ω–µ –≤–∏–¥–Ω–∞ –≤ —Å—Ö–µ–º–µ ‚Äî silently skip –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –æ–∫—Ä—É–∂–µ–Ω–∏–π.
        if not cols:
            return
        pid = str(_uuid.uuid4())
        url_val = url or f"https://yandex.ru/maps/"
        fields = ["id", "business_id", "url", "map_type", "rating", "reviews_count", "news_count", "photos_count", "created_at"]
        values = [pid, business_id, url_val, "yandex", str(rating) if rating else None, reviews_count, news_count, photos_count]
        if "services_count" in cols and products:
            s_count = sum(len(c.get("items") or []) for c in products if isinstance(c, dict))
            fields.append("services_count")
            values.append(s_count)
        if "products" in cols and products:
            fields.append("products")
            values.append(json.dumps(products, ensure_ascii=False) if products else None)
        if "competitors" in cols and competitors:
            fields.append("competitors")
            values.append(json.dumps(competitors, ensure_ascii=False) if competitors else None)
        placeholders = ", ".join(["%s"] * len(values))
        cursor.execute(
            f"INSERT INTO mapparseresults ({', '.join(fields)}) VALUES ({placeholders})",
            values,
        )
        conn.commit()
    finally:
        cursor.close()


def _extract_date_from_review(review: dict) -> str | int | float | None:
    """–ò–∑–≤–ª–µ—á—å –¥–∞—Ç—É –∏–∑ –æ—Ç–∑—ã–≤–∞, –ø—Ä–æ–≤–µ—Ä—è—è —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–ª—è"""
    date_fields = ['date', 'published_at', 'publishedAt', 'created_at', 'createdAt', 'time', 'timestamp']
    date_value = review.get('date')
    
    if date_value:
        if isinstance(date_value, str):
            return date_value.strip()
        return date_value
    
    # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–ª—è
    for field in date_fields[1:]:
        date_value = review.get(field)
        if date_value:
            if isinstance(date_value, str):
                return date_value.strip()
            return date_value
    
    return None

def _parse_timestamp_to_datetime(timestamp: int | float) -> datetime | None:
    """–ü–∞—Ä—Å–∏—Ç—å timestamp –≤ datetime (–º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –∏–ª–∏ —Å–µ–∫—É–Ω–¥—ã)"""
    try:
        if timestamp > 1e10:  # –ú–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
            return datetime.fromtimestamp(timestamp / 1000.0)
        return datetime.fromtimestamp(timestamp)  # –°–µ–∫—É–Ω–¥—ã
    except Exception:
        return None

def _parse_relative_date(date_str: str) -> datetime | None:
    """–ü–∞—Ä—Å–∏—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã: '—Å–µ–≥–æ–¥–Ω—è', '–≤—á–µ—Ä–∞', '2 –¥–Ω—è –Ω–∞–∑–∞–¥' –∏ —Ç.–¥."""
    date_lower = date_str.lower()
    
    if '—Å–µ–≥–æ–¥–Ω—è' in date_lower or 'today' in date_lower:
        return datetime.now()
    if '–≤—á–µ—Ä–∞' in date_lower or 'yesterday' in date_lower:
        return datetime.now() - timedelta(days=1)
    
    # –î–Ω–∏ –Ω–∞–∑–∞–¥
    if any(word in date_str for word in ['–¥–Ω—è', '–¥–µ–Ω—å', '–¥–Ω–µ–π']):
        days_match = re.search(r'(\d+)', date_str)
        if days_match:
            return datetime.now() - timedelta(days=int(days_match.group(1)))
    
    # –ù–µ–¥–µ–ª–∏ –Ω–∞–∑–∞–¥
    if any(word in date_str for word in ['–Ω–µ–¥–µ–ª—é', '–Ω–µ–¥–µ–ª–∏', '–Ω–µ–¥–µ–ª—å']):
        weeks_match = re.search(r'(\d+)', date_str)
        weeks_ago = int(weeks_match.group(1)) if weeks_match else 1
        return datetime.now() - timedelta(weeks=weeks_ago)
    
    # –ú–µ—Å—è—Ü—ã –Ω–∞–∑–∞–¥
    if any(word in date_str for word in ['–º–µ—Å—è—Ü', '–º–µ—Å—è—Ü–∞', '–º–µ—Å—è—Ü–µ–≤']):
        months_match = re.search(r'(\d+)', date_str)
        months_ago = int(months_match.group(1)) if months_match else 1
        return datetime.now() - timedelta(days=months_ago * 30)
    
    # –ì–æ–¥—ã –Ω–∞–∑–∞–¥
    if any(word in date_str for word in ['–≥–æ–¥', '–≥–æ–¥–∞', '–ª–µ—Ç']):
        years_match = re.search(r'(\d+)', date_str)
        years_ago = int(years_match.group(1)) if years_match else 1
        return datetime.now() - timedelta(days=years_ago * 365)
    
    return None

def _parse_russian_date(date_str: str) -> datetime | None:
    try:
        months = {
            '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4, '–º–∞—è': 5, '–∏—é–Ω—è': 6,
            '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8, '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12,
            '—è–Ω–≤': 1, '—Ñ–µ–≤': 2, '–º–∞—Ä': 3, '–∞–ø—Ä': 4, '–º–∞–π': 5, '–∏—é–Ω': 6,
            '–∏—é–ª': 7, '–∞–≤–≥': 8, '—Å–µ–Ω': 9, '–æ–∫—Ç': 10, '–Ω–æ—è': 11, '–¥–µ–∫': 12
        }
        
        parts = date_str.lower().split()
        if len(parts) >= 2:
            day_str = parts[0]
            month_str = parts[1]
            year_str = parts[2] if len(parts) > 2 else str(datetime.now().year)
            
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            day_str = re.sub(r'\D', '', day_str)
            year_str = re.sub(r'\D', '', year_str)
            # –û—á–∏—â–∞–µ–º –º–µ—Å—è—Ü –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (–∑–∞–ø—è—Ç—ã–µ, —Ç–æ—á–∫–∏)
            month_str = re.sub(r'[^\w\s]', '', month_str, flags=re.UNICODE) 
            
            if not day_str or not month_str:
                return None
                
            day = int(day_str)
            month = months.get(month_str)
            year = int(year_str)
            
            if month:
                return datetime(year, month, day)
                
    except Exception:
        pass
    return None

def _parse_date_string(date_str: str) -> datetime | None:
    """–ü–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã –≤ datetime"""
    if not date_str or not isinstance(date_str, str):
        return None
    
    date_str = date_str.strip()
    if not date_str:
        return None
    
    # –ü—Ä–æ–±—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã
    relative = _parse_relative_date(date_str)
    if relative:
        return relative
    
    # –ü—Ä–æ–±—É–µ–º —Ä—É—Å—Å–∫–∏–µ –¥–∞—Ç—ã (27 —è–Ω–≤–∞—Ä—è 2026)
    russian_date = _parse_russian_date(date_str)
    if russian_date:
        return russian_date
    
    # –ü—Ä–æ–±—É–µ–º ISO —Ñ–æ—Ä–º–∞—Ç
    try:
        if 'T' in date_str or 'Z' in date_str or date_str.count('-') >= 2:
            return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
    except Exception:
        pass
    
    # –ü—Ä–æ–±—É–µ–º dateutil –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
    try:
        return date_parser.parse(date_str, fuzzy=True)
    except Exception:
        return None

def _validate_parsing_result(card_data: dict) -> tuple:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–ª—è–º. –ë–µ–∑ –ø–æ–¥–º–µ—à–∏–≤–∞–Ω–∏—è –∏–∑ –ë–î ‚Äî
    —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—à–ª–æ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ø–Ω–¥–µ–∫—Å).
    Returns:
        (is_successful: bool, reason: str, validation_result: dict | None)
    """
    from parsed_payload_validation import validate_parsed_payload

    if card_data.get("error") == "captcha_detected":
        return False, "captcha_detected", None
    if card_data.get("error"):
        return False, f"error: {card_data.get('error')}", None

    validation = validate_parsed_payload(card_data, source=SOURCE_YANDEX_BUSINESS)
    hard_missing = validation.get("hard_missing") or []
    quality_score = validation.get("quality_score", 0.0)

    if hard_missing:
        return False, "missing_in_source:" + ",".join(hard_missing), validation

    # –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ: –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫, –Ω–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø–æ–ª—è –ø–æ—á—Ç–∏ –≤—Å–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.
    # –ù–µ —Å—á–∏—Ç–∞–µ–º —Ç–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É—Å–ø–µ—à–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
    missing_fields = set(validation.get("missing_fields") or [])
    critical_list = []
    for field in ("address", "rating", "reviews_count", "categories"):
        if field in missing_fields:
            critical_list.append(field)

    # –ü–æ—Ä–æ–≥ 0.5: –ø—Ä–∏ 0.4 –ø–∞—Ä—Å–µ—Ä —á–∞—Å—Ç–æ –æ—Ç–¥–∞—ë—Ç —Ç–æ–ª—å–∫–æ title (—Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ /prices/, –∫–∞–ø—á–∞ –∏ —Ç.–¥.)
    if quality_score < 0.5:
        reason = f"low_quality_payload:quality_score={quality_score}"
        if critical_list:
            reason = f"{reason} missing={','.join(critical_list)}"
        return False, reason, validation

    return True, "success", validation

def _has_cabinet_account(business_id: str) -> tuple:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É –±–∏–∑–Ω–µ—Å–∞ –∞–∫–∫–∞—É–Ω—Ç –≤ –ª–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ.
    
    Returns:
        (has_account: bool, account_id: str)
    """
    if not business_id:
        return False, None
    
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            SELECT id
            FROM externalbusinessaccounts
            WHERE business_id = %s AND source = 'yandex_business' AND is_active = TRUE
            LIMIT 1
        """, (business_id,))
        
        row = cursor.fetchone()
        if row:
            return True, row[0]
        return False, None
    finally:
        cursor.close()
        conn.close()

def _ensure_column_exists(cursor, conn, table_name, column_name, column_type="TEXT"):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å —Ç–æ–ª—å–∫–æ –¥–ª—è SQLite (PRAGMA, ALTER TABLE on the fly).
    # –í PostgreSQL —Å—Ö–µ–º–∞ —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ –º–∏–≥—Ä–∞—Ü–∏–∏ (schema_postgres.sql),
    # –ø–æ—ç—Ç–æ–º—É –≤ worker'–µ –ø—Ä–∏ DB_TYPE='postgres' –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º.
    if DB_TYPE == "postgres":
        return

    try:
        # PRAGMA –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º f-string —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        ALLOWED_TABLES = {"parsequeue", "cards"}
        if table_name not in ALLOWED_TABLES:
            raise ValueError(f"–ù–µ—Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞: {table_name}")
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [row[1] for row in cursor.fetchall()]

        if column_name not in columns:
            print(f"üìù –î–æ–±–∞–≤–ª—è—é –ø–æ–ª–µ {column_name} –≤ {table_name}...")
            cursor.execute(f"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_type}")
            conn.commit()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–ª–æ–Ω–∫–∏ {column_name} –≤ {table_name}: {e}")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º parser_config –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ –ø–∞—Ä—Å–µ—Ä–∞ (interception –∏–ª–∏ legacy)
from parser_config import parse_yandex_card
from gigachat_analyzer import analyze_business_data

def process_queue():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑ SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    queue_dict = None
    
    # –®–ê–ì 1: –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å (–∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—Ä–∞–∑—É)
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # –î–ª—è PostgreSQL —Å—Ö–µ–º–∞ –æ—á–µ—Ä–µ–¥–∏ —É–∂–µ –∑–∞–¥–∞–Ω–∞ –≤ schema_postgres.sql,
        # –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–µ—Ä–µ–∑ sqlite_master / PRAGMA –∑–¥–µ—Å—å –Ω–µ –Ω—É–∂–Ω—ã.

        # –°–∞–Ω–∏—Ç–∞–π–∑–µ—Ä "–±–∏—Ç—ã—Ö" captcha-–∑–∞–ø–∏—Å–µ–π: status='captcha' –±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ captcha_started_at
        try:
            cursor.execute(
                """
                UPDATE parsequeue
                SET status = %s,
                    captcha_status = 'expired',
                    captcha_required = 0,
                    captcha_url = NULL,
                    captcha_session_id = NULL,
                    captcha_started_at = NULL,
                    resume_requested = 0,
                    updated_at = CURRENT_TIMESTAMP,
                    error_message = COALESCE(
                        error_message || '; broken captcha record: missing captcha_started_at',
                        'broken captcha record: missing captcha_started_at'
                    )
                WHERE status = %s
                  AND captcha_started_at IS NULL
                """,
                (STATUS_PENDING, STATUS_CAPTCHA),
            )
            if cursor.rowcount:
                conn.commit()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–∞–Ω–∏—Ç–∞—Ü–∏–∏ –±–∏—Ç—ã—Ö captcha-–∑–∞–ø–∏—Å–µ–π: {e}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ parse_card, –∏ sync –∑–∞–¥–∞—á–∏)
        now = datetime.now()
        now_iso = now.isoformat()
        ttl_cutoff_iso = (now - timedelta(minutes=CAPTCHA_TTL_MINUTES)).isoformat()
        cursor.execute(
            """
            SELECT *
            FROM parsequeue
            WHERE 
                (
                    status = %s
                    AND (retry_after IS NULL OR retry_after <= %s)
                )
                OR (
                    status = %s
                    AND (
                        resume_requested = 1
                        OR (retry_after IS NULL OR retry_after <= %s)
                        OR (captcha_started_at <= %s)
                    )
                )
            ORDER BY 
                CASE 
                    WHEN status = %s THEN 1 
                    WHEN status = %s THEN 2 
                    ELSE 3 
                END,
                created_at ASC 
            LIMIT 1
            """,
            (
                STATUS_PENDING,
                now_iso,
                STATUS_CAPTCHA,
                now_iso,
                ttl_cutoff_iso,
                STATUS_PENDING,
                STATUS_CAPTCHA,
            ),
        )
        queue_item = cursor.fetchone()
        
        if not queue_item:
            return
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Row –≤ —Å–ª–æ–≤–∞—Ä—å (RealDictCursor –≤ pg_db_utils)
        queue_dict = dict(queue_item)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ processing
        cursor.execute(
            "UPDATE parsequeue SET status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
            (STATUS_PROCESSING, queue_dict["id"]),
        )
        conn.commit()
    finally:
        # –í–ê–ñ–ù–û: –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –¥–æ–ª–≥–∏–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º
        cursor.close()
        conn.close()
    
    if not queue_dict:
        return
    
    status = queue_dict.get("status") or "pending"
    task_type = queue_dict.get("task_type") or "parse_card"
    
    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞—è–≤–∫—É: {queue_dict.get('id')}, —Ç–∏–ø: {task_type}, —Å—Ç–∞—Ç—É—Å: {status}")
    
    # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –≤ —Å—Ç–∞—Ç—É—Å–µ captcha ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º HITL-flow (resume/expired)
    if status == "captcha":
        task_id = queue_dict["id"]
        captcha_session_id = queue_dict.get("captcha_session_id")
        captcha_started_at = queue_dict.get("captcha_started_at")
        resume_requested = queue_dict.get("resume_requested")
        url = queue_dict.get("url")

        # 1) –ü—Ä–æ–≤–µ—Ä–∫–∞ TTL (expired)
        try:
            if captcha_started_at:
                started_dt = datetime.fromisoformat(str(captcha_started_at))
                age_minutes = (datetime.now() - started_dt).total_seconds() / 60.0
            else:
                age_minutes = 0
        except Exception:
            age_minutes = 0

        if age_minutes > CAPTCHA_TTL_MINUTES:
            print(f"‚è∞ CAPTCHA TTL –∏—Å—Ç—ë–∫ –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}, –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ expired")
            session = BROWSER_SESSION_MANAGER.get(ACTIVE_CAPTCHA_SESSIONS, str(captcha_session_id)) if captcha_session_id else None
            if session:
                BROWSER_SESSION_MANAGER.close_session(session)
            if captcha_session_id:
                ACTIVE_CAPTCHA_SESSIONS.pop(str(captcha_session_id), None)

            conn = get_db_connection()
            cursor = conn.cursor()
            try:
                cursor.execute(
                    """
                    UPDATE parsequeue
                    SET captcha_status = 'expired',
                        captcha_session_id = NULL,
                        captcha_required = 0,
                        captcha_url = NULL,
                        captcha_started_at = NULL,
                        resume_requested = 0,
                        status = %s,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = %s
                    """,
                    (STATUS_PENDING, task_id),
                )
                conn.commit()
            finally:
                cursor.close()
                conn.close()
            return

        # 2) Resume –ø–æ –∑–∞–ø—Ä–æ—Å—É –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
        if resume_requested and captcha_session_id and url:
            print(f"‚ñ∂Ô∏è RESUME CAPTCHA –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}, session_id={captcha_session_id}")
            card_data = parse_yandex_card(
                url,
                keep_open_on_captcha=False,
                session_registry=ACTIVE_CAPTCHA_SESSIONS,
                session_id=str(captcha_session_id),
            )

            if card_data.get("error") == "captcha_session_lost":
                print(f"‚ö†Ô∏è CAPTCHA session lost –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}")
                conn = get_db_connection()
                cursor = conn.cursor()
                try:
                    cursor.execute(
                        """
                        UPDATE parsequeue
                        SET captcha_status = 'expired',
                            captcha_session_id = NULL,
                            captcha_required = 0,
                            captcha_url = NULL,
                            captcha_started_at = NULL,
                            resume_requested = 0,
                            status = 'pending',
                            updated_at = CURRENT_TIMESTAMP,
                            error_message = %s
                        WHERE id = %s
                        """,
                        ("captcha session lost", task_id),
                    )
                    conn.commit()
                finally:
                    cursor.close()
                    conn.close()
                ACTIVE_CAPTCHA_SESSIONS.pop(str(captcha_session_id), None)
                return

            if card_data.get("error") == "captcha_detected":
                # –ö–∞–ø—á–∞ –Ω–µ —Ä–µ—à–µ–Ω–∞ –∏–ª–∏ –ø–æ—è–≤–∏–ª–∞—Å—å –∑–∞–Ω–æ–≤–æ ‚Äî –æ—Å—Ç–∞—ë–º—Å—è –≤ waiting —Å –Ω–æ–≤—ã–º session_id (–µ—Å–ª–∏ –µ—Å—Ç—å)
                new_session_id = card_data.get("captcha_session_id") or captcha_session_id
                captcha_url = card_data.get("captcha_url") or url
                captcha_comment = f"captcha_required: –æ—Ç–∫—Ä–æ–π—Ç–µ —Å—Å—ã–ª–∫—É –∏ –ø—Ä–æ–π–¥–∏—Ç–µ –∫–∞–ø—á—É: {captcha_url}" if captcha_url else "captcha_required: –ø—Ä–æ–π–¥–∏—Ç–µ –∫–∞–ø—á—É –∏ –Ω–∞–∂–º–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å"
                print(f"‚ö†Ô∏è –ö–∞–ø—á–∞ –≤—Å—ë –µ—â—ë –∞–∫—Ç–∏–≤–Ω–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}, session_id={new_session_id}")
                conn = get_db_connection()
                cursor = conn.cursor()
                try:
                    retry_after = datetime.now() + timedelta(minutes=CAPTCHA_TTL_MINUTES)
                    cursor.execute(
                        """
                        UPDATE parsequeue
                        SET captcha_status = 'waiting',
                            retry_after = %s,
                            captcha_url = %s,
                            captcha_session_id = %s,
                            error_message = %s,
                            resume_requested = 0,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = %s
                        """,
                        (retry_after.isoformat(), captcha_url, str(new_session_id), captcha_comment, task_id),
                    )
                    conn.commit()
                finally:
                    cursor.close()
                    conn.close()
                return

            # –ò–Ω–∞—á–µ ‚Äî –∫–∞–ø—á–∞ —Ä–µ—à–µ–Ω–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —É—Å–ø–µ—à–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
            print(f"‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id}, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É")
            queue_dict["status"] = "processing"
            queue_dict["resume_requested"] = 0
            # –ß–∏—Å—Ç–∏–º captcha-–ø–æ–ª—è
            conn = get_db_connection()
            cursor = conn.cursor()
            try:
                cursor.execute(
                    """
                    UPDATE parsequeue
                    SET captcha_status = NULL,
                        captcha_required = 0,
                        captcha_url = NULL,
                        captcha_session_id = NULL,
                        captcha_started_at = NULL,
                        resume_requested = 0,
                        status = 'processing',
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = %s
                    """,
                    (task_id,),
                )
                conn.commit()
            finally:
                cursor.close()
                conn.close()

            # –£–±–∏—Ä–∞–µ–º —Å–µ—Å—Å–∏—é –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —É–∂–µ –µ—ë –∑–∞–∫—Ä—ã–ª)
            ACTIVE_CAPTCHA_SESSIONS.pop(str(captcha_session_id), None)

            # card_data —É–∂–µ –ø–æ–ª—É—á–µ–Ω, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –¥–∞–ª—å—à–µ, –º–∏–Ω—É—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –≤—ã–∑–æ–≤ parse_yandex_card
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –ø–æ–π—Ç–∏ –ø–æ "–æ–±—ã—á–Ω–æ–º—É" –ø—É—Ç–∏: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º card_data –Ω–∏–∂–µ.
        else:
            # –ü–æ–∫–∞ –∂–¥—ë–º –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ –∏–ª–∏ TTL, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            print(f"‚è≥ –ó–∞–¥–∞—á–∞ {queue_dict.get('id')} –≤ —Å—Ç–∞—Ç—É—Å–µ CAPTCHA/waiting, –¥–µ–π—Å—Ç–≤–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
    if task_type == "sync_yandex_business":
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ø–Ω–¥–µ–∫—Å.–ë–∏–∑–Ω–µ—Å
        _process_sync_yandex_business_task(queue_dict)
        return
    elif task_type == "parse_cabinet_fallback":
        # Fallback –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –∫–∞–±–∏–Ω–µ—Ç
        _process_cabinet_fallback_task(queue_dict)
        return
    elif task_type == "sync_2gis":
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è 2–ì–ò–° API
        _process_sync_2gis_task(queue_dict)
        return
    elif task_type == "sync_google_business":
        # –î—Ä—É–≥–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–±—É–¥—É—â–µ–µ)
        print(f"‚ö†Ô∏è –¢–∏–ø –∑–∞–¥–∞—á–∏ {task_type} –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            """
            UPDATE parsequeue
            SET status = 'error',
                error_message = %s,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
            """,
            (f"–¢–∏–ø –∑–∞–¥–∞—á–∏ {task_type} –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω", queue_dict["id"]),
        )
        conn.commit()
        cursor.close()
        conn.close()
        return
    
    # –û–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç (task_type = 'parse_card' –∏–ª–∏ NULL)
    # –®–ê–ì 2: –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ (–ë–ï–ó –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î)
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç 10 –º–∏–Ω—É—Ç
    def timeout_handler(signum, frame):
        raise TimeoutError("Parsing task timed out after 10 minutes")
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(600)
    
    try:
        if not queue_dict.get("url"):
            raise ValueError("URL –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        
        url = queue_dict["url"]

        # --- –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–°–´–õ–û–ö (SPRAV -> MAPS) ---
        if '/sprav/' in url:
            import re
            # –ò—â–µ–º ID –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (—Ü–∏—Ñ—Ä—ã)
            sprav_match = re.search(r'/sprav/(\d+)', url)
            if sprav_match:
                org_id = sprav_match.group(1)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É –∫–∞—Ä—Ç
                new_url = f"https://yandex.ru/maps/org/redirect/{org_id}"
                print(f"‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–ê –°–°–´–õ–ö–ê –ù–ê –õ–ò–ß–ù–´–ô –ö–ê–ë–ò–ù–ï–¢: {url}")
                print(f"üîÑ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –ó–ê–ú–ï–ù–ê –ù–ê: {new_url}")
                url = new_url
                queue_dict['url'] = new_url # –û–±–Ω–æ–≤–ª—è–µ–º –∏ –≤ —Å–ª–æ–≤–∞—Ä–µ

        url = queue_dict["url"]

        cookies = get_yandex_cookies()
        business_id = queue_dict.get("business_id")
        debug_dir_root = os.getenv("DEBUG_DIR", "/app/debug_data").rstrip("/")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º debug_bundle_id –∏ bundle_dir –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ (–ø—Ä–∏–≤—è–∑–∞–Ω –∫ –±–∏–∑–Ω–µ—Å—É –∏ –∑–∞–¥–∞—á–µ)
        debug_bundle_id = None
        bundle_dir = None
        if business_id:
            ts_dbg = datetime.now().strftime("%Y%m%d_%H%M%S")
            debug_bundle_id = f"yandex_{business_id}_{queue_dict['id']}_{ts_dbg}"
            bundle_dir = os.path.join(debug_dir_root, debug_bundle_id)
            try:
                os.makedirs(bundle_dir, exist_ok=True)
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å debug bundle dir {bundle_dir}: {e}")
            else:
                print(f"[DEBUG_BUNDLE] {bundle_dir}")

        # –ì–µ–æ–ª–æ–∫–∞—Ü–∏—è –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–≥–∏–æ–Ω–∞: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É –±–∏–∑–Ω–µ—Å–∞ –µ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        geolocation_kwarg = {}
        if business_id:
            try:
                conn_geo = get_db_connection()
                cur_geo = conn_geo.cursor()
                cur_geo.execute("SELECT geo_lat, geo_lon FROM businesses WHERE id = %s", (business_id,))
                row_geo = cur_geo.fetchone()
                cur_geo.close()
                conn_geo.close()
                if row_geo and row_geo[0] is not None and row_geo[1] is not None:
                    geolocation_kwarg = {"geolocation": {"latitude": float(row_geo[0]), "longitude": float(row_geo[1])}}
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å geo –¥–ª—è business_id={business_id}: {e}")

        # –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã–∑–æ–≤ –ø–∞—Ä—Å–µ—Ä–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç Playwright Sync-in-async –∫—Ä–∞—à–∞
        try:
            card_data = parse_yandex_card(
                url,
                keep_open_on_captcha=True,
                session_registry=ACTIVE_CAPTCHA_SESSIONS,
                cookies=cookies,
                user_agent=(
                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/120.0.0.0 Safari/537.36"
                ),
                viewport={"width": 1920, "height": 1080},
                locale="ru-RU",
                timezone_id="Europe/Moscow",
                headless=True,
                debug_bundle_id=debug_bundle_id,
                **geolocation_kwarg,
            )

            # –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ –ø–∞—Ä—Å–µ—Ä–∞
            if card_data is None:
                print("[FATAL] parse_yandex_card –≤–µ—Ä–Ω—É–ª None", flush=True)
                card_data = {"error": "parser_returned_none", "url": url}
            elif not isinstance(card_data, dict):
                print(f"[FATAL] parse_yandex_card –≤–µ—Ä–Ω—É–ª {type(card_data)}", flush=True)
                card_data = {"error": f"parser_returned_{type(card_data).__name__}", "url": url}

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è title_or_name –¥–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–∫–∞—Å–∫–∞–¥: title ‚Üí name ‚Üí overview ‚Üí page_title ‚Üí og_title)
            if isinstance(card_data, dict) and not card_data.get("error"):
                if not card_data.get("title_or_name", "").strip():
                    og_raw = (card_data.get("og_title") or "").strip()
                    og_clean = og_raw.replace(" ‚Äî –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").replace(" - –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").split("|")[0].split(",")[0].strip() if og_raw else ""
                    sources = [
                        (card_data.get("title") or "").strip(),
                        (card_data.get("name") or "").strip(),
                        (card_data.get("overview") or {}).get("title") if isinstance(card_data.get("overview"), dict) else "",
                        (card_data.get("page_title") or "").replace(" ‚Äî –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").replace(" - –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã", "").strip() if card_data.get("page_title") else "",
                        og_clean,
                    ]
                    fallback = next((s for s in sources if s and str(s).strip()), None)
                    if fallback:
                        fallback = str(fallback).strip()
                        card_data["title_or_name"] = fallback
                        if not card_data.get("title"):
                            card_data["title"] = fallback
                        overview = card_data.get("overview") or {}
                        if isinstance(overview, dict) and not overview.get("title"):
                            overview["title"] = fallback
                        used_og = fallback == og_clean and og_clean
                        print(f"[WORKER_NORMALIZE] title_or_name='{fallback[:50]}'" + (" (from og_title)" if used_og else " –∏–∑ title/name/overview/page_title"), flush=True)
                    else:
                        print("[CRITICAL] –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è title_or_name", flush=True)
        except Exception as e:
            msg = str(e)
            if "Playwright Sync API inside the asyncio loop" in msg:
                # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–µ–π—Å: –∫—Ä—ç—à Playwright Sync –≤–Ω—É—Ç—Ä–∏ asyncio loop.
                # –ü–∏—à–µ–º exception.txt –≤ bundle (–µ—Å–ª–∏ –º–æ–∂–Ω–æ) –∏ –ø–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ error.
                bundle_path = None
                try:
                    if bundle_dir:
                        os.makedirs(bundle_dir, exist_ok=True)
                        bundle_path = bundle_dir
                        exc_path = os.path.join(bundle_dir, "exception.txt")
                        with open(exc_path, "w", encoding="utf-8") as f:
                            f.write("Playwright Sync-in-async crash\n\n")
                            f.write(repr(e) + "\n\n")
                            f.write(traceback.format_exc())
                except Exception as we:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å exception.txt: {we}")

                err_msg = f"playwright_sync_in_async_loop exc={type(e).__name__}"
                if bundle_path:
                    err_msg = f"{err_msg} bundle={bundle_path}"

                try:
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute(
                        """
                        UPDATE parsequeue
                        SET status = %s,
                            error_message = %s,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = %s
                        """,
                        (STATUS_ERROR, err_msg, queue_dict["id"]),
                    )
                    conn.commit()
                    cursor.close()
                    conn.close()
                except Exception as db_ex:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å parsequeue –¥–ª—è playwright-sync –æ—à–∏–±–∫–∏: {db_ex}")
                return
            # –õ—é–±–∞—è –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ ‚Äî –ø—É—Å—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ–±—â–µ–π –ª–æ–≥–∏–∫–æ–π –Ω–∏–∂–µ
            raise
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ (–≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –ø–æ –¥–∞–Ω–Ω—ã–º –Ø–Ω–¥–µ–∫—Å–∞, –±–µ–∑ fallback –∏–∑ –ë–î)
        is_successful, reason, validation_result = _validate_parsing_result(card_data)

        # –ø–∏—à–µ–º validation.json –≤ bundle (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
        if bundle_dir and validation_result:
            try:
                v_path = os.path.join(bundle_dir, "validation.json")
                val_warnings = list(validation_result.get("warnings") or [])
                parser_warnings = list(card_data.get("warnings") or []) if isinstance(card_data, dict) else []
                all_warnings = list(dict.fromkeys(val_warnings + parser_warnings))
                payload = {
                    "is_successful": bool(is_successful),
                    "reason": str(reason),
                    "quality_score": validation_result.get("quality_score"),
                    "hard_missing": validation_result.get("hard_missing") or [],
                    "missing_fields": validation_result.get("missing_fields") or [],
                    "found_fields": validation_result.get("found_fields") or [],
                    "warnings": all_warnings,
                }
                with open(v_path, "w", encoding="utf-8") as f:
                    json.dump(payload, f, ensure_ascii=False, indent=2, default=str)
            except Exception as ve:
                print(f"‚ö†Ô∏è Failed to write validation.json: {ve}")

        # –õ–æ–≥ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–µ–π (coverage), –µ—Å–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç—Ä–∞–±–æ—Ç–∞–ª–∞
        if validation_result:
            found_fields = validation_result.get("found_fields", []) or []
            missing_fields = validation_result.get("missing_fields", []) or []
            hard_missing = validation_result.get("hard_missing", []) or []
            quality_score = validation_result.get("quality_score", 0.0)
            print(
                f"üìä Parsing coverage: found={len(found_fields)} "
                f"missing={len(missing_fields)} hard_missing={hard_missing} "
                f"quality={quality_score}"
            )

            # –°–æ–±–∏—Ä–∞–µ–º _meta –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫ card_data –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ cards
            meta = build_parsing_meta(card_data, validation_result, source=SOURCE_YANDEX_BUSINESS)
            card_data["_meta"] = meta
        
        if not is_successful and business_id:
            print(f"‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–ø–æ–ª–Ω—ã–π ({reason}). –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fallback –æ—Ç–∫–ª—é—á–µ–Ω.")
        
        if card_data.get("error") == "captcha_detected":
            captcha_session_id = card_data.get("captcha_session_id")
            captcha_url = card_data.get("captcha_url") or queue_dict.get("url")
            captcha_comment = f"captcha_required: –æ—Ç–∫—Ä–æ–π—Ç–µ —Å—Å—ã–ª–∫—É –∏ –ø—Ä–æ–π–¥–∏—Ç–µ –∫–∞–ø—á—É: {captcha_url}" if captcha_url else "captcha_required: –ø—Ä–æ–π–¥–∏—Ç–µ –∫–∞–ø—á—É –∏ –Ω–∞–∂–º–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å"
            if captcha_session_id:
                print(f"‚ö†Ô∏è –ö–∞–ø—á–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, session_id={captcha_session_id} (human-in-the-loop)")
            else:
                print("‚ö†Ô∏è –ö–∞–ø—á–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞, –Ω–æ session_id –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (registry –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")

            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∫–∞–ø—á–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            conn = get_db_connection()
            cursor = conn.cursor()
            try:
                retry_after = datetime.now() + timedelta(minutes=30)
                now_iso = datetime.now().isoformat()
                cursor.execute(
                    """
                    UPDATE parsequeue
                    SET status = %s,
                        retry_after = %s,
                        captcha_required = 1,
                        captcha_url = %s,
                        captcha_session_id = %s,
                        captcha_started_at = %s,
                        captcha_status = 'waiting',
                        error_message = %s,
                        resume_requested = 0,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE id = %s
                    """,
                    (
                        STATUS_CAPTCHA,
                        retry_after.isoformat(),
                        captcha_url,
                        captcha_session_id,
                        now_iso,
                        captcha_comment,
                        queue_dict["id"],
                    ),
                )
                conn.commit()
            finally:
                cursor.close()
                conn.close()
            return

        # –®–ê–ì 3: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–æ—Ç–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)
        if not is_successful and card_data.get("error") != "captcha_detected":
            print(f"‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ—É—Å–ø–µ—à–µ–Ω: {reason}. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")

            # –ë–∞–∑–æ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞
            err_msg = str(reason)

            # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ debug bundle, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
            debug_dir = os.getenv("DEBUG_DIR", "/app/debug_data").rstrip("/")
            if debug_bundle_id:
                bundle_path = f"{debug_dir}/{debug_bundle_id}"
                err_msg = f"{err_msg} bundle={bundle_path}"
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute(
                """
                UPDATE parsequeue
                SET status = %s,
                    error_message = %s,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
                """,
                (STATUS_ERROR, err_msg, queue_dict["id"]),
            )
            conn.commit()
            cursor.close()
            conn.close()
            return

        business_id = queue_dict.get("business_id")
        conn = get_db_connection()
        cursor = conn.cursor()
        
        try:
            if business_id:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ cards (Postgres source of truth)
                print(f"üìä –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ cards –¥–ª—è business_id={business_id}")
                
                try:
                    from gigachat_analyzer import analyze_business_data
                    from report import generate_html_report
                    
                    print(f"ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º GigaChat –∞–Ω–∞–ª–∏–∑ –¥–ª—è {business_id}...")
                    analysis_result = analyze_business_data(card_data)
                    
                    analysis_data = {
                        'score': analysis_result.get('score', 50),
                        'recommendations': analysis_result.get('recommendations', []),
                        'ai_analysis': analysis_result.get('analysis', {})
                    }
                    
                    report_path = generate_html_report(card_data, analysis_data, {})
                    print(f"üìÑ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {report_path}")
                    
                    rating = card_data.get('overview', {}).get('rating', '') or ''
                    reviews_count = card_data.get('reviews_count') or card_data.get('overview', {}).get('reviews_count') or 0
                    reviews = card_data.get('reviews', [])
                    if isinstance(reviews, dict) and 'items' in reviews:
                        reviews_list = reviews['items']
                    elif isinstance(reviews, list):
                        reviews_list = reviews
                    else:
                        reviews_list = []
                    
                    parsed_reviews_count = len(reviews_list)
                    if parsed_reviews_count > int(reviews_count or 0):
                        reviews_count = parsed_reviews_count
                    
                    try:
                        reviews_count = int(reviews_count or 0)
                    except (ValueError, TypeError):
                        reviews_count = 0
                    photos_count = card_data.get('photos_count') or 0
                    try:
                        photos_count = int(photos_count)
                    except (ValueError, TypeError):
                        photos_count = 0
                    
                    phone = card_data.get('phone', '') or ''
                    website = card_data.get('site', '') or card_data.get('website', '') or ''
                    hours_full = card_data.get('hours_full', [])
                    hours_struct = {'schedule': hours_full} if hours_full else None
                    competitors = card_data.get('competitors', [])
                    products = card_data.get('products', [])
                    news_list = card_data.get('news') or card_data.get('posts') or []
                    if not isinstance(news_list, list):
                        news_list = []
                    
                    rating_float = None
                    if rating not in (None, ''):
                        try:
                            rating_float = float(rating)
                        except (ValueError, TypeError):
                            pass
                    
                    # –ì–æ—Ç–æ–≤–∏–º overview —Å –º–µ—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥–∞
                    overview_payload = {
                        'photos_count': photos_count,
                        'news_count': len(news_list),
                        'snapshot_type': 'full',
                    }
                    if card_data.get("_meta"):
                        overview_payload["_meta"] = card_data["_meta"]

                    db_manager = DatabaseManager()
                    services_saved_count = 0
                    try:
                        _photos = card_data.get("photos") or []
                        if isinstance(_photos, int):
                            _photos = []
                        db_manager.save_new_card_version(
                            business_id,
                            url=queue_dict["url"],
                            title=(card_data.get('name') or card_data.get('title') or ''),
                            address=(card_data.get('address') or ''),
                            phone=phone or None,
                            site=website or None,
                            rating=rating_float,
                            reviews_count=reviews_count,
                            overview=overview_payload,
                            products=products or None,
                            news=news_list or None,
                            photos=_photos if _photos else None,
                            competitors=competitors or None,
                            hours=hours_struct,
                            hours_full=hours_full or None,
                            report_path=report_path,
                            ai_analysis=analysis_data.get('ai_analysis'),
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∫–∞–∫ [] (–∞ –Ω–µ NULL), —á—Ç–æ–±—ã –æ—Ç–ª–∏—á–∞—Ç—å
                            # "–Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π" –æ—Ç "–ø–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
                            recommendations=analysis_data.get('recommendations', []),
                        )

                        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è –≤ businesses (rich model)
                        try:
                            sync_payload = {
                                "address": card_data.get("address"),
                                "phone": phone or None,
                                "site": website or None,
                                "rating": rating_float,
                                "reviews_count": reviews_count,
                                "categories": card_data.get("categories"),
                                "hours": hours_struct,
                                "hours_full": hours_full or None,
                                "description": card_data.get("description") or (card_data.get("overview") or {}).get("description"),
                                "industry": card_data.get("industry"),
                                "geo": card_data.get("geo"),
                                "external_ids": card_data.get("external_ids"),
                            }
                            db_manager.update_business_from_card(business_id, sync_payload)
                            # –£—Å–ª—É–≥–∏ –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏ ‚Üí userservices (–¥–ª—è –≤–∫–ª–∞–¥–∫–∏ ¬´–£—Å–ª—É–≥–∏ –∏ —Ü–µ–Ω—ã¬ª)
                            owner_id = (db_manager.get_business_by_id(business_id) or {}).get("owner_id")
                            if owner_id and (card_data.get("products") or card_data.get("services")):
                                try:
                                    service_rows = map_card_services(card_data, business_id, owner_id)
                                    if service_rows:
                                        services_saved_count = db_manager.upsert_parsed_services(business_id, owner_id, service_rows)
                                        print(f"[Services] Saved {services_saved_count} services")
                                except Exception as svc_e:
                                    print(f"‚ö†Ô∏è upsert_parsed_services failed for {business_id}: {svc_e}")
                        except Exception as sync_e:
                            print(f"‚ö†Ô∏è Failed to update businesses from card for {business_id}: {sync_e}")

                    except Exception as e:
                        # –ü–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ –æ—à–∏–±–æ—á–Ω–æ–π, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–∞–ª–∞ –≤ processing
                        err_text = f"save_failed:{e.__class__.__name__}:{e}"
                        _handle_worker_error(queue_dict["id"], err_text)
                        db_manager.close()
                        raise
                    else:
                        # MapParseResults –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (Progress, growth_api)
                        try:
                            mpr_fields = {
                                'rating': rating_float,
                                'reviews_count': reviews_count,
                                'photos_count': photos_count,
                                'news_count': len(news_list or []),
                            }
                            print(f"[METRICS_SAVE] {business_id} | rating={mpr_fields['rating']} | reviews={mpr_fields['reviews_count']} | photos={mpr_fields['photos_count']} | news={mpr_fields['news_count']}")
                            _upsert_map_parse_from_card(
                                db_manager.conn,
                                business_id,
                                url=queue_dict["url"],
                                rating=mpr_fields['rating'],
                                reviews_count=mpr_fields['reviews_count'],
                                photos_count=mpr_fields['photos_count'],
                                news_count=mpr_fields['news_count'],
                                products=products if products else None,
                                competitors=competitors if competitors else None,
                            )
                        except Exception as mpr_e:
                            print(f"‚ùå [MapParseResults] Failed for {business_id}: {mpr_e}")
                            traceback.print_exc()
                        db_manager.close()

                    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –ª–æ–≥: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤
                    title_snippet = (card_data.get('name') or card_data.get('title') or '')[:80]
                    _products = card_data.get("products") or []
                    _news = card_data.get("news") or []
                    _photos = card_data.get("photos") or []
                    if isinstance(_photos, int):
                        _photos = []
                    _competitors = card_data.get("competitors") or []
                    _hours_full = card_data.get("hours_full") or []
                    print(
                        f"[PARSE_DIAG] business_id={business_id} queue_id={queue_dict.get('id')} "
                        f"title={title_snippet!r} address_present={bool(card_data.get('address'))} "
                        f"rating={rating_float} reviews_count={reviews_count} "
                        f"products_len={len(_products) if isinstance(_products, list) else 0} "
                        f"news_len={len(_news) if isinstance(_news, list) else 0} "
                        f"photos_len={len(_photos) if isinstance(_photos, list) else 0} "
                        f"competitors_len={len(_competitors) if isinstance(_competitors, list) else 0} "
                        f"hours_full_len={len(_hours_full) if isinstance(_hours_full, list) else 0} "
                        f"services_saved_count={services_saved_count}"
                    )
                    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ cards –¥–ª—è business_id={business_id}")
                    
                    # --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø SyncWorker –î–õ–Ø –°–û–•–†–ê–ù–ï–ù–ò–Ø –î–ï–¢–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• ---
                    try:
                        import re
                        
                        db_manager = None
                        try:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º DatabaseManager –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è–º–∏
                            db_manager = DatabaseManager()
                            sync_worker = YandexBusinessSyncWorker()
                            
                            # DEBUG LOGGING
                            try:
                                from worker_debug_helper import debug_log
                                from safe_db_utils import get_db_path
                                db_path_debug = get_db_path()
                                r_len = len(reviews_list) if reviews_list else 0
                                # –†–∞—Å—á—ë—Ç –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ (–µ—Å–ª–∏ reviews_list –æ–ø—Ä–µ–¥–µ–ª—ë–Ω)
                                if 'reviews_list' in locals() and reviews_list:
                                    unanswered_reviews_count = sum(
                                        1 for r in reviews_list
                                        if not r.get("org_reply")
                                    )
                                else:
                                    unanswered_reviews_count = 0
                                debug_log(f"Worker DB Path: {db_path_debug}")
                                debug_log(f"Reviews in list: {r_len}")
                                debug_log(f"Unanswered calc: {unanswered_reviews_count}")
                            except Exception as e:
                                print(f"Debug log fail: {e}")
                            
                            # 1. –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ó–´–í–û–í (–° –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ï–ô)
                            if reviews_list:
                                external_reviews = []
                                seen_review_ids = set()
                                
                                for review in reviews_list:
                                    if not review.get('text'):
                                        continue
                                    
                                    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º ID –æ—Ç–∑—ã–≤–∞ –∏–ª–∏ —Ö–µ—à –æ—Ç —Ç–µ–∫—Å—Ç–∞+–∞–≤—Ç–æ—Ä–∞
                                    raw_id = review.get('id')
                                    if raw_id:
                                        unique_key = str(raw_id)
                                    else:
                                        author = review.get('author') or 'Anon'
                                        text_snippet = (review.get('text') or '')[:50]
                                        unique_key = f"{author}_{text_snippet}"
                                        
                                    if unique_key in seen_review_ids:
                                        continue
                                    seen_review_ids.add(unique_key)
                                    
                                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –¥–ª—è –Ω–∞—à–µ–π –ë–î (–¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, —á—Ç–æ–±—ã –∏–∑–±–µ–≥–∞—Ç—å –¥—É–±–ª–µ–π)
                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º business_id + author + text snippet (–±–µ–∑ –æ—Ç–≤–µ—Ç–∞, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç –æ–±–Ω–æ–≤–ª—è–ª –∑–∞–ø–∏—Å—å, –∞ –Ω–µ —Å–æ–∑–¥–∞–≤–∞–ª –Ω–æ–≤—É—é)
                                    text_part = (review.get('text') or '').strip()
                                    unique_string = f"{business_id}_{review.get('author')}_{text_part}"
                                    review_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, unique_string))
                                    external_review_id = raw_id or f"html_{review_id}"
                                    
                                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                                    published_at = None
                                    response_text = None
                                    response_at = None
                                    
                                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                                    date_value = _extract_date_from_review(review)
                                    
                                    if date_value:
                                        if isinstance(date_value, (int, float)):
                                            published_at = _parse_timestamp_to_datetime(date_value)
                                        elif isinstance(date_value, str):
                                            published_at = _parse_date_string(date_value)
                                    
                                    # –û—Ç–≤–µ—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
                                    response_text = review.get('org_reply') or review.get('response_text') or ''
                                    response_text = response_text.strip() if response_text else None
                                    response_at = None
                                    
                                    if review.get('response_date'):
                                        response_at = _parse_date_string(str(review.get('response_date')))
                                    
                                    # –†–µ–π—Ç–∏–Ω–≥
                                    r_val = review.get('score') or review.get('rating')
                                    try:
                                        r_val = int(r_val) if r_val else None
                                    except:
                                        r_val = None
                                    
                                    external_review = ExternalReview(
                                        id=review_id,
                                        business_id=business_id,
                                        source=ExternalSource.YANDEX_MAPS,
                                        external_review_id=external_review_id,
                                        rating=r_val,
                                        author_name=review.get('author') or '–ê–Ω–æ–Ω–∏–º–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å',
                                        text=review.get('text'),
                                        published_at=published_at,
                                        response_text=response_text,
                                        response_at=response_at,
                                        raw_payload=review
                                    )
                                    external_reviews.append(external_review)
                                
                                if external_reviews:
                                    sync_worker._upsert_reviews(db_manager, external_reviews)
                                    db_manager.conn.commit()
                                    print(f"‚úÖ Saved {len(external_reviews)} reviews to ExternalBusinessReviews")

                            # 2. –°–û–•–†–ê–ù–ï–ù–ò–ï –ù–û–í–û–°–¢–ï–ô (Posts)
                            news_items = card_data.get('news', [])
                            if news_items:
                                external_posts = []
                                for item in news_items:
                                    post_text = item.get('text')
                                    if not post_text:
                                        continue
                                        
                                    post_id = str(uuid.uuid4())
                                    # –ü—ã—Ç–∞–µ–º—Å—è –¥–∞—Ç—É –¥–æ—Å—Ç–∞—Ç—å
                                    pub_at = None
                                    if item.get('date'):
                                        pub_at = _parse_date_string(item['date'])
                                        
                                    ext_post = ExternalPost(
                                        id=post_id,
                                        business_id=business_id,
                                        source=ExternalSource.YANDEX_MAPS,
                                        external_post_id=f"html_{post_id}", # –ù–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ ID –≤ HTML
                                        title=item.get('title') or (post_text[:30] + '...'),
                                        text=post_text,
                                        published_at=pub_at, # Keep None if not found, don't fake it with now()
                                        image_url=None, # HTML scraper rarely gets clean image URLs for news context
                                        raw_payload=item
                                    )
                                    external_posts.append(ext_post)
                                
                                if external_posts:
                                    try:
                                        sync_worker._upsert_posts(db_manager, external_posts)
                                        print(f"‚úÖ Saved {len(external_posts)} posts to ExternalBusinessPosts")
                                    except Exception as posts_err:
                                        # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Å–∏–Ω–∫ —É—Å–ª—É–≥/—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –ø–æ—Å—Ç–æ–≤ –µ—â—ë –Ω–µ –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞.
                                        print(f"‚ö†Ô∏è Skip posts sync (ExternalBusinessPosts unavailable): {posts_err}")

                            # 3. –°–û–•–†–ê–ù–ï–ù–ò–ï –£–°–õ–£–ì (Services)
                            products = card_data.get('products')
                            if products:
                                services_count = len(products)
                                # Fetch owner_id for service syncing
                                cursor.execute("SELECT owner_id FROM businesses WHERE id = %s", (business_id,))
                                owner_row = cursor.fetchone()
                                if owner_row:
                                    owner_id = owner_row[0] if isinstance(owner_row, (list, tuple)) else owner_row.get("owner_id")
                                    sync_worker._sync_services_to_db(db_manager.conn, business_id, products, owner_id)
                                    print(f"üíæ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {services_count} —É—Å–ª—É–≥ (owner_id={owner_id})")
                                else:
                                    print(f"‚ö†Ô∏è Cannot sync services: owner_id not found for business {business_id}")

                            # 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò (Rating History)
                            if rating and reviews_count is not None:
                                today = datetime.now().strftime('%Y-%m-%d')
                                stats_id = make_stats_id(business_id, ExternalSource.YANDEX_MAPS, today)
                                
                                try:
                                    rating_val = float(rating)
                                except:
                                    rating_val = 0.0
                                    
                                stat_point = ExternalStatsPoint(
                                    id=stats_id,
                                    business_id=business_id,
                                    source=ExternalSource.YANDEX_MAPS,
                                    date=today,
                                    rating=rating_val,
                                    reviews_total=reviews_count,
                                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è None, —Ç–∞–∫ –∫–∞–∫ –ø—É–±–ª–∏—á–Ω—ã–µ –∫–∞—Ä—Ç—ã –∏—Ö –Ω–µ –¥–∞—é—Ç
                                    views_total=None,
                                    actions_total=None
                                )
                                sync_worker._upsert_stats(db_manager, [stat_point])
                                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–†–µ–π—Ç–∏–Ω–≥: {rating_val}, –û—Ç–∑—ã–≤–æ–≤: {reviews_count})")

                            # Commit changes to External Data tables
                            if db_manager and db_manager.conn:
                                db_manager.conn.commit()
                                print("üíæ Detailed data committed successfully")

                        finally:
                            if db_manager:
                                db_manager.close()
                                
                    except Exception as det_err:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (reviews/posts/stats): {det_err}")
                        traceback.print_exc()

                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ cards: {e}")
                    traceback.print_exc()
                    try:
                        from user_api import send_email
                        send_email(
                            "demyanovap@yandex.ru",
                            "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç—ã",
                            f"URL: {queue_dict['url']}\nBusiness ID: {business_id}\n–û—à–∏–±–∫–∞: {e}"
                        )
                    except:
                        pass
                    raise
            else:
                # –°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Cards
                card_id = str(uuid.uuid4())
                
                rating = card_data.get("rating")
                if rating == "" or rating is None:
                    rating = None
                else:
                    try:
                        rating = float(rating)
                    except (ValueError, TypeError):
                        rating = None
                        
                reviews_count = card_data.get("reviews_count")
                if reviews_count == "" or reviews_count is None:
                    reviews_count = None
                else:
                    try:
                        reviews_count = int(reviews_count)
                    except (ValueError, TypeError):
                        reviews_count = None
                
                cursor.execute("""
                    INSERT INTO cards (
                        id, user_id, url, title, address, phone, site, rating,
                        reviews_count, categories, overview, products, news,
                        photos, features_full, competitors, hours, hours_full,
                        created_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    card_id,
                    queue_dict["user_id"],
                    queue_dict["url"],
                    card_data.get("title"),
                    card_data.get("address"),
                    card_data.get("phone"),
                    card_data.get("site"),
                    rating,
                    reviews_count,
                    json.dumps(card_data.get("categories", [])),
                    json.dumps(
                        {
                            **(card_data.get("overview") or {}),
                            **({"_meta": card_data["_meta"]} if card_data.get("_meta") else {}),
                        },
                        ensure_ascii=False,
                    ),
                    json.dumps(card_data.get("products", [])),
                    json.dumps(card_data.get("news", [])),
                    json.dumps(card_data.get("photos", [])),
                    json.dumps(card_data.get("features_full", {})),
                    json.dumps(card_data.get("competitors", [])),
                    card_data.get("hours"),
                    json.dumps(card_data.get("hours_full", [])),
                    datetime.now().isoformat()
                ))
                
                # –ü–æ–ø—ã—Ç–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–æ–≤ –¥–∞–∂–µ –¥–ª—è —Å—Ç–∞—Ä–æ–π —Å—Ö–µ–º—ã (–µ—Å–ª–∏ –µ—Å—Ç—å owner_id)
                # –ù–æ —É –Ω–∞—Å –Ω–µ—Ç business_id –∑–¥–µ—Å—å, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                pass
                
                print(f"–í—ã–ø–æ–ª–Ω—è–µ–º –ò–ò-–∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞—Ä—Ç–æ—á–∫–∏ {card_id}...")
                
                try:
                    analysis_result = analyze_business_data(card_data)
                    
                    cursor.execute("""
                        UPDATE cards SET
                            ai_analysis = %s,
                            seo_score = %s,
                            recommendations = %s
                        WHERE id = %s
                    """, (
                        json.dumps(analysis_result.get('analysis', {})),
                        analysis_result.get('score', 50),
                        json.dumps(analysis_result.get('recommendations', [])),
                        card_id
                    ))
                    
                    print(f"–ò–ò-–∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω –¥–ª—è –∫–∞—Ä—Ç–æ—á–∫–∏ {card_id}")
                    
                    try:
                        from report import generate_html_report
                        analysis_data = {
                            'score': analysis_result.get('score', 50),
                            'recommendations': analysis_result.get('recommendations', []),
                            'ai_analysis': analysis_result.get('analysis', {})
                        }
                        report_path = generate_html_report(card_data, analysis_data)
                        print(f"HTML –æ—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {report_path}")
                        cursor.execute("UPDATE cards SET report_path = %s WHERE id = %s", (report_path, card_id))
                    except Exception as report_error:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞ –¥–ª—è –∫–∞—Ä—Ç–æ—á–∫–∏ {card_id}: {report_error}")
                        
                except Exception as analysis_error:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ò–ò-–∞–Ω–∞–ª–∏–∑–µ –∫–∞—Ä—Ç–æ—á–∫–∏ {card_id}: {analysis_error}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "completed" (—á—Ç–æ–±—ã –∑–∞–¥–∞—á–∞ –æ—Å—Ç–∞–ª–∞—Å—å –≤ —Å–ø–∏—Å–∫–µ)
            warning_parts = []
            # –°—Ç–∞—Ä–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–æ HTML fallback (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç)
            if card_data.get('fallback_used'):
                warning_parts.append("‚ö†Ô∏è Fast Endpoint Outdated (Used HTML Fallback)")

            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º CRITICAL-–ø–æ–ª—è–º –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
            if validation_result:
                missing_fields = set(validation_result.get("missing_fields", []) or [])
                critical_missing = [f for f in FIELDS_CRITICAL if f in missing_fields]
                if critical_missing:
                    warning_parts.append(
                        "warnings_missing_in_source:" + ",".join(critical_missing)
                    )

            warning_msg = " | ".join(warning_parts) if warning_parts else None

            # –û–±–Ω–æ–≤–ª—è–µ–º completed: error_message = NULL, warnings ‚Äî —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º fallback –ø—Ä–∏ UndefinedColumn
            try:
                cursor.execute(
                    "UPDATE parsequeue SET status = %s, error_message = NULL, warnings = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                    (STATUS_COMPLETED, warning_msg, queue_dict["id"]),
                )
            except Exception as upd_err:
                # Fallback —Ç–æ–ª—å–∫–æ –¥–ª—è PostgreSQL UndefinedColumn (pgcode 42703).
                if getattr(upd_err, "pgcode", None) == "42703":
                    # –ö–æ–ª–æ–Ω–∫–∏ warnings –Ω–µ—Ç ‚Äî –ø–∏—à–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤ error_message —Ç–æ–ª—å–∫–æ –≤ —ç—Ç–æ–º fallback
                    cursor.execute(
                        "UPDATE parsequeue SET status = %s, error_message = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                        (STATUS_COMPLETED, warning_msg, queue_dict["id"]),
                    )
                else:
                    raise
            conn.commit()
            
            print(f"‚úÖ –ó–∞—è–≤–∫–∞ {queue_dict['id']} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.")
            signal.alarm(0)  # –û—Ç–∫–ª—é—á–∞–µ–º —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
            
        finally:
            try:
                if 'cursor' in locals() and cursor:
                    cursor.close()
            except:
                pass
            try:
                if 'conn' in locals() and conn:
                    conn.close()
            except:
                pass
            
    except Exception as e:
        signal.alarm(0)  # –û—Ç–∫–ª—é—á–∞–µ–º —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
        queue_id = queue_dict.get('id', 'unknown') if queue_dict else 'unknown'
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞—è–≤–∫–∏ {queue_id}: {e}")
        traceback.print_exc()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–∫–∏
        conn = get_db_connection()
        cursor = conn.cursor()
        try:
            cursor.execute("UPDATE parsequeue SET status = %s, error_message = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                         (STATUS_ERROR, str(e), queue_id))
            conn.commit()
            print(f"‚ö†Ô∏è –ó–∞—è–≤–∫–∞ {queue_id} –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ –æ—à–∏–±–∫–∞.")
        except Exception as update_error:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞—è–≤–∫–∏ {queue_id}: {update_error}")
        finally:
            cursor.close()
            conn.close()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º email (–æ—à–∏–±–∫–∞ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞)
        try:
            from user_api import send_email
            send_email(
                "demyanovap@yandex.ru",
                "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç—ã",
                f"URL: {queue_dict.get('url', 'unknown') if queue_dict else 'unknown'}\n–û—à–∏–±–∫–∞: {e}"
            )
        except Exception as email_error:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å email: {email_error}")

def map_card_services(card_data: Dict[str, Any], business_id: str, user_id: str) -> List[Dict[str, Any]]:
    """
    –ß–∏—Å—Ç—ã–π –º–∞–ø–ø–µ—Ä: –∏–∑ card_data (products/services) –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è userservices.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É: —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å items –∏–ª–∏ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
    """
    products = card_data.get("products") or card_data.get("services") or []
    print(f"[map_card_services] Found {len(products) if isinstance(products, list) else 0} product categories for {business_id}")
    if not products:
        print(f"[map_card_services] No products in card_data. Keys: {list(card_data.keys())}")
        return []
    if not isinstance(products, list):
        print(f"[map_card_services] No products in card_data. Keys: {list(card_data.keys())}")
        return []
    rows = []
    seen = set()
    source = "yandex_maps"
    for cat_block in products:
        # cat_block –º–æ–∂–µ—Ç –±—ã—Ç—å: dict (–∫–∞—Ç–µ–≥–æ—Ä–∏—è), list (–≤–ª–æ–∂–µ–Ω–Ω—ã–µ items), –∏–ª–∏ –º—É—Å–æ—Ä
        if isinstance(cat_block, list):
            # –ü–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ items –±–µ–∑ –æ–±—ë—Ä—Ç–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            items = cat_block
            category_name = "–†–∞–∑–Ω–æ–µ"
            for item in items:
                if isinstance(item, dict) and item.get("name"):
                    row = _one_service_row(item, business_id, user_id, source)
                    if row:
                        row["category"] = category_name
                        key = (
                            (row.get("source") or "").lower(),
                            (row.get("name") or "").strip().lower(),
                            (row.get("category") or "").strip().lower(),
                            str(row.get("price_from") or ""),
                            str(row.get("price_to") or ""),
                        )
                        if key in seen:
                            continue
                        seen.add(key)
                        rows.append(row)
            continue

        if not isinstance(cat_block, dict):
            # –ü—Ä–∏–º–∏—Ç–∏–≤—ã –∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–∏–ø—ã ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: dict —Å category –∏ items
        category_name = (cat_block.get("category") or "–†–∞–∑–Ω–æ–µ").strip() or "–†–∞–∑–Ω–æ–µ"
        items = cat_block.get("items") or cat_block.get("products") or []
        if not isinstance(items, list):
            continue

        for item in items:
            if not isinstance(item, dict) or not item.get("name"):
                continue
            row = _one_service_row(item, business_id, user_id, source)
            if row:
                row["category"] = category_name
                key = (
                    (row.get("source") or "").lower(),
                    (row.get("name") or "").strip().lower(),
                    (row.get("category") or "").strip().lower(),
                    str(row.get("price_from") or ""),
                    str(row.get("price_to") or ""),
                )
                if key in seen:
                    continue
                seen.add(key)
                rows.append(row)
    return rows


def _one_service_row(item: Dict[str, Any], business_id: str, user_id: str, source: str) -> Dict[str, Any]:
    """–û–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç —É—Å–ª—É–≥–∏ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ –¥–ª—è userservices."""
    name = (item.get("name") or "").strip() or None
    if not name:
        return {}
    external_id = item.get("id") or item.get("external_id")
    if external_id is not None:
        external_id = str(external_id).strip() or None
    raw_price = item.get("price") or item.get("price_from") or ""
    price_from, price_to = _parse_service_price(raw_price)
    return {
        "business_id": business_id,
        "user_id": user_id,
        "name": name,
        "description": (item.get("description") or "").strip() or None,
        "category": (item.get("category") or "–†–∞–∑–Ω–æ–µ").strip() or "–†–∞–∑–Ω–æ–µ",
        "source": source,
        "external_id": external_id,
        "price_from": price_from,
        "price_to": price_to,
        "raw": (dict(item) if isinstance(item, dict) else {"_error": "not_a_dict", "_type": type(item).__name__}),
        "duration_minutes": item.get("duration_minutes") or item.get("duration"),
    }


def _parse_service_price(raw_price: Any) -> tuple[Optional[float], Optional[float]]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ü–µ–Ω—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç –≤ —Ä—É–±–ª–∏."""
    if raw_price is None:
        return None, None
    s = str(raw_price).strip()
    if not s:
        return None, None
    numbers = re.findall(r"\d+", s)
    if not numbers:
        return None, None
    try:
        # –Ø–≤–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: "1000-1500", "1000 ‚Äì 1500", "–æ—Ç 1000 –¥–æ 1500"
        if len(numbers) >= 2 and (re.search(r"[-‚Äì‚Äî]", s) or " –¥–æ " in s.lower()):
            n1, n2 = int(numbers[0]), int(numbers[1])
            return float(min(n1, n2)), float(max(n1, n2))

        # –¢—ã—Å—è—á–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: "1.650", "1,650", "1 650" => 1650
        if len(numbers) >= 2:
            compact = "".join(numbers[:2])
            if compact.isdigit():
                return float(int(compact)), float(int(compact))

        n = int(numbers[0])
        return float(n), float(n)
    except (ValueError, TypeError):
        return None, None


def _sync_parsed_services_to_db(business_id: str, products: list, conn, owner_id: str):
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∞—Ä—à–µ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ –≤ —Ç–∞–±–ª–∏—Ü—É UserServices.
    –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ, –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ü–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö.
    """
    if not products:
        return

    # STRICT CHECK: owner_id required
    if not owner_id:
        print(f"‚ö†Ô∏è Service sync skipped: owner_id is missing for business {business_id}")
        # Raising error to fail fast as per plan, but let's confirm logic
        raise ValueError(f"owner_id (str) is required for service sync for business {business_id}")

    cursor = conn.cursor()
    
    # –°—Ç–∞—Ä—ã–π –ø—É—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –≤ —Ç–∞–±–ª–∏—Ü—É UserServices –∏—Å–ø–æ–ª—å–∑—É–µ—Ç SQLite-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.
    # –í PostgreSQL –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã –ø–æ —É—Å–ª—É–≥–∞–º ‚Äî YandexBusinessSyncWorker –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã,
    # –ø–æ—ç—Ç–æ–º—É –∑–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å worker.
    if DB_TYPE == "postgres":
        print(f"‚ö†Ô∏è Service sync via _sync_parsed_services_to_db –ø—Ä–æ–ø—É—â–µ–Ω –¥–ª—è Postgres (business_id={business_id})")
        return

    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü—ã UserServices –∏ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (SQLite)
    cursor.execute("SELECT to_regclass('public.userservices')")
    if not cursor.fetchone():
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç, —Å–æ–∑–¥–∞—ë–º (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS UserServices (
                id TEXT PRIMARY KEY,
                business_id TEXT NOT NULL,
                name TEXT NOT NULL,
                description TEXT,
                category TEXT,
                price INTEGER, -- —Ü–µ–Ω–∞ –≤ –∫–æ–ø–µ–π–∫–∞—Ö
                duration INTEGER DEFAULT 60,
                is_active INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                user_id TEXT,
                FOREIGN KEY (business_id) REFERENCES businesses(id) ON DELETE CASCADE
            )
        """
        )
    
    count_new = 0
    count_updated = 0
    
    print(f"üë§ Syncing services for owner_id: {owner_id}")
    
    for category_data in products:


        category_name = category_data.get('category', '–†–∞–∑–Ω–æ–µ')
        items = category_data.get('items', [])
        
        for item in items:
            name = item.get('name')
            if not name:
                continue
                
            raw_price = item.get('price', '')
            description = item.get('description', '')
            
            # –ü–∞—Ä—Å–∏–Ω–≥ —Ü–µ–Ω—ã
            price_cents = None
            if raw_price:
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
                try:
                    # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ —Å—Ç—Ä–æ–∫–µ
                    import re
                    # "–æ—Ç 1 500 ‚ÇΩ" -> "1500"
                    digits = re.sub(r'[^0-9]', '', str(raw_price))
                    if digits:
                        price_cents = int(digits) * 100 # –í –∫–æ–ø–µ–π–∫–∏
                except:
                    pass
            
            # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —É—Å–ª—É–≥—É –ø–æ –∏–º–µ–Ω–∏ –∏ business_id
            cursor.execute(
                """
                SELECT id FROM userservices
                WHERE business_id = %s AND name = %s
                """,
                (business_id, name),
            )
            row = cursor.fetchone()
            service_id = (row[0] if isinstance(row, (list, tuple)) else row.get("id")) if row else None

            if service_id:
                cursor.execute(
                    """
                    UPDATE userservices
                    SET price = %s, description = %s, category = %s, updated_at = CURRENT_TIMESTAMP, is_active = TRUE
                    WHERE id = %s
                    """,
                    (price_cents, description, category_name, service_id),
                )
                count_updated += 1
            else:
                service_id = str(uuid.uuid4())
                cursor.execute(
                    """
                    INSERT INTO userservices (id, business_id, user_id, name, description, category, price, is_active)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, TRUE)
                    """,
                    (service_id, business_id, owner_id, name, description, category_name, price_cents),
                )
                count_new += 1
                
    conn.commit()
    print(f"üìä –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É—Å–ª—É–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {count_new} –Ω–æ–≤—ã—Ö, {count_updated} –æ–±–Ω–æ–≤–ª–µ–Ω–æ.")

def _process_sync_yandex_business_task(queue_dict):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –Ø–Ω–¥–µ–∫—Å.–ë–∏–∑–Ω–µ—Å —á–µ—Ä–µ–∑ –∫–∞–±–∏–Ω–µ—Ç"""
    import signal
    import sys
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç 10 –º–∏–Ω—É—Ç –¥–ª—è –∑–∞–¥–∞—á–∏
    def timeout_handler(signum, frame):
        raise TimeoutError("–ó–∞–¥–∞—á–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ —Ç–∞–π–º–∞—É—Ç 10 –º–∏–Ω—É—Ç")
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(600)  # 10 –º–∏–Ω—É—Ç
    
    try:
        business_id = queue_dict.get("business_id")
        account_id = queue_dict.get("account_id")
        
        if not business_id or not account_id:
            print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç business_id –∏–ª–∏ account_id –¥–ª—è –∑–∞–¥–∞—á–∏ {queue_dict.get('id')}", flush=True)
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE parsequeue
                SET status = 'error',
                    error_message = %s,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, ("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç business_id –∏–ª–∏ account_id", queue_dict["id"]))
            conn.commit()
            cursor.close()
            conn.close()
            signal.alarm(0)  # –û—Ç–º–µ–Ω—è–µ–º —Ç–∞–π–º–∞—É—Ç
            return
        
        print(f"üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ø–Ω–¥–µ–∫—Å.–ë–∏–∑–Ω–µ—Å –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}", flush=True)
        
        from yandex_business_parser import YandexBusinessParser
        from yandex_business_sync_worker import YandexBusinessSyncWorker
        from auth_encryption import decrypt_auth_data
        from database_manager import DatabaseManager
        import json
        
        # –ü–æ–ª—É—á–∞–µ–º auth_data
        db = None  # Initialize to None for safe cleanup
        try:
            db = DatabaseManager()
            cursor = db.conn.cursor()
        

            cursor.execute("""
                SELECT auth_data_encrypted, external_id
                FROM externalbusinessaccounts
                WHERE id = %s AND business_id = %s
            """, (account_id, business_id))
            account_row = cursor.fetchone()
            if not account_row:
                raise Exception("–ê–∫–∫–∞—É–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            if isinstance(account_row, (list, tuple)):
                auth_data_encrypted, external_id = account_row[0], (account_row[1] if len(account_row) > 1 else None)
            else:
                auth_data_encrypted = account_row.get("auth_data_encrypted")
                external_id = account_row.get("external_id")
            auth_data_plain = decrypt_auth_data(auth_data_encrypted)
            
            if not auth_data_plain:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å auth_data")
            
            # –ü–∞—Ä—Å–∏–º auth_data
            try:
                auth_data_dict = json.loads(auth_data_plain)
            except json.JSONDecodeError:
                auth_data_dict = {"cookies": auth_data_plain}
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
            parser = YandexBusinessParser(auth_data_dict)
            account_data = {
                "id": account_id,
                "business_id": business_id,
                "external_id": external_id
            }
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞
            print(f"üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞...")
            reviews = parser.fetch_reviews(account_data)
            print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
            
            print(f"üì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞...")
            stats = parser.fetch_stats(account_data)
            print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Ç–æ—á–µ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {len(stats)}")
            
            print(f"üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–π –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞...")
            posts = parser.fetch_posts(account_data)
            print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {len(posts)}")
            
            print(f"üì• –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞...")
            org_info = parser.fetch_organization_info(account_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–∑—ã–≤—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            worker = YandexBusinessSyncWorker()
            if reviews:
                worker._upsert_reviews(db, reviews)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews)}")
            
            if stats:
                worker._upsert_stats(db, stats)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ç–æ—á–µ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {len(stats)}")
            
            if posts:
                worker._upsert_posts(db, posts)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {len(posts)}")
            
            # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ cards (Postgres source of truth)
            cursor.execute("""
                SELECT rating, reviews_count, overview
                FROM cards
                WHERE business_id = %s
                ORDER BY created_at DESC
                LIMIT 1
            """, (business_id,))
            existing_row = cursor.fetchone()
            existing_data = None
            if existing_row:
                if isinstance(existing_row, (list, tuple)):
                    existing_data = {'rating': existing_row[0], 'reviews_count': existing_row[1], 'overview': existing_row[2] if len(existing_row) > 2 else None}
                else:
                    existing_data = dict(existing_row) if hasattr(existing_row, 'keys') else None

            current_reviews_count = len(reviews) if reviews else 0
            rating = org_info.get('rating')
            if not rating and existing_data and existing_data.get('rating') is not None:
                rating = existing_data['rating']
            if current_reviews_count == 0 and existing_data and (existing_data.get('reviews_count') or 0) > 0:
                reviews_count = existing_data['reviews_count']
            else:
                reviews_count = current_reviews_count
            reviews_without_response = sum(1 for r in reviews if not getattr(r, 'response_text', None)) if reviews else 0
            current_news = len(posts) if posts else 0
            news_count = current_news
            current_photos = org_info.get('photos_count', 0) if org_info else 0
            photos_count = current_photos

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–µ–∑ –≤ cards, –Ω–µ –∑–∞—Ç–∏—Ä–∞—è rich-–ø–æ–ª—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∫–∞—Ä—Ç–æ—á–∫–∏.
            url = f"https://yandex.ru/sprav/{external_id or 'unknown'}"
            overview_payload = {
                "photos_count": photos_count,
                "news_count": news_count,
                "snapshot_type": "metrics_update",
            }
            try:
                # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç–æ—á–∫—É, —á—Ç–æ–±—ã —É–Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å products/news/photos/...,
                # –∏–Ω–∞—á–µ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –±—É–¥–µ—Ç –ø—É—Å—Ç–æ–π.
                existing_card = db.get_latest_card_by_business(business_id)
                inherit_fields = {}
                if existing_card:
                    for key in (
                        "products",
                        "news",
                        "photos",
                        "features_full",
                        "competitors",
                        "hours",
                        "hours_full",
                        "categories",
                        "description",
                        "industry",
                        "geo",
                        "external_ids",
                    ):
                        if key in existing_card and existing_card[key] is not None:
                            inherit_fields[key] = existing_card[key]

                # Safeguard: –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–µ—Ç –Ω–∏ rich-–ø–æ–ª–µ–π, –Ω–∏ –º–µ—Ç—Ä–∏–∫ ‚Äî –Ω–µ –ø–ª–æ–¥–∏–º –ø—É—Å—Ç—ã–µ –≤–µ—Ä—Å–∏–∏.
                has_rich = bool(inherit_fields)
                has_metrics = (
                    rating is not None
                    or (reviews_count not in (None, 0))
                    or (photos_count not in (None, 0))
                    or (news_count not in (None, 0))
                )

                if has_rich or has_metrics:
                    db.save_new_card_version(
                        business_id,
                        url=url,
                        rating=float(rating) if rating is not None else None,
                        reviews_count=int(reviews_count or 0),
                        overview=overview_payload,
                        **inherit_fields,
                    )
                else:
                    # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ worker, –Ω–æ —è–≤–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Å–∏—Ç—É–∞—Ü–∏—é –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏.
                    print(
                        f"[CARDS_SYNC] Skip creating new card version for business_id={business_id}: "
                        f"no rich fields and no metrics"
                    )
            except Exception as card_err:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ cards (sync): {card_err}")

            try:
                metric_history_id = str(uuid.uuid4())
                current_date = datetime.now().strftime('%Y-%m-%d')
                cursor.execute("""
                    SELECT id FROM businessmetricshistory
                    WHERE business_id = %s AND metric_date = %s AND source = 'parsing'
                """, (business_id, current_date))
                existing_metric = cursor.fetchone()
                mid = existing_metric[0] if isinstance(existing_metric, (list, tuple)) else (existing_metric.get("id") if existing_metric else None)
                if mid:
                    cursor.execute("""
                        UPDATE businessmetricshistory
                        SET rating = %s, reviews_count = %s, photos_count = %s, news_count = %s
                        WHERE id = %s
                    """, (rating, reviews_count, photos_count, news_count, mid))
                else:
                    cursor.execute("""
                        INSERT INTO businessmetricshistory (
                            id, business_id, metric_date, rating, reviews_count,
                            photos_count, news_count, source
                        )
                        VALUES (%s, %s, %s, %s, %s, %s, %s, 'parsing')
                    """, (
                        metric_history_id,
                        business_id,
                        current_date,
                        rating,
                        reviews_count,
                        photos_count,
                        news_count,
                    ))
            except Exception as e:
                print(f"Error saving metrics history: {e}")
            
            db.conn.commit()
            # Safely close db and connections
            try:
                if 'db' in locals() and db:
                    db.close()
            except Exception:
                pass
            
            # The cursor and conn here refer to the ones created within the try block
            # associated with the DatabaseManager instance.
            try:
                if 'cursor' in locals() and cursor and not cursor.closed:
                    cursor.close()
            except Exception:
                pass
            try:
                if 'conn' in locals() and conn and not conn.closed:
                    conn.close()
            except Exception:
                pass
            
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE parsequeue
                SET status = %s,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, (STATUS_COMPLETED, queue_dict["id"]))
            conn.commit()
            try:
                if cursor:
                    cursor.close()
            except Exception:
                pass
            try:
                if conn:
                    conn.close()
            except Exception:
                pass

            print(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}", flush=True)
            signal.alarm(0)  # –û—Ç–º–µ–Ω—è–µ–º —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
            
        except TimeoutError as e:
            print(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}", flush=True)
            signal.alarm(0)
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–∫–∏
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE parsequeue
                SET status = 'error',
                    error_message = %s,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, (str(e), queue_dict["id"]))
            conn.commit()
            try:
                if cursor:
                    cursor.close()
            except:
                pass
            try:
                if conn:
                    conn.close()
            except:
                pass
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}", flush=True)
            traceback.print_exc(file=sys.stdout)
            sys.stdout.flush()
            signal.alarm(0)  # –û—Ç–º–µ–Ω—è–µ–º —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
            
            try:
                if 'db' in locals() and db:
                    db.close()
            except:
                pass
            
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE parsequeue
                SET status = 'error',
                    error_message = %s,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, (str(e), queue_dict["id"]))
            conn.commit()
            try:
                if cursor:
                    cursor.close()
            except:
                pass
            try:
                if conn:
                    conn.close()
            except:
                pass
            
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
        traceback.print_exc()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–∫–∏
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE parsequeue
            SET status = 'error',
                error_message = %s,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
        """, (str(e), queue_dict["id"]))
        conn.commit()
        try:
            if cursor:
                cursor.close()
        except:
            pass
        try:
            if conn:
                conn.close()
        except:
            pass

def _process_cabinet_fallback_task(queue_dict):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ fallback –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ –∫–∞–±–∏–Ω–µ—Ç"""
    business_id = queue_dict.get("business_id")
    account_id = queue_dict.get("account_id")
    
    if not business_id or not account_id:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç business_id –∏–ª–∏ account_id –¥–ª—è –∑–∞–¥–∞—á–∏ {queue_dict.get('id')}", flush=True)
        _handle_worker_error(queue_dict["id"], "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç business_id –∏–ª–∏ account_id")
        return
    
    print(f"üîÑ Fallback –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –∫–∞–±–∏–Ω–µ—Ç –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}", flush=True)
    
    try:
        from yandex_business_sync_worker import YandexBusinessSyncWorker
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º sync_account –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞
        worker = YandexBusinessSyncWorker()
        worker.sync_account(account_id)
        
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE parsequeue
            SET status = %s,
                updated_at = CURRENT_TIMESTAMP
        WHERE id = %s
        """, (STATUS_COMPLETED, queue_dict["id"]))
        conn.commit()
        cursor.close()
        conn.close()

        print(f"‚úÖ Fallback –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}", flush=True)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ fallback –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", flush=True)
        traceback.print_exc(file=sys.stdout)
        sys.stdout.flush()
        _handle_worker_error(queue_dict["id"], str(e))

def _process_sync_2gis_task(queue_dict):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å 2–ì–ò–° —á–µ—Ä–µ–∑ API"""
    business_id = queue_dict.get("business_id")
    target_url = queue_dict.get("url")
    user_id = queue_dict.get("user_id")
    
    print(f"üîÑ –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ 2–ì–ò–° –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}...", flush=True)
    
    try:
        from services.two_gis_client import TwoGISClient
        from external_sources import ExternalSource, ExternalStatsPoint, make_stats_id
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        # TODO: –ú–æ–∂–Ω–æ –±—Ä–∞—Ç—å –∫–ª—é—á –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –±–∏–∑–Ω–µ—Å–∞, –µ—Å–ª–∏ –º—ã —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞–º —Å–≤–æ–∏ –∫–ª—é—á–∏
        # –ü–æ–∫–∞ –±–µ—Ä–µ–º –∏–∑ ENV
        if not os.getenv("TWOGIS_API_KEY"):
            raise ValueError("TWOGIS_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")

        client = TwoGISClient()
        
        org_data = None
        
        # 1. –ï—Å–ª–∏ –µ—Å—Ç—å URL, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å ID –∏–ª–∏ –Ω–∞–π—Ç–∏ –ø–æ –Ω–µ–º—É
        if target_url:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL –≤–∏–¥–∞ https://2gis.ru/city/firm/70000001007629561
            import re
            match = re.search(r'/firm/(\d+)', target_url)
            if match:
                org_id = match.group(1)
                print(f"üîç –ù–∞–π–¥–µ–Ω ID –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –≤ URL: {org_id}")
                org_data = client.search_organization_by_id(org_id)
            else:
                # –ï—Å–ª–∏ URL —Å–ª–æ–∂–Ω—ã–π, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫–∞—Ç—å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é, –Ω–æ —ç—Ç–æ –Ω–µ—Ç–æ—á–Ω–æ
                pass
        
        # 2. –ï—Å–ª–∏ –ø–æ URL –Ω–µ –Ω–∞—à–ª–∏ (–∏–ª–∏ –µ–≥–æ –Ω–µ—Ç), –∏—â–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é/–∞–¥—Ä–µ—Å—É –∏–∑ –ë–î
        if not org_data:
            conn = get_db_connection()
            cursor = conn.cursor()
            try:
                cursor.execute("SELECT name, address FROM businesses WHERE id = %s", (business_id,))
                row = cursor.fetchone()
                if row:
                    name = row[0] if isinstance(row, (list, tuple)) else row.get("name")
                    address = row[1] if isinstance(row, (list, tuple)) else row.get("address")
                    query = f"{name} {address}"
                    print(f"üîç –ü–æ–∏—Å–∫ –≤ 2–ì–ò–° –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}")
                    items = client.search_organization_by_text(query)
                    if items:
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –í –∏–¥–µ–∞–ª–µ –Ω—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤.
                        org_data = items[0]
                        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è: {org_data.get('name')}")
            finally:
                cursor.close()
                conn.close()

        if not org_data:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –≤ 2–ì–ò–° –ø–æ ID –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—é")

        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        conn = get_db_connection()
        cursor = conn.cursor()
        
        try:
            reviews_data = org_data.get('reviews', {})
            rating = reviews_data.get('general_rating')
            reviews_count = reviews_data.get('general_review_count', 0)
            name = org_data.get('name')
            address = org_data.get('address_name') or (org_data.get('adm_div', [{}])[0].get('name') if org_data.get('adm_div') else None)
            contacts = org_data.get('contact_groups', [])
            phone = None
            website = None
            for group in contacts:
                for contact in group.get('contacts', []):
                    if contact.get('type') == 'phone_number':
                        phone = contact.get('value') or contact.get('text')
                    if contact.get('type') == 'website':
                        website = contact.get('value') or contact.get('text')
            schedule = org_data.get('schedule')
            schedule_json = json.dumps(schedule, ensure_ascii=False) if schedule else None

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ cards (Postgres)
            db_2gis = DatabaseManager()
            try:
                db_2gis.save_new_card_version(
                    business_id,
                    url=target_url or "",
                    title=name or "",
                    address=address or "",
                    phone=phone,
                    site=website,
                    rating=float(rating) if rating is not None else None,
                    reviews_count=int(reviews_count or 0),
                    hours=schedule_json,
                )
            finally:
                db_2gis.close()

            if rating is not None:
                today = datetime.now().strftime('%Y-%m-%d')
                stats_id = make_stats_id(business_id, ExternalSource.TWO_GIS, today)
                cursor.execute("""
                    INSERT INTO externalbusinessstats
                    (id, business_id, source, date, rating, reviews_total, updated_at)
                    VALUES (%s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
                    ON CONFLICT (id) DO UPDATE SET
                    rating = EXCLUDED.rating,
                    reviews_total = EXCLUDED.reviews_total,
                    updated_at = CURRENT_TIMESTAMP
                """, (stats_id, business_id, "2gis", today, float(rating), int(reviews_count)))
                print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ 2–ì–ò–° –æ–±–Ω–æ–≤–ª–µ–Ω–∞: –†–µ–π—Ç–∏–Ω–≥ {rating}, –û—Ç–∑—ã–≤–æ–≤ {reviews_count}")

            cursor.execute("""
                UPDATE parsequeue
                SET status = %s,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
            """, (STATUS_COMPLETED, queue_dict["id"]))
            
            conn.commit()
            print(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å 2–ì–ò–° —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {business_id}")
            
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            cursor.close()
            conn.close()

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ 2–ì–ò–°: {e}", flush=True)
        # import traceback
        # traceback.print_exc()
        _handle_worker_error(queue_dict["id"], str(e))


if __name__ == "__main__":
    print("Worker –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—á–µ—Ä–µ–¥–∏ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç...")
    while True:
        try:
            process_queue()
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ worker loop: {e}", flush=True)
            traceback.print_exc(file=sys.stdout)
            sys.stdout.flush()
        
        try:    
            time.sleep(10)  # 10 —Å–µ–∫—É–Ω–¥
        except Exception as e:
             # –ï—Å–ª–∏ sleep –ø—Ä–µ—Ä–≤–∞–Ω —Å–∏–≥–Ω–∞–ª–æ–º –∏–ª–∏ –æ—à–∏–±–∫–æ–π, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
             print(f"‚ö†Ô∏è Sleep interrupted: {e}", flush=True)
