#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ø–Ω–¥–µ–∫—Å.–í–æ—Ä–¥—Å—Ç–∞—Ç
"""

import os
import sys
import json
from datetime import datetime, timedelta
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__))))

from wordstat_client import WordstatClient
from wordstat_config import config

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    
    print("üîÑ –ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ø–Ω–¥–µ–∫—Å.–í–æ—Ä–¥—Å—Ç–∞—Ç...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if not config.is_configured():
        print("‚ùå API –Ø–Ω–¥–µ–∫—Å.–í–æ—Ä–¥—Å—Ç–∞—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        print(f"üîó –ü–æ–ª—É—á–∏—Ç–µ OAuth —Ç–æ–∫–µ–Ω –ø–æ —Å—Å—ã–ª–∫–µ: {config.get_auth_url()}")
        print("üìù –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–æ–∫–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è YANDEX_WORDSTAT_OAUTH_TOKEN")
        return False
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç
    client = WordstatClient(config.client_id, config.client_secret)
    client.set_access_token(config.oauth_token)
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±—å—é—Ç–∏-–∏–Ω–¥—É—Å—Ç—Ä–∏–∏ (—Ä–∞—Å—à–∏—Ä–µ–Ω—ã, –≤–∫–ª—é—á–∞—è –∫–æ—Å–º–µ—Ç–æ–ª–æ–≥–∏—é)
    beauty_keywords = [
        # –í–æ–ª–æ—Å—ã/—Å—Ç—Ä–∏–∂–∫–∏/–æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ
        "—Å—Ç—Ä–∏–∂–∫–∞ –∂–µ–Ω—Å–∫–∞—è", "—Å—Ç—Ä–∏–∂–∫–∞ –º—É–∂—Å–∫–∞—è", "—É–∫–ª–∞–¥–∫–∞ –≤–æ–ª–æ—Å",
        "–æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ –≤–æ–ª–æ—Å", "–º–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "–±–ª–æ–Ω–¥–∏—Ä–æ–≤–∞–Ω–∏–µ",
        "–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä—Å–∫–∞—è", "—Å–∞–ª–æ–Ω –∫—Ä–∞—Å–æ—Ç—ã", "–±–∞—Ä–±–µ—Ä—à–æ–ø",
        # –ù–æ–≥—Ç–∏
        "–º–∞–Ω–∏–∫—é—Ä", "–ø–µ–¥–∏–∫—é—Ä", "–≥–µ–ª—å-–ª–∞–∫", "–Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏–µ –Ω–æ–≥—Ç–µ–π",
        # SPA/–º–∞—Å—Å–∞–∂
        "–º–∞—Å—Å–∞–∂", "—Å–ø–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã", "–æ–±–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ",
        # –ë—Ä–æ–≤–∏/—Ä–µ—Å–Ω–∏—Ü—ã
        "–±—Ä–æ–≤–∏", "—Ä–µ—Å–Ω–∏—Ü—ã", "–ª–∞–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—Ä–æ–≤–µ–π", "–ª–∞–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å–Ω–∏—Ü",
        # –ö–æ—Å–º–µ—Ç–æ–ª–æ–≥–∏—è ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω–æ
        "–∫–æ—Å–º–µ—Ç–æ–ª–æ–≥–∏—è", "–∫–æ—Å–º–µ—Ç–æ–ª–æ–≥", "—á–∏—Å—Ç–∫–∞ –ª–∏—Ü–∞", "–ø–∏–ª–∏–Ω–≥ –ª–∏—Ü–∞",
        "–±–æ—Ç–æ–∫—Å", "–¥–∏—Å–ø–æ—Ä—Ç", "–∫–æ–Ω—Ç—É—Ä–Ω–∞—è –ø–ª–∞—Å—Ç–∏–∫–∞", "—Ñ–∏–ª–ª–µ—Ä—ã",
        "–≥–∏–∞–ª—É—Ä–æ–Ω–æ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞", "–±–∏–æ—Ä–µ–≤–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "–º–µ–∑–æ—Ç–µ—Ä–∞–ø–∏—è",
        "–ø–ª–∞–∑–º–æ–ª–∏—Ñ—Ç–∏–Ω–≥", "RF-–ª–∏—Ñ—Ç–∏–Ω–≥", "SMAS-–ª–∏—Ñ—Ç–∏–Ω–≥", "—É–ª—å—Ç—Ä–∞–∑–≤—É–∫–æ–≤–æ–π SMAS",
        "–ª–∞–∑–µ—Ä–Ω–∞—è —ç–ø–∏–ª—è—Ü–∏—è", "—Ñ–æ—Ç–æ—ç–ø–∏–ª—è—Ü–∏—è", "–ª–∞–∑–µ—Ä–Ω–æ–µ –æ–º–æ–ª–æ–∂–µ–Ω–∏–µ",
        "–ª–∞–∑–µ—Ä–Ω–∞—è —à–ª–∏—Ñ–æ–≤–∫–∞", "–Ω–∏—Ç–µ–≤–æ–π –ª–∏—Ñ—Ç–∏–Ω–≥", "–ª–∏–ø–æ–ª–∏—Ç–∏–∫–∏",
        "–º–∏–∫—Ä–æ—Ç–æ–∫–∏", "–∞–ø–ø–∞—Ä–∞—Ç–Ω–∞—è –∫–æ—Å–º–µ—Ç–æ–ª–æ–≥–∏—è", "–¥–µ—Ä–º–∞–ø–µ–Ω", "–º–∏–∫—Ä–æ–Ω–∏–¥–ª–∏–Ω–≥",
        "–∞–Ω—Ç–∏–≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã", "–ª–µ—á–µ–Ω–∏–µ –∞–∫–Ω–µ", "–ø–æ—Å—Ç–∞–∫–Ω–µ", "–∫—É–ø–∏—Ç—å –∫—É–ø–µ—Ä–æ–∑",
        "—É—Ö–æ–¥ –∑–∞ –∫–æ–∂–µ–π", "–æ–º–æ–ª–æ–∂–µ–Ω–∏–µ –ª–∏—Ü–∞", "–º–∞—Å–∫–∞ –¥–ª—è –ª–∏—Ü–∞"
    ]
    
    print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(beauty_keywords)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        print("üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")
        popular_data = client.get_popular_queries(beauty_keywords, config.default_region)
        
        if not popular_data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç API")
            return False
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
        print("üîó –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")
        similar_queries = []
        
        for keyword in beauty_keywords[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –∫–≤–æ—Ç—ã
            similar_data = client.get_similar_queries(keyword, config.default_region)
            if similar_data and 'data' in similar_data:
                similar_queries.extend(similar_data['data'])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        all_queries = []
        if popular_data and 'data' in popular_data:
            all_queries.extend(popular_data['data'])
        all_queries.extend(similar_queries)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        from database_manager import DatabaseManager
        from service_categorizer import categorizer
        import uuid
        
        db = DatabaseManager()
        cursor = db.conn.cursor()
        
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É WordstatKeywords...")
        
        saved_count = 0
        updated_count = 0
        
        try:
            for item in all_queries:
                keyword = item.get('key', '').strip()
                if not keyword:
                    continue
                    
                views = int(item.get('clicks', 0))
                
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º categorizer.categorize_service, —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                # –û–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (category_key, confidence, matched_keywords)
                category, confidence, _ = categorizer.categorize_service(keyword)
                
                if confidence < 0.3:
                    category = 'other'

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                cursor.execute("SELECT id FROM WordstatKeywords WHERE keyword = ?", (keyword,))
                existing = cursor.fetchone()
                
                if existing:
                    cursor.execute("""
                        UPDATE WordstatKeywords 
                        SET views = ?, category = ?, updated_at = CURRENT_TIMESTAMP 
                        WHERE id = ?
                    """, (views, category, existing[0]))
                    updated_count += 1
                else:
                    new_id = str(uuid.uuid4())
                    cursor.execute("""
                        INSERT INTO WordstatKeywords (id, keyword, views, category, updated_at) 
                        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)
                    """, (new_id, keyword, views, category))
                    saved_count += 1
            
            db.conn.commit()
            print("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
            print(f"   ‚ûï –ù–æ–≤—ã—Ö: {saved_count}")
            print(f"   üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_count}")
            
        except Exception as db_err:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –ë–î: {db_err}")
            db.conn.rollback()
            return False
            
        finally:
            db.close()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–≤—Å–µ –µ—â–µ –ø–æ–ª–µ–∑–Ω–æ)
        metadata = {
            'last_update': datetime.now().isoformat(),
            'queries_count': saved_count + updated_count,
            'region': config.default_region,
            'region_name': config.get_region_name(config.default_region)
        }
        
        prompts_dir = Path(__file__).parent.parent / "prompts"
        if not prompts_dir.exists():
            prompts_dir.mkdir(parents=True, exist_ok=True)
            
        metadata_path = prompts_dir / "wordstat_metadata.json"
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {metadata_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_update_needed() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
    metadata_path = Path(__file__).parent.parent / "prompts" / "wordstat_metadata.json"
    
    if not metadata_path.exists():
        return True
    
    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        last_update = datetime.fromisoformat(metadata['last_update'])
        update_interval = timedelta(seconds=config.update_interval)
        
        return datetime.now() - last_update > update_interval
        
    except Exception:
        return True

if __name__ == "__main__":
    if check_update_needed():
        success = main()
        if success:
            print("üéâ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        else:
            print("üí• –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏")
            sys.exit(1)
    else:
        print("‚è∞ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è (–¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã)")
