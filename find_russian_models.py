#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ Hugging Face
"""

import os
import requests
from dotenv import load_dotenv

load_dotenv()

def search_models(query, limit=20):
    """–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Hugging Face API"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return []
    
    headers = {
        "Authorization": f"Bearer {hf_token}"
    }
    
    try:
        # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π
        response = requests.get(
            "https://huggingface.co/api/models",
            headers=headers,
            params={
                "search": query,
                "limit": limit,
                "sort": "downloads",
                "direction": "-1"
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
            return []
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        return []

def test_model_generation(model_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        return False
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    payload = {
        "inputs": "–ê–Ω–∞–ª–∏–∑ SEO –¥–ª—è –±–∏–∑–Ω–µ—Å–∞:",
        "parameters": {
            "max_length": 100,
            "temperature": 0.7,
            "do_sample": True
        }
    }
    
    try:
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{model_name}",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç
            if isinstance(result, list) and len(result) > 0:
                if 'generated_text' in result[0]:
                    return True
        return False
        
    except Exception as e:
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞"""
    print("üîç –ü–æ–∏—Å–∫ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞")
    print("=" * 60)
    
    # –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    search_queries = [
        "russian text generation",
        "russian gpt",
        "russian language model",
        "text2text-generation russian",
        "sberbank-ai russian",
        "ai-forever russian"
    ]
    
    found_models = []
    
    for query in search_queries:
        print(f"\nüîé –ü–æ–∏—Å–∫: {query}")
        models = search_models(query, limit=10)
        
        for model in models:
            model_id = model.get('id', '')
            downloads = model.get('downloads', 0)
            likes = model.get('likes', 0)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
            if downloads > 1000:
                print(f"  üìä {model_id} (–∑–∞–≥—Ä—É–∑–æ–∫: {downloads}, –ª–∞–π–∫–æ–≤: {likes})")
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                if test_model_generation(model_id):
                    print(f"    ‚úÖ –ì–ï–ù–ï–†–ê–¶–ò–Ø –†–ê–ë–û–¢–ê–ï–¢!")
                    found_models.append({
                        'id': model_id,
                        'downloads': downloads,
                        'likes': likes,
                        'query': query
                    })
                else:
                    print(f"    ‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:")
    print("=" * 40)
    
    if found_models:
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        found_models.sort(key=lambda x: x['downloads'], reverse=True)
        
        print("‚úÖ –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏:")
        for i, model in enumerate(found_models[:10], 1):
            print(f"{i}. {model['id']}")
            print(f"   –ó–∞–≥—Ä—É–∑–æ–∫: {model['downloads']}, –õ–∞–π–∫–æ–≤: {model['likes']}")
            print(f"   –ù–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑: {model['query']}")
            print()
    else:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    
    return found_models

if __name__ == "__main__":
    models = main() 