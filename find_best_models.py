#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π Hugging Face –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞
"""
import requests
import os
from dotenv import load_dotenv

load_dotenv()

def search_huggingface_models():
    """–ò—â–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞"""
    
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
        return
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞
    search_queries = [
        "text-generation",
        "text2text-generation", 
        "text-analysis",
        "business analysis",
        "SEO optimization",
        "recommendation system",
        "russian language",
        "multilingual"
    ]
    
    print("üîç –ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞...")
    print("=" * 60)
    
    found_models = []
    
    for query in search_queries:
        print(f"\nüìù –ü–æ–∏—Å–∫: {query}")
        
        try:
            # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Hugging Face API
            response = requests.get(
                f"https://huggingface.co/api/models",
                headers=headers,
                params={
                    "search": query,
                    "sort": "downloads",
                    "direction": "-1",
                    "limit": 10
                }
            )
            
            if response.status_code == 200:
                models = response.json()
                
                for model in models:
                    model_id = model.get('id', '')
                    downloads = model.get('downloads', 0)
                    likes = model.get('likes', 0)
                    tags = model.get('tags', [])
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–æ–¥–µ–ª–∏
                    if downloads > 1000 and any(tag in ['text-generation', 'text2text-generation', 'russian', 'multilingual'] for tag in tags):
                        found_models.append({
                            'id': model_id,
                            'downloads': downloads,
                            'likes': likes,
                            'tags': tags,
                            'query': query
                        })
                        
                        print(f"  ‚úÖ {model_id}")
                        print(f"     üì• Downloads: {downloads:,}")
                        print(f"     ‚ù§Ô∏è  Likes: {likes}")
                        print(f"     üè∑Ô∏è  Tags: {', '.join(tags[:5])}")
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    found_models.sort(key=lambda x: x['downloads'], reverse=True)
    
    print("\n" + "=" * 60)
    print("üèÜ –¢–û–ü-10 –õ–£–ß–®–ò–• –ú–û–î–ï–õ–ï–ô –î–õ–Ø SEO –ê–ù–ê–õ–ò–ó–ê:")
    print("=" * 60)
    
    for i, model in enumerate(found_models[:10], 1):
        print(f"\n{i}. {model['id']}")
        print(f"   üì• Downloads: {model['downloads']:,}")
        print(f"   ‚ù§Ô∏è  Likes: {model['likes']}")
        print(f"   üè∑Ô∏è  Tags: {', '.join(model['tags'][:5])}")
        print(f"   üîç Found by: {model['query']}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + "=" * 60)
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("=" * 60)
    
    if found_models:
        best_model = found_models[0]
        print(f"\nüéØ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model['id']}")
        print(f"   - –°–∞–º–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–∞—è ({best_model['downloads']:,} –∑–∞–≥—Ä—É–∑–æ–∫)")
        print(f"   - –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        print(f"   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
        
        print(f"\nüìã –î–õ–Ø –í–ê–®–ï–ì–û –ü–†–û–ú–ü–¢–ê –†–ï–ö–û–ú–ï–ù–î–£–Æ:")
        print(f"   1. {best_model['id']} - –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        print(f"   2. facebook/bart-large-cnn - –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤")
        print(f"   3. t5-large - –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        
        print(f"\n‚öôÔ∏è  –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø {best_model['id']}:")
        print(f"   - max_length: 2048 (–¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤)")
        print(f"   - temperature: 0.3 (–¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)")
        print(f"   - do_sample: True")
        print(f"   - top_p: 0.9")
    else:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–æ–¥–µ–ª–µ–π")

def test_current_model():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å"""
    print("\n" + "=" * 60)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –¢–ï–ö–£–©–ï–ô –ú–û–î–ï–õ–ò:")
    print("=" * 60)
    
    from src.model_config import get_model_config, get_prompt
    
    model_config = get_model_config()
    print(f"ü§ñ –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {model_config['name']}")
    print(f"üìè Max length: {model_config['max_length']}")
    print(f"üå°Ô∏è  Temperature: {model_config['temperature']}")
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
    test_text = "–ö–∞—Ñ–µ '–£—é—Ç–Ω–æ–µ –º–µ—Å—Ç–æ', –∞–¥—Ä–µ—Å: —É–ª. –õ–µ–Ω–∏–Ω–∞ 123, —Ä–µ–π—Ç–∏–Ω–≥ 4.2"
    prompt = get_prompt("seo_analysis", test_text)
    
    print(f"\nüìù –¢–µ–∫—É—â–∏–π –ø—Ä–æ–º–ø—Ç:")
    print(f"   {prompt[:100]}...")
    
    print(f"\n‚ö†Ô∏è  –ü–†–û–ë–õ–ï–ú–´ –¢–ï–ö–£–©–ï–ì–û –ü–†–û–ú–ü–¢–ê:")
    print(f"   - –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∏ –æ–±—â–∏–π")
    print(f"   - –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç 2025")
    print(f"   - –ù–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    print(f"   - –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

if __name__ == "__main__":
    search_huggingface_models()
    test_current_model() 