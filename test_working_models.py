#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Ä–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —á–µ—Ä–µ–∑ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π Hugging Face API
"""

import os
import requests
from dotenv import load_dotenv

load_dotenv()

def test_model(model_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    payload = {
        "inputs": "–ê–Ω–∞–ª–∏–∑ SEO –¥–ª—è –±–∏–∑–Ω–µ—Å–∞. –î–∞–π 2 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:",
        "parameters": {
            "max_length": 150,
            "temperature": 0.7,
            "do_sample": True,
            "top_p": 0.9
        }
    }
    
    try:
        print(f"ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º: {model_name}")
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{model_name}",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ {model_name} - –†–ê–ë–û–¢–ê–ï–¢!")
            if isinstance(result, list) and len(result) > 0:
                generated = result[0].get('generated_text', '')
                print(f"   –ü—Ä–∏–º–µ—Ä: {generated[:100]}...")
            return True
        elif response.status_code == 503:
            print(f"‚è≥ {model_name} - –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
            return False
        else:
            print(f"‚ùå {model_name} - –û—à–∏–±–∫–∞ {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå {model_name} - –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
        return False

def main():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã —Ä–∞–±–æ—Ç–∞—Ç—å"""
    print("üîç –¢–µ—Å—Ç —Ä–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π")
    print("=" * 40)
    
    # –ú–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –¥–æ–ª–∂–Ω—ã —Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π API
    test_models = [
        # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ GPT
        "gpt2",
        "gpt2-medium",
        "distilgpt2",
        
        # –ú–æ–¥–µ–ª–∏ BART
        "facebook/bart-base",
        "facebook/bart-large",
        
        # –ú–æ–¥–µ–ª–∏ T5
        "t5-small",
        "t5-base",
        
        # –ú–æ–¥–µ–ª–∏ DialoGPT
        "microsoft/DialoGPT-small",
        "microsoft/DialoGPT-medium",
        
        # –ú–æ–¥–µ–ª–∏ BLOOM
        "bigscience/bloom-560m",
        "bigscience/bloom-1b1",
        
        # –ú–æ–¥–µ–ª–∏ EleutherAI
        "EleutherAI/gpt-neo-125M",
        "EleutherAI/gpt-neo-1.3B",
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        "DeepPavlov/rubert-base-cased",
        "DeepPavlov/rubert-large-cased",
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        "cardiffnlp/twitter-roberta-base-sentiment",
        "nlptown/bert-base-multilingual-uncased-sentiment",
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        "microsoft/DialoGPT-medium",
        "microsoft/DialoGPT-large",
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
        "sshleifer/tiny-gpt2",
        "sshleifer/distilgpt2",
        "microsoft/DialoGPT-small"
    ]
    
    print(f"üìã –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(test_models)} –º–æ–¥–µ–ª–µ–π...")
    print()
    
    working_models = []
    
    for model in test_models:
        if test_model(model):
            working_models.append(model)
        print()
    
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print("=" * 30)
    if working_models:
        print("‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏:")
        for i, model in enumerate(working_models, 1):
            print(f"{i}. {model}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        best_model = working_models[0]
        print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {best_model}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        update_model_config(best_model)
        
    else:
        print("‚ùå –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("\nüí° –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ API...")
        search_working_models()

def search_working_models():
    """–ü–æ–∏—Å–∫ —Ä–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ API"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    headers = {
        "Authorization": f"Bearer {hf_token}"
    }
    
    search_queries = [
        "text-generation",
        "gpt2",
        "bart-base",
        "t5-small",
        "dialoGPT"
    ]
    
    print("üîç –ü–æ–∏—Å–∫ —Ä–∞–±–æ—á–∏—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ API...")
    
    for query in search_queries:
        try:
            print(f"\nüìù –ü–æ–∏—Å–∫: {query}")
            response = requests.get(
                "https://huggingface.co/api/models",
                headers=headers,
                params={
                    "search": query,
                    "limit": 5,
                    "sort": "downloads",
                    "direction": "-1"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                models = response.json()
                for model in models:
                    model_id = model.get('id', '')
                    downloads = model.get('downloads', 0)
                    print(f"  üìä {model_id} (–∑–∞–≥—Ä—É–∑–æ–∫: {downloads})")
                    
                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                    if test_model(model_id):
                        print(f"üéØ –ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—Ç–∞—é—â–∞—è –º–æ–¥–µ–ª—å: {model_id}")
                        update_model_config(model_id)
                        return
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")

def update_model_config(model_name):
    """–û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    print(f"\n‚öôÔ∏è –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è {model_name}...")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º model_config.py
    config_content = f'''# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π Hugging Face –¥–ª—è –ò–ò-–∞–Ω–∞–ª–∏–∑–∞

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
AVAILABLE_MODELS = {{
    "{model_name}": {{
        "name": "{model_name}",
        "description": "–†–∞–±–æ—á–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞",
        "max_length": 1024,
        "temperature": 0.7,
        "do_sample": True,
        "top_p": 0.9,
        "repetition_penalty": 1.1
    }},
    "gpt2": {{
        "name": "gpt2",
        "description": "–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞",
        "max_length": 200,
        "temperature": 0.8,
        "do_sample": True,
        "top_p": 0.9,
        "repetition_penalty": 1.1
    }},
    "facebook/bart-base": {{
        "name": "facebook/bart-base",
        "description": "–ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞",
        "max_length": 1024,
        "temperature": 0.7,
        "do_sample": True,
        "top_p": 0.9
    }}
}}

# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
PROMPTS = {{
    "seo_analysis": """–ê–Ω–∞–ª–∏–∑ SEO –¥–ª—è –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç. –î–∞–Ω–Ω—ã–µ: {{text}}

–î–∞–π 5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:
1) –ù–∞–∑–≤–∞–Ω–∏–µ: —É–±—Ä–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
2) –£—Å–ª—É–≥–∏: –¥–æ–±–∞–≤–∏—Ç—å –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é  
3) –ö–æ–Ω—Ç–∞–∫—Ç—ã: –ø–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å
4) –ö–æ–Ω—Ç–µ–Ω—Ç: –±–æ–ª—å—à–µ —Ñ–æ—Ç–æ
5) –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–æ—Å—Ç—ã

–ù–µ —Å–æ–≤–µ—Ç—É–π Google Pay/Apple Pay - –æ–Ω–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –†–æ—Å—Å–∏–∏.""",
    "rating_analysis": "–ê–Ω–∞–ª–∏–∑ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏ –æ—Ç–∑—ã–≤–æ–≤. –î–∞–Ω–Ω—ã–µ: {{text}}. –û—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –¥–∞–π 2-3 —Å–æ–≤–µ—Ç–∞ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é.",
    "general_analysis": "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å–∞. –î–∞–Ω–Ω—ã–µ: {{text}}. –î–∞–π 3-4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é."
}}

# –¢–µ–∫—É—â–∞—è –∞–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
CURRENT_MODEL = "{model_name}"

def get_model_config(model_name=None):
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    if model_name is None:
        model_name = CURRENT_MODEL
    
    return AVAILABLE_MODELS.get(model_name, AVAILABLE_MODELS["{model_name}"])

def get_prompt(prompt_type="seo_analysis", text=""):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    return PROMPTS.get(prompt_type, PROMPTS["seo_analysis"]).format(text=text)
'''
    
    try:
        with open('src/model_config.py', 'w', encoding='utf-8') as f:
            f.write(config_content)
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è {model_name}")
        
        # –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º ai_analyzer.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        update_ai_analyzer(model_name)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

def update_ai_analyzer(model_name):
    """–û–±–Ω–æ–≤–ª—è–µ–º ai_analyzer.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º ai_analyzer.py –¥–ª—è {model_name}...")
    
    try:
        with open('src/ai_analyzer.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ó–∞–º–µ–Ω—è–µ–º rule-based –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏
        new_call_function = f'''def call_huggingface_analysis(text: str) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ {model_name}
    """
    try:
        from model_config import get_model_config, get_prompt
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
        model_config = get_model_config("{model_name}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = get_prompt("seo_analysis", text)
        
        # –í—ã–∑—ã–≤–∞–µ–º Hugging Face API
        import requests
        import os
        
        hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
        if not hf_token:
            return {{"error": "HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω"}}
        
        headers = {{
            "Authorization": f"Bearer {{hf_token}}",
            "Content-Type": "application/json"
        }}
        
        payload = {{
            "inputs": prompt,
            "parameters": {{
                "max_length": model_config.get("max_length", 1024),
                "temperature": model_config.get("temperature", 0.7),
                "do_sample": model_config.get("do_sample", True),
                "top_p": model_config.get("top_p", 0.9),
                "repetition_penalty": model_config.get("repetition_penalty", 1.1)
            }}
        }}
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{model_name}",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                generated_text = result[0].get('generated_text', '')
                return {{
                    "generated_text": generated_text,
                    "analysis_type": "ai_model",
                    "model_used": "{model_name}"
                }}
            else:
                return {{"error": "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏"}}
        else:
            return {{"error": f"–û—à–∏–±–∫–∞ API {{response.status_code}}: {{response.text}}"}}
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {{e}}")
        return {{"error": str(e)}}'''
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≤ —Ñ–∞–π–ª–µ
        import re
        pattern = r'def call_huggingface_analysis\(text: str\) -> Dict\[str, Any\]:.*?return \{"error": str\(e\)\}'
        new_content = re.sub(pattern, new_call_function, content, flags=re.DOTALL)
        
        with open('src/ai_analyzer.py', 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("‚úÖ ai_analyzer.py –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ai_analyzer.py: {e}")

if __name__ == "__main__":
    main() 