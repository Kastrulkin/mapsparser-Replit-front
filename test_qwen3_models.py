#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π Qwen 3 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
"""

import os
import requests
from dotenv import load_dotenv

load_dotenv()

def search_qwen_models():
    """–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π Qwen 3 –Ω–∞ Hugging Face"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return []
    
    headers = {
        "Authorization": f"Bearer {hf_token}"
    }
    
    # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π Qwen 3
    search_queries = [
        "Qwen2.5",
        "Qwen2.5-7B",
        "Qwen2.5-14B", 
        "Qwen2.5-32B",
        "Qwen2.5-72B",
        "Qwen2.5-Instruct",
        "Qwen2.5-Chat"
    ]
    
    found_models = []
    
    for query in search_queries:
        try:
            print(f"üîç –ü–æ–∏—Å–∫: {query}")
            response = requests.get(
                "https://huggingface.co/api/models",
                headers=headers,
                params={
                    "search": query,
                    "limit": 10,
                    "sort": "downloads",
                    "direction": "-1"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                models = response.json()
                for model in models:
                    model_id = model.get('id', '')
                    downloads = model.get('downloads', 0)
                    likes = model.get('likes', 0)
                    
                    if downloads > 1000:
                        print(f"  üìä {model_id} (–∑–∞–≥—Ä—É–∑–æ–∫: {downloads}, –ª–∞–π–∫–æ–≤: {likes})")
                        found_models.append({
                            'id': model_id,
                            'downloads': downloads,
                            'likes': likes,
                            'query': query
                        })
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
    
    return found_models

def test_qwen_model(model_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å Qwen"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        return False
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å Qwen
    payload = {
        "inputs": "–ê–Ω–∞–ª–∏–∑ SEO –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö. –î–∞–π 3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:",
        "parameters": {
            "max_length": 200,
            "temperature": 0.7,
            "do_sample": True,
            "top_p": 0.9
        }
    }
    
    try:
        print(f"ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º: {model_name}")
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{model_name}",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ {model_name} - –†–ê–ë–û–¢–ê–ï–¢!")
            if isinstance(result, list) and len(result) > 0:
                generated = result[0].get('generated_text', '')
                print(f"   –ü—Ä–∏–º–µ—Ä: {generated[:150]}...")
            return True
        else:
            print(f"‚ùå {model_name} - –û—à–∏–±–∫–∞ {response.status_code}")
            if response.status_code == 503:
                print("   ‚è≥ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
            return False
            
    except Exception as e:
        print(f"‚ùå {model_name} - –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ü–æ–∏—Å–∫ –∏ —Ç–µ—Å—Ç –º–æ–¥–µ–ª–µ–π Qwen 3")
    print("=" * 50)
    
    # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π
    print("üìã –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π Qwen 3...")
    models = search_qwen_models()
    
    if not models:
        print("‚ùå –ú–æ–¥–µ–ª–∏ Qwen 3 –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    models.sort(key=lambda x: x['downloads'], reverse=True)
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π Qwen 3:")
    for i, model in enumerate(models[:5], 1):
        print(f"{i}. {model['id']} (–∑–∞–≥—Ä—É–∑–æ–∫: {model['downloads']})")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ø –º–æ–¥–µ–ª–∏
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ø –º–æ–¥–µ–ª–∏...")
    working_models = []
    
    for model in models[:3]:
        if test_qwen_model(model['id']):
            working_models.append(model)
        print()
    
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print("=" * 30)
    if working_models:
        print("‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏ Qwen 3:")
        for model in working_models:
            print(f"  - {model['id']}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        best_model = working_models[0]
        print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {best_model['id']}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        update_model_config(best_model['id'])
        
    else:
        print("‚ùå –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å Qwen 3 –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")

def update_model_config(model_name):
    """–û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    print(f"\n‚öôÔ∏è –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è {model_name}...")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º model_config.py
    config_content = f'''# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π Hugging Face –¥–ª—è –ò–ò-–∞–Ω–∞–ª–∏–∑–∞

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
AVAILABLE_MODELS = {{
    "{model_name}": {{
        "name": "{model_name}",
        "description": "–ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å Qwen 3 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞",
        "max_length": 2048,
        "temperature": 0.6,
        "do_sample": True,
        "top_p": 0.9,
        "repetition_penalty": 1.1
    }},
    "gpt2": {{
        "name": "gpt2",
        "description": "–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞",
        "max_length": 200,
        "temperature": 0.8,
        "do_sample": True,
        "top_p": 0.9,
        "repetition_penalty": 1.1
    }},
    "facebook/bart-base": {{
        "name": "facebook/bart-base",
        "description": "–ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞",
        "max_length": 1024,
        "temperature": 0.7,
        "do_sample": True,
        "top_p": 0.9
    }}
}}

# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
PROMPTS = {{
    "seo_analysis": """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞—Ä—Ç–æ—á–∫—É –±–∏–∑–Ω–µ—Å–∞ –¥–ª—è SEO –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö. –î–∞–Ω–Ω—ã–µ: {{text}}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –î–∞–π 5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–∑–∏—Ü–∏–π –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö. –£—á–∏—Ç—ã–≤–∞–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è 2025 –≥–æ–¥–∞:

1. –ù–ê–ó–í–ê–ù–ò–ï –ö–û–ú–ü–ê–ù–ò–ò: –¢–æ–ª—å–∫–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–µ–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
2. –£–°–õ–£–ì–ò: –î–æ–±–∞–≤–ª—è–π –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é (–º–µ—Ç—Ä–æ, —Ä–∞–π–æ–Ω)
3. –ê–î–†–ï–°: –ü–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å —Å –º–µ—Ç—Ä–æ/–æ—Å—Ç–∞–Ω–æ–≤–∫–∞–º–∏
4. –ö–û–ù–¢–ï–ù–¢: –ú–∏–Ω–∏–º—É–º 10 —Ñ–æ—Ç–æ, –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
5. –ê–ö–¢–ò–í–ù–û–°–¢–¨: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–æ—Å—Ç—ã, –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Ç–∑—ã–≤—ã

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
1) –ù–∞–∑–≤–∞–Ω–∏–µ: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]
2) –£—Å–ª—É–≥–∏: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è] 
3) –ö–æ–Ω—Ç–∞–∫—Ç—ã: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]
4) –ö–æ–Ω—Ç–µ–Ω—Ç: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]
5) –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]

–ù–µ —Å–æ–≤–µ—Ç—É–π Google Pay/Apple Pay - –æ–Ω–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –†–æ—Å—Å–∏–∏.""",
    "rating_analysis": "–ê–Ω–∞–ª–∏–∑ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏ –æ—Ç–∑—ã–≤–æ–≤. –î–∞–Ω–Ω—ã–µ: {text}. –û—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –¥–∞–π 2-3 —Å–æ–≤–µ—Ç–∞ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é.",
    "general_analysis": "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å–∞. –î–∞–Ω–Ω—ã–µ: {text}. –î–∞–π 3-4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é."
}}

# –¢–µ–∫—É—â–∞—è –∞–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
CURRENT_MODEL = "{model_name}"

def get_model_config(model_name=None):
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    if model_name is None:
        model_name = CURRENT_MODEL
    
    return AVAILABLE_MODELS.get(model_name, AVAILABLE_MODELS["{model_name}"])

def get_prompt(prompt_type="seo_analysis", text=""):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    return PROMPTS.get(prompt_type, PROMPTS["seo_analysis"]).format(text=text)
'''
    
    try:
        with open('src/model_config.py', 'w', encoding='utf-8') as f:
            f.write(config_content)
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è {model_name}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

if __name__ == "__main__":
    main() 