#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–∞ sidebar –∏ –ø–æ–∏—Å–∫–∞ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π/–ø—É–±–ª–∏–∫–∞—Ü–∏–π.
"""

import json
import re
import sys
from pathlib import Path

def read_file_content(file_path: str) -> str:
    """–ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç .txt, .docx –∏ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã."""
    path = Path(file_path)
    
    # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    if path.suffix.lower() == '.docx':
        try:
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å python-docx
            from docx import Document
            doc = Document(file_path)
            content = '\n'.join([para.text for para in doc.paragraphs])
            print(f"‚úÖ –§–∞–π–ª .docx –ø—Ä–æ—á–∏—Ç–∞–Ω —á–µ—Ä–µ–∑ python-docx")
            return content
        except ImportError:
            print("‚ö†Ô∏è python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ zip...")
            # .docx —ç—Ç–æ zip –∞—Ä—Ö–∏–≤, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å text
            try:
                import zipfile
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    # –ò—â–µ–º document.xml –≤ –∞—Ä—Ö–∏–≤–µ
                    if 'word/document.xml' in zip_ref.namelist():
                        xml_content = zip_ref.read('word/document.xml').decode('utf-8')
                        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ XML (—É–¥–∞–ª—è–µ–º —Ç–µ–≥–∏)
                        content = re.sub(r'<[^>]+>', '', xml_content)
                        print(f"‚úÖ –§–∞–π–ª .docx –ø—Ä–æ—á–∏—Ç–∞–Ω –∫–∞–∫ zip –∞—Ä—Ö–∏–≤")
                        return content
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å .docx: {e}")
                print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ python-docx: pip install python-docx")
                return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ .docx: {e}")
            return None
    else:
        # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    return f.read()
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
                return None

def analyze_sidebar_response(file_path: str):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å –æ—Ç–≤–µ—Ç–æ–º sidebar –∏ –∏—â–µ—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö."""
    
    print(f"üìñ –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {file_path}")
    
    content = read_file_content(file_path)
    if content is None:
        return
    
    if not content:
        print(f"‚ö†Ô∏è –§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ")
        return
    
    print(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω, —Ä–∞–∑–º–µ—Ä: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤\n")
    
    # 1. –ò—â–µ–º API endpoints –¥–ª—è –ø–æ—Å—Ç–æ–≤/–Ω–æ–≤–æ—Å—Ç–µ–π
    print("=" * 80)
    print("1Ô∏è‚É£ –ü–û–ò–°–ö API ENDPOINTS –î–õ–Ø –ü–û–°–¢–û–í/–ù–û–í–û–°–¢–ï–ô")
    print("=" * 80)
    
    endpoint_patterns = [
        (r'["\']https?://[^"\']*/(?:api|sprav|business)[^"\']*/(?:posts|news|publications|–ø—É–±–ª–∏–∫–∞—Ü|–Ω–æ–≤–æ—Å—Ç)[^"\']*["\']', "–ü–æ–ª–Ω—ã–µ URL —Å posts/news/publications"),
        (r'["\']/api/[^"\']*/(?:posts|news|publications)[^"\']*["\']', "–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ /api/..."),
        (r'["\']/sprav/[^"\']*/(?:posts|news|publications)[^"\']*["\']', "–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ /sprav/..."),
        (r'["\']/business/[^"\']*/(?:posts|news|publications)[^"\']*["\']', "–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ /business/..."),
        (r'url["\']?\s*[:=]\s*["\']([^"\']*/(?:posts|news|publications)[^"\']*)["\']', "–ö–ª—é—á url —Å posts/news"),
        (r'endpoint["\']?\s*[:=]\s*["\']([^"\']*/(?:posts|news|publications)[^"\']*)["\']', "–ö–ª—é—á endpoint"),
        (r'apiUrl["\']?\s*[:=]\s*["\']([^"\']*/(?:posts|news|publications)[^"\']*)["\']', "–ö–ª—é—á apiUrl"),
        (r'fetch\(["\']([^"\']*/(?:posts|news|publications)[^"\']*)["\']', "fetch() –≤—ã–∑–æ–≤—ã"),
        (r'axios\.(?:get|post)\(["\']([^"\']*/(?:posts|news|publications)[^"\']*)["\']', "axios –≤—ã–∑–æ–≤—ã"),
    ]
    
    all_endpoints = []
    for pattern, description in endpoint_patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            print(f"\n‚úÖ {description}:")
            for match in matches[:10]:  # –ü–µ—Ä–≤—ã–µ 10
                endpoint = match if isinstance(match, str) else match[0] if match else ""
                if endpoint:
                    print(f"   - {endpoint}")
                    all_endpoints.append(endpoint)
    
    if not all_endpoints:
        print("\n‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —è–≤–Ω—ã—Ö endpoints –¥–ª—è posts/news/publications")
    
    # 2. –ò—â–µ–º –≤—Å–µ URL, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å API
    print("\n" + "=" * 80)
    print("2Ô∏è‚É£ –ü–û–ò–°–ö –í–°–ï–• URL, –°–í–Ø–ó–ê–ù–ù–´–• –° API/SPRAV/BUSINESS")
    print("=" * 80)
    
    all_urls = re.findall(r'https?://[^\s"\'<>)]+', content[:50000])  # –ü–µ—Ä–≤—ã–µ 50k —Å–∏–º–≤–æ–ª–æ–≤
    api_related_urls = [url for url in all_urls if any(word in url.lower() for word in ['api', 'sprav', 'business', 'yandex.ru'])]
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–æ—Å—Ç–∞–º–∏
    unique_api_urls = []
    seen = set()
    for url in api_related_urls:
        if url not in seen and len(url) < 500:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ
            seen.add(url)
            unique_api_urls.append(url)
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(unique_api_urls)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å API")
    print("–ü–µ—Ä–≤—ã–µ 20:")
    for url in unique_api_urls[:20]:
        print(f"   - {url[:150]}")
    
    # 3. –ò—â–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ—Å—Ç–∞–º–∏
    print("\n" + "=" * 80)
    print("3Ô∏è‚É£ –ü–û–ò–°–ö –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–• –° –ü–û–°–¢–ê–ú–ò")
    print("=" * 80)
    
    # –ò—â–µ–º JSON –æ–±—ä–µ–∫—Ç—ã —Å –∫–ª—é—á–∞–º–∏ posts/publications/news
    json_patterns = [
        (r'["\']posts["\']\s*:\s*\[', "–ö–ª—é—á 'posts' —Å –º–∞—Å—Å–∏–≤–æ–º"),
        (r'["\']publications["\']\s*:\s*\[', "–ö–ª—é—á 'publications' —Å –º–∞—Å—Å–∏–≤–æ–º"),
        (r'["\']news["\']\s*:\s*\[', "–ö–ª—é—á 'news' —Å –º–∞—Å—Å–∏–≤–æ–º"),
        (r'["\']–ø—É–±–ª–∏–∫–∞—Ü–∏–∏["\']\s*:\s*\[', "–ö–ª—é—á '–ø—É–±–ª–∏–∫–∞—Ü–∏–∏' —Å –º–∞—Å—Å–∏–≤–æ–º"),
        (r'["\']–Ω–æ–≤–æ—Å—Ç–∏["\']\s*:\s*\[', "–ö–ª—é—á '–Ω–æ–≤–æ—Å—Ç–∏' —Å –º–∞—Å—Å–∏–≤–æ–º"),
    ]
    
    for pattern, description in json_patterns:
        matches = list(re.finditer(pattern, content, re.IGNORECASE))
        if matches:
            print(f"\n‚úÖ {description}: –Ω–∞–π–¥–µ–Ω–æ {len(matches)} –≤—Ö–æ–∂–¥–µ–Ω–∏–π")
            for i, match in enumerate(matches[:3]):  # –ü–µ—Ä–≤—ã–µ 3
                start = max(0, match.start() - 100)
                end = min(len(content), match.end() + 500)
                context = content[start:end]
                print(f"\n   –í—Ö–æ–∂–¥–µ–Ω–∏–µ #{i+1} (–ø–æ–∑–∏—Ü–∏—è {match.start()}):")
                print(f"   {context[:400]}...")
    
    # 4. –ò—â–µ–º window.__INITIAL__ –∏ –ø–æ–¥–æ–±–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    print("\n" + "=" * 80)
    print("4Ô∏è‚É£ –ü–û–ò–°–ö WINDOW.__INITIAL__ –ò –ü–û–î–û–ë–ù–´–• –°–¢–†–£–ö–¢–£–†")
    print("=" * 80)
    
    initial_patterns = [
        r'window\.__INITIAL__',
        r'window\.__INITIAL_STATE__',
        r'window\.__DATA__',
        r'__INITIAL__',
        r'const\s+STATE\s*=',
    ]
    
    for pattern in initial_patterns:
        matches = list(re.finditer(pattern, content, re.IGNORECASE))
        if matches:
            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ '{pattern}': {len(matches)} –≤—Ö–æ–∂–¥–µ–Ω–∏–π")
            for i, match in enumerate(matches[:2]):  # –ü–µ—Ä–≤—ã–µ 2
                start = max(0, match.start() - 50)
                end = min(len(content), match.end() + 200)
                context = content[start:end]
                print(f"   –í—Ö–æ–∂–¥–µ–Ω–∏–µ #{i+1}: {context[:300]}...")
    
    # 5. –ò—â–µ–º –∫–ª—é—á–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–æ—Å—Ç–∞–º–∏ –≤ JSON
    print("\n" + "=" * 80)
    print("5Ô∏è‚É£ –ü–û–ò–°–ö –ö–õ–Æ–ß–ï–ô, –°–í–Ø–ó–ê–ù–ù–´–• –° –ü–û–°–¢–ê–ú–ò –í JSON")
    print("=" * 80)
    
    post_key_patterns = [
        r'["\'](?:posts|publications|news|–ø—É–±–ª–∏–∫–∞—Ü–∏–∏|–Ω–æ–≤–æ—Å—Ç–∏)["\']',
        r'["\'][^"\']*(?:post|publication|news|–ø—É–±–ª–∏–∫–∞—Ü|–Ω–æ–≤–æ—Å—Ç)[^"\']*["\']',
    ]
    
    found_keys = set()
    for pattern in post_key_patterns:
        matches = re.findall(pattern, content[:100000], re.IGNORECASE)  # –ü–µ—Ä–≤—ã–µ 100k
        found_keys.update(matches)
    
    if found_keys:
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(found_keys)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø–æ—Å—Ç–∞–º–∏:")
        for key in sorted(found_keys)[:20]:
            print(f"   - {key}")
    else:
        print("\n‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–π, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø–æ—Å—Ç–∞–º–∏")
    
    # 6. –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON (–µ—Å–ª–∏ —ç—Ç–æ JSON)
    print("\n" + "=" * 80)
    print("6Ô∏è‚É£ –ü–û–ü–´–¢–ö–ê –ü–ê–†–°–ò–ù–ì–ê –ö–ê–ö JSON")
    print("=" * 80)
    
    try:
        data = json.loads(content)
        print("‚úÖ –§–∞–π–ª —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON!")
        print(f"   –¢–∏–ø –∫–æ—Ä–Ω–µ–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞: {type(data).__name__}")
        
        if isinstance(data, dict):
            print(f"   –ö–ª—é—á–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è: {list(data.keys())[:20]}")
            
            # –ò—â–µ–º –ø–æ—Å—Ç—ã —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
            def find_posts_keys(obj, path="", depth=0, max_depth=5):
                if depth > max_depth:
                    return []
                keys = []
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        if any(word in key.lower() for word in ['post', 'publication', 'news', '–ø—É–±–ª–∏–∫–∞—Ü', '–Ω–æ–≤–æ—Å—Ç']):
                            keys.append(f"{path}.{key}" if path else key)
                        if isinstance(value, (dict, list)):
                            keys.extend(find_posts_keys(value, f"{path}.{key}" if path else key, depth + 1, max_depth))
                elif isinstance(obj, list) and obj:
                    if isinstance(obj[0], (dict, list)):
                        keys.extend(find_posts_keys(obj[0], f"{path}[0]", depth + 1, max_depth))
                return keys
            
            post_keys = find_posts_keys(data)
            if post_keys:
                print(f"\n   ‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫–ª—é—á–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø–æ—Å—Ç–∞–º–∏:")
                for key in post_keys[:15]:
                    print(f"      - {key}")
        
    except json.JSONDecodeError:
        print("‚ö†Ô∏è –§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON (–≤–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ HTML/JavaScript)")
    
    # 7. –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö endpoints –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    print("\n" + "=" * 80)
    print("7Ô∏è‚É£ –ü–û–ò–°–ö –ò–ó–í–ï–°–¢–ù–´–• ENDPOINTS")
    print("=" * 80)
    
    known_endpoints = [
        '/api/company/',
        '/sprav/api/company/',
        '/business/server-components/',
        'price-lists',
        'posts',
        'publications',
        'news',
    ]
    
    for endpoint in known_endpoints:
        matches = list(re.finditer(re.escape(endpoint), content, re.IGNORECASE))
        if matches:
            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ '{endpoint}': {len(matches)} –≤—Ö–æ–∂–¥–µ–Ω–∏–π")
            for i, match in enumerate(matches[:2]):
                start = max(0, match.start() - 100)
                end = min(len(content), match.end() + 200)
                context = content[start:end]
                print(f"   –í—Ö–æ–∂–¥–µ–Ω–∏–µ #{i+1}: {context[:300]}...")
    
    print("\n" + "=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 80)
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("1. –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã endpoints - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Ö –≤ –±—Ä–∞—É–∑–µ—Ä–µ/Postman")
    print("2. –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–ª—é—á–∏ 'posts'/'publications' - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON")
    print("3. –ï—Å–ª–∏ —Ñ–∞–π–ª HTML/JS - –∏—â–∏—Ç–µ window.__INITIAL__ –∏–ª–∏ –ø–æ–¥–æ–±–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
    print("4. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ endpoints –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–∞—Ä—Å–µ—Ä–µ")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python analyze_sidebar_response.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É>")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python analyze_sidebar_response.py sidebar_response.txt")
        sys.exit(1)
    
    file_path = sys.argv[1]
    if not Path(file_path).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        sys.exit(1)
    
    analyze_sidebar_response(file_path)

