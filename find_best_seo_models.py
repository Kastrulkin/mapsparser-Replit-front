#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π Hugging Face –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞
"""
import requests
import os
from dotenv import load_dotenv

load_dotenv()

def find_best_seo_models():
    """–ò—â–µ—Ç –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞"""
    
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞
    search_queries = [
        "text-generation",
        "text2text-generation", 
        "causal-lm",
        "russian language",
        "multilingual",
        "business analysis",
        "SEO optimization",
        "recommendation system",
        "text analysis",
        "content generation",
        "instruction following",
        "chat model",
        "instruct model",
        "llama",
        "mistral",
        "gemma",
        "qwen",
        "yi",
        "deepseek",
        "codellama",
        "phi",
        "falcon",
        "mpt",
        "redpajama",
        "openllama",
        "vicuna",
        "alpaca",
        "dolly",
        "stablelm",
        "neural-chat",
        "orca",
        "wizardlm",
        "baichuan",
        "chatglm",
        "internlm",
        "aquila",
        "skywork",
        "zephyr",
        "solar",
        "mixtral",
        "llama2",
        "llama3",
        "gpt4all",
        "nomic",
        "openhermes",
        "tigerbot",
        "qwen2",
        "deepseek-coder",
        "codellama-instruct",
        "phi-2",
        "phi-3",
        "gemma2",
        "mistral-7b",
        "mixtral-8x7b",
        "llama-3-8b",
        "llama-3-70b"
    ]
    
    print("üîç –ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞...")
    print("=" * 80)
    
    found_models = []
    
    for query in search_queries:
        print(f"\nüìù –ü–æ–∏—Å–∫: {query}")
        
        try:
            response = requests.get(
                "https://huggingface.co/api/models",
                headers=headers,
                params={
                    "search": query,
                    "sort": "downloads",
                    "direction": "-1",
                    "limit": 20
                }
            )
            
            if response.status_code == 200:
                models = response.json()
                
                for model in models:
                    model_id = model.get('id', '')
                    downloads = model.get('downloads', 0)
                    likes = model.get('likes', 0)
                    tags = model.get('tags', [])
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–æ–¥–µ–ª–∏
                    if downloads > 10000 and any(tag in ['text-generation', 'text2text-generation', 'causal-lm', 'russian', 'multilingual', 'instruct', 'chat'] for tag in tags):
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
                        card_data = model.get('cardData', {})
                        model_size = "Unknown"
                        if 'model-index' in card_data:
                            try:
                                model_size = card_data['model-index'].get('results', [{}])[0].get('metrics', {}).get('parameters', 'Unknown')
                            except:
                                pass
                        
                        found_models.append({
                            'id': model_id,
                            'downloads': downloads,
                            'likes': likes,
                            'tags': tags,
                            'query': query,
                            'size': model_size
                        })
                        
                        print(f"  ‚úÖ {model_id}")
                        print(f"     üì• Downloads: {downloads:,}")
                        print(f"     ‚ù§Ô∏è  Likes: {likes}")
                        print(f"     üìä Size: {model_size}")
                        print(f"     üè∑Ô∏è  Tags: {', '.join(tags[:5])}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
                        if any(tag in ['russian', 'multilingual'] for tag in tags):
                            print(f"     üåç –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
                        if any(tag in ['instruct', 'chat', 'llama3', 'mistral', 'gemma', 'qwen2'] for tag in tags):
                            print(f"     üöÄ –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    found_models.sort(key=lambda x: x['downloads'], reverse=True)
    
    print("\n" + "=" * 80)
    print("üèÜ –¢–û–ü-20 –õ–£–ß–®–ò–• –ú–û–î–ï–õ–ï–ô –î–õ–Ø SEO –ê–ù–ê–õ–ò–ó–ê:")
    print("=" * 80)
    
    for i, model in enumerate(found_models[:20], 1):
        print(f"\n{i}. {model['id']}")
        print(f"   üì• Downloads: {model['downloads']:,}")
        print(f"   ‚ù§Ô∏è  Likes: {model['likes']}")
        print(f"   üìä Size: {model['size']}")
        print(f"   üè∑Ô∏è  Tags: {', '.join(model['tags'][:5])}")
        print(f"   üîç Found by: {model['query']}")
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –æ—Ç–º–µ—Ç–∫–∏
        if any(tag in ['russian', 'multilingual'] for tag in model['tags']):
            print(f"   üåç –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
        if any(tag in ['instruct', 'chat'] for tag in model['tags']):
            print(f"   üéØ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
        if any(tag in ['llama3', 'mistral', 'gemma', 'qwen2'] for tag in model['tags']):
            print(f"   üöÄ –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + "=" * 80)
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø SEO –ê–ù–ê–õ–ò–ó–ê:")
    print("=" * 80)
    
    if found_models:
        # –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        russian_models = [m for m in found_models if any(tag in ['russian', 'multilingual'] for tag in m['tags'])]
        
        if russian_models:
            best_russian = russian_models[0]
            print(f"\nüåç –õ–£–ß–®–ê–Ø –î–õ–Ø –†–£–°–°–ö–û–ì–û –Ø–ó–´–ö–ê:")
            print(f"   {best_russian['id']} ({best_russian['downloads']:,} –∑–∞–≥—Ä—É–∑–æ–∫)")
        
        # –õ—É—á—à–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        modern_models = [m for m in found_models if any(tag in ['llama3', 'mistral', 'gemma', 'qwen2', 'instruct'] for tag in m['tags'])]
        
        if modern_models:
            best_modern = modern_models[0]
            print(f"\nüöÄ –õ–£–ß–®–ê–Ø –°–û–í–†–ï–ú–ï–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:")
            print(f"   {best_modern['id']} ({best_modern['downloads']:,} –∑–∞–≥—Ä—É–∑–æ–∫)")
        
        # –õ—É—á—à–∏–µ –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        best_popular = found_models[0]
        print(f"\nüìà –°–ê–ú–ê–Ø –ü–û–ü–£–õ–Ø–†–ù–ê–Ø:")
        print(f"   {best_popular['id']} ({best_popular['downloads']:,} –∑–∞–≥—Ä—É–∑–æ–∫)")
        
        print(f"\n‚öôÔ∏è  –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –î–õ–ò–ù–ù–´–• –ü–†–û–ú–ü–¢–û–í:")
        print(f"   - max_length: 4096-8192 (–¥–ª—è –≤–∞—à–µ–≥–æ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)")
        print(f"   - temperature: 0.3-0.5 (–¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)")
        print(f"   - do_sample: True")
        print(f"   - top_p: 0.9")
        print(f"   - repetition_penalty: 1.1")
        
        print(f"\nüìù –í–ê–® –ü–†–û–ú–ü–¢ –û–ß–ï–ù–¨ –î–ï–¢–ê–õ–¨–ù–´–ô:")
        print(f"   ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç 2025")
        print(f"   ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º")
        print(f"   ‚úÖ –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
        print(f"   ‚úÖ –§–æ–∫—É—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —Ä—ã–Ω–∫–µ")
        print(f"   ‚ö†Ô∏è  –ù—É–∂–Ω–∞ –º–æ–¥–µ–ª—å —Å –±–æ–ª—å—à–∏–º max_length –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞")

if __name__ == "__main__":
    find_best_seo_models() 