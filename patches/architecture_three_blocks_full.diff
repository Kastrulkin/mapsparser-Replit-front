diff --git a/src/parser_interception.py b/src/parser_interception.py
index 7b2b45e..407641e 100644
--- a/src/parser_interception.py
+++ b/src/parser_interception.py
@@ -12,16 +12,207 @@ import time
 import random
 from typing import Dict, Any, List, Optional
 from urllib.parse import urlparse, parse_qs
+import os
+from datetime import datetime
 
 from browser_session import BrowserSession, BrowserSessionManager
 
+DEBUG_DIR = os.getenv("DEBUG_DIR", "/app/debug_data")
+
+ALLOWED_SESSION_KWARGS = {
+    # –î–æ–ø—É—Å—Ç–∏–º—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Å—Å–∏–∏
+    "proxy",
+    "timeout",
+    "retries",
+    "trace",
+    # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–∏ open_session
+    "headless",
+    "cookies",
+    "user_agent",
+    "viewport",
+    "locale",
+    "timezone_id",
+    "launch_args",
+    "init_scripts",
+}
+
+def _find_paths(obj: Any, target_keys: List[str], max_depth: int = 6, max_preview_len: int = 120,
+                max_results_per_key: int = 20) -> Dict[str, List[Dict[str, str]]]:
+    """
+    Dev-only —É—Ç–∏–ª–∏—Ç–∞: –Ω–∞–π—Ç–∏ –ø—É—Ç–∏ –∫ –∫–ª—é—á–∞–º target_keys –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–º JSON (dict/list).
+
+    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å:
+      { key: [ { "path": "payload.company.rubrics[0].name", "preview": "..." }, ... ] }
+    """
+    targets = set(target_keys)
+    results: Dict[str, List[Dict[str, str]]] = {k: [] for k in targets}
+
+    def _add_result(key: str, path: str, value: Any) -> None:
+        bucket = results.setdefault(key, [])
+        if len(bucket) >= max_results_per_key:
+            return
+        try:
+            if isinstance(value, (dict, list)):
+                preview = json.dumps(value, ensure_ascii=False)
+            else:
+                preview = str(value)
+        except Exception:
+            preview = repr(value)
+        if len(preview) > max_preview_len:
+            preview = preview[:max_preview_len] + "‚Ä¶"
+        bucket.append({"path": path, "preview": preview})
+
+    def _walk(node: Any, path: str, depth: int) -> None:
+        if depth > max_depth:
+            return
+        if isinstance(node, dict):
+            for k, v in node.items():
+                new_path = f"{path}.{k}" if path else k
+                if k in targets:
+                    _add_result(k, new_path, v)
+                _walk(v, new_path, depth + 1)
+        elif isinstance(node, list):
+            for idx, item in enumerate(node):
+                new_path = f"{path}[{idx}]" if path else f"[{idx}]"
+                _walk(item, new_path, depth + 1)
+
+    _walk(obj, "", 0)
+    return {k: v for k, v in results.items() if v}
+
+
+def _set_if_empty(result: Dict[str, Any], key: str, value: Any) -> None:
+    """
+    –ü–æ—Å—Ç–∞–≤–∏—Ç—å result[key] —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–∞–º —Å–µ–π—á–∞—Å "–ø—É—Å—Ç–æ" –∏ value –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ.
+    –ü—É—Å—Ç–æ: None, '', [], {}.
+    """
+    if value is None:
+        return
+    if isinstance(value, str) and not value.strip():
+        return
+
+    current = result.get(key)
+    if current is None or current == "" or current == [] or current == {}:
+        result[key] = value
+
+
+def _extend_unique(result: Dict[str, Any], key: str, items: List[Any]) -> None:
+    """
+    –î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–æ–∫ result[key] –±–µ–∑ –¥—É–±–ª–µ–π, –Ω–µ –∑–∞—Ç–∏—Ä–∞—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ.
+    """
+    if not items:
+        return
+
+    # –î–ª—è categories —Ö—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (–∏–º–µ–Ω/–º–µ—Ç–æ–∫), –±–µ–∑ dict –∏ –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤.
+    if key == "categories":
+        def _cat_str_from_item(it: Any) -> Optional[str]:
+            if isinstance(it, str):
+                s = it.strip()
+                return s or None
+            if isinstance(it, dict):
+                for k in ("name", "label", "text", "title"):
+                    v = it.get(k)
+                    if isinstance(v, str) and v.strip():
+                        return v.strip()
+            return None
+
+        existing_raw = result.get(key)
+        existing_list: List[str] = []
+        if isinstance(existing_raw, list):
+            for it in existing_raw:
+                s = _cat_str_from_item(it)
+                if s and s not in existing_list:
+                    existing_list.append(s)
+        elif isinstance(existing_raw, str) and existing_raw.strip():
+            existing_list = [existing_raw.strip()]
+
+        seen = set(existing_list)
+        for item in items:
+            s = _cat_str_from_item(item)
+            if not s or s in seen:
+                continue
+            existing_list.append(s)
+            seen.add(s)
+
+        result[key] = existing_list
+        return
+
+    # –û–±—â–∏–π —Å–ª—É—á–∞–π: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∏–ø—ã –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ –∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–µ–π –ø–æ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—é.
+    existing = result.get(key)
+    if existing is None:
+        existing_list: List[Any] = []
+    elif isinstance(existing, list):
+        existing_list = existing
+    else:
+        existing_list = [existing]
+
+    seen = {str(x) for x in existing_list}
+    for item in items:
+        s = str(item)
+        if s in seen:
+            continue
+        existing_list.append(item)
+        seen.add(s)
+
+    result[key] = existing_list
+
+
+def _get_nested(obj: Any, path: str) -> Any:
+    """
+    –î–æ—Å—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—É—Ç–∏ –≤–∏–¥–∞ "payload.company.rubrics[0].name"
+    —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–Ω–¥–µ–∫—Å–æ–≤ [0].
+    """
+    if not path:
+        return obj
+
+    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ç–æ—á–∫–∞–º, –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏–Ω–¥–µ–∫—Å—ã [0]
+    for part in path.split("."):
+        if not part:
+            continue
+        # –í—ã–¥–µ–ª—è–µ–º –∫–ª—é—á –∏ –∏–Ω–¥–µ–∫—Å—ã.
+        # –ü—Ä–∏–º–µ—Ä part: "rubrics[0][1]"
+        i = 0
+        key = ""
+        # –°–æ–±–∏—Ä–∞–µ–º –±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—É—é —á–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–π —Å–∫–æ–±–∫–∏
+        while i < len(part) and part[i] != "[":
+            key += part[i]
+            i += 1
+
+        if key:
+            if not isinstance(obj, dict):
+                return None
+            obj = obj.get(key)
+            if obj is None:
+                return None
+
+        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤–∏–¥–∞ [0]
+        while i < len(part):
+            if part[i] != "[":
+                return None
+            j = part.find("]", i)
+            if j == -1:
+                return None
+            index_str = part[i + 1 : j]
+            try:
+                idx = int(index_str)
+            except ValueError:
+                return None
+            if not isinstance(obj, list) or idx < 0 or idx >= len(obj):
+                return None
+            obj = obj[idx]
+            i = j + 1
+
+    return obj
+
 
 class YandexMapsInterceptionParser:
     """–ü–∞—Ä—Å–µ—Ä –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç —á–µ—Ä–µ–∑ –ø–µ—Ä–µ—Ö–≤–∞—Ç —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
     
-    def __init__(self):
-        self.api_responses = {}
-        self.org_id = None
+    def __init__(self, debug_bundle_id: Optional[str] = None):
+        self.api_responses: Dict[str, Any] = {}
+        self.org_id: Optional[str] = None
+        self.debug_bundle_id: Optional[str] = debug_bundle_id
+        _base = os.getenv("DEBUG_DIR", "/app/debug_data")
+        self.debug_bundle_dir: Optional[str] = os.path.join(_base, debug_bundle_id) if debug_bundle_id else None
         
     def extract_org_id(self, url: str) -> Optional[str]:
         """–ò–∑–≤–ª–µ—á—å org_id –∏–∑ URL –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç
@@ -61,9 +252,28 @@ class YandexMapsInterceptionParser:
         
         print(f"üìã –ò–∑–≤–ª–µ—á–µ–Ω org_id: {self.org_id}")
 
+        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º bundle-–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ (–µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–¥–∞–Ω–∞ –≤ __init__)
+        if not self.debug_bundle_id:
+            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
+            self.debug_bundle_id = f"yandex_{self.org_id}_{ts}"
+        if not self.debug_bundle_dir:
+            self.debug_bundle_dir = os.path.join(os.getenv("DEBUG_DIR", "/app/debug_data"), self.debug_bundle_id)
+        try:
+            if self.debug_bundle_dir:
+                os.makedirs(self.debug_bundle_dir, exist_ok=True)
+        except Exception as e:
+            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å debug bundle dir {self.debug_bundle_dir}: {e}")
+        else:
+            if self.debug_bundle_dir:
+                print(f"[DEBUG_BUNDLE] {self.debug_bundle_dir}")
+
         context = session.context
         page = session.page
 
+        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è debug bundle
+        initial_url = url
+        main_http_status: Optional[int] = None
+
         # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã
         self.api_responses = {}
 
@@ -84,9 +294,7 @@ class YandexMapsInterceptionParser:
 
                             # DEBUG: Save to file for inspection
                             try:
-                                import os
-
-                                debug_dir = os.path.join(os.getcwd(), "debug_data")
+                                debug_dir = self.debug_bundle_dir or DEBUG_DIR
                                 os.makedirs(debug_dir, exist_ok=True)
 
                                 # Create filename from URL path last part or timestamp
@@ -97,7 +305,6 @@ class YandexMapsInterceptionParser:
 
                                 with open(filepath, "w", encoding="utf-8") as f:
                                     json.dump(json_data, f, ensure_ascii=False, indent=2)
-                                print(f"üíæ Saved debug response: {filename}")
                             except Exception as e:
                                 print(f"Failed to save debug json: {e}")
 
@@ -135,7 +342,12 @@ class YandexMapsInterceptionParser:
         # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
         print("üåê –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º API –∑–∞–ø—Ä–æ—Å—ã...")
         try:
-            page.goto(url, wait_until="domcontentloaded", timeout=30000)
+            main_response = page.goto(url, wait_until="domcontentloaded", timeout=30000)
+            try:
+                if main_response is not None:
+                    main_http_status = main_response.status
+            except Exception:
+                main_http_status = None
 
             # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏—è
             for _ in range(24):  # –ñ–¥–µ–º –¥–æ 120 —Å–µ–∫—É–Ω–¥
@@ -209,9 +421,11 @@ class YandexMapsInterceptionParser:
 
             # Debug: Save bad page
             try:
-                with open("debug_data/redirect_page.html", "w", encoding="utf-8") as f:
-                    f.write(page.content())
-                print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ HTML —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–¥–∏—Ä–µ–∫—Ç–∞ –≤ debug_data/redirect_page.html")
+                html_redirect = page.content()
+                debug_dir = self.debug_bundle_dir or DEBUG_DIR
+                os.makedirs(debug_dir, exist_ok=True)
+                with open(os.path.join(debug_dir, "redirect_page.html"), "w", encoding="utf-8") as f:
+                    f.write(html_redirect or "")
             except Exception:
                 pass
 
@@ -230,8 +444,11 @@ class YandexMapsInterceptionParser:
             except PlaywrightTimeoutError:
                 print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ä—Ç–æ—á–∫—É –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞. –í–æ–∑–º–æ–∂–Ω–æ –±–∞–Ω.")
                 try:
-                    with open("debug_data/failed_page_final.html", "w", encoding="utf-8") as f:
-                        f.write(page.content())
+                    html_failed = page.content()
+                    debug_dir = self.debug_bundle_dir or DEBUG_DIR
+                    os.makedirs(debug_dir, exist_ok=True)
+                    with open(os.path.join(debug_dir, "failed_page_final.html"), "w", encoding="utf-8") as f:
+                        f.write(html_failed or "")
                 except Exception:
                     pass
         else:
@@ -591,6 +808,211 @@ class YandexMapsInterceptionParser:
                 except Exception:
                     pass
 
+        # DEBUG BUNDLE (dev): —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≤–æ–¥–∫—É –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º
+        try:
+            debug_dir = self.debug_bundle_dir or DEBUG_DIR
+            os.makedirs(debug_dir, exist_ok=True)
+
+            final_url = page.url
+            page_title = ""
+            try:
+                page_title = page.title()
+            except Exception:
+                pass
+
+            html_content = ""
+            try:
+                html_content = page.content()
+            except Exception:
+                pass
+            html_length = len(html_content or "")
+
+            intercepted_json_count = len(self.api_responses)
+            all_urls = list(self.api_responses.keys())
+            last_10_urls = all_urls[-10:]
+
+            # –¢–æ–ø-3 —Å–∞–º—ã—Ö –∫—Ä—É–ø–Ω—ã—Ö JSON-–æ—Ç–≤–µ—Ç–∞ –ø–æ –¥–ª–∏–Ω–µ body
+            sized = []
+            for u, info in self.api_responses.items():
+                try:
+                    body = info.get("data")
+                    body_str = json.dumps(body, ensure_ascii=False)
+                    sized.append((u, len(body_str)))
+                except Exception:
+                    continue
+            sized.sort(key=lambda x: x[1], reverse=True)
+            top_3_urls = [u for (u, _) in sized[:3]]
+
+            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ cookies –∏ –¥–æ–º–µ–Ω–∞—Ö
+            cookie_domains = set()
+            final_host = ""
+            try:
+                parsed = urlparse(final_url)
+                final_host = parsed.hostname or ""
+            except Exception:
+                final_host = ""
+
+            try:
+                cookies = context.cookies()
+                for c in cookies:
+                    dom = c.get("domain")
+                    if dom:
+                        cookie_domains.add(dom)
+            except Exception:
+                pass
+
+            # –ü—Ä–∏–∑–Ω–∞–∫–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ / –∫–∞–ø—á–∏
+            blocked_flags = {
+                "has_captcha_text": any(
+                    kw in (page_title or "")
+                    for kw in ["–û–π!", "Captcha", "Robot", "–í—ã –Ω–µ —Ä–æ–±–æ—Ç"]
+                ),
+                "html_contains_captcha": ("smart-captcha" in (html_content or "")),
+            }
+
+            timestamp = int(time.time() * 1000)
+            safe_org = (self.org_id or "unknown")[:32]
+            summary_name = f"debug_{timestamp}_{safe_org}.json"
+            html_name = f"debug_{timestamp}_{safe_org}.html"
+            screenshot_name = f"debug_{timestamp}_{safe_org}.png"
+
+            summary_path = os.path.join(debug_dir, summary_name)
+            html_path = os.path.join(debug_dir, html_name)
+            screenshot_path = os.path.join(debug_dir, screenshot_name)
+
+            debug_summary = {
+                "final_url": final_url,
+                "page_title": page_title,
+                "html_length": html_length,
+                "intercepted_json_count": intercepted_json_count,
+                "last_10_json_urls": last_10_urls,
+                "top_3_largest_json_urls": top_3_urls,
+                "cookie_domains": sorted(cookie_domains),
+                "final_host": final_host,
+                "blocked_flags": blocked_flags,
+                "org_id": self.org_id,
+            }
+
+            # –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –ø—É—Ç–µ–π –≤ –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö JSON-–æ—Ç–≤–µ—Ç–∞—Ö
+            target_keys = [
+                "address",
+                "address_name",
+                "fullAddress",
+                "rating",
+                "score",
+                "ratingData",
+                "rubrics",
+                "categories",
+                "rubric",
+            ]
+            found_key_paths: Dict[str, List[Dict[str, str]]] = {}
+            for u in top_3_urls:
+                info = self.api_responses.get(u)
+                if not info:
+                    continue
+                data = info.get("data")
+                try:
+                    paths = _find_paths(data, target_keys)
+                    for key, items in paths.items():
+                        bucket = found_key_paths.setdefault(key, [])
+                        # –ª–∏–º–∏—Ç–∏—Ä—É–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –ø–æ –∫–ª—é—á—É
+                        for item in items:
+                            if len(bucket) >= 30:
+                                break
+                            bucket.append({"url": u, **item})
+                except Exception:
+                    continue
+
+            if found_key_paths:
+                debug_summary["found_key_paths"] = found_key_paths
+
+            with open(summary_path, "w", encoding="utf-8") as f:
+                json.dump(debug_summary, f, ensure_ascii=False, indent=2)
+
+            if html_content:
+                with open(html_path, "w", encoding="utf-8") as f:
+                    f.write(html_content)
+
+            try:
+                page.screenshot(path=screenshot_path, full_page=True)
+            except Exception:
+                pass
+
+            print(f"üíæ Debug bundle saved: {summary_name}, {html_name}, {screenshot_name}")
+        except Exception as e:
+            print(f"‚ö†Ô∏è Failed to save debug bundle: {e}")
+
+        # DEV-–ª–æ–≥ –ø–æ –∏—Ç–æ–≥–æ–≤—ã–º –ø–æ–ª—è–º
+        try:
+            cats = data.get("categories") or []
+            if isinstance(cats, list):
+                categories_count = len(cats)
+            elif cats:
+                categories_count = 1
+            else:
+                categories_count = 0
+
+            quality_score = None
+            meta = data.get("_meta")
+            if isinstance(meta, dict):
+                quality_score = meta.get("quality_score")
+
+            print(
+                f"DEV summary: title='{str(data.get('title', ''))[:80]}', "
+                f"address_present={bool(data.get('address'))}, "
+                f"rating='{data.get('rating', '')}', "
+                f"reviews_count={data.get('reviews_count')}, "
+                f"categories_count={categories_count}, "
+                f"quality_score={quality_score}"
+            )
+        except Exception:
+            pass
+
+        # –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π debug bundle –¥–ª—è —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π:
+        # request_url.txt, final_url.txt, http_status.txt, page.html, payload.json
+        if self.debug_bundle_dir:
+            try:
+                bundle_dir = self.debug_bundle_dir
+                os.makedirs(bundle_dir, exist_ok=True)
+
+                # HTML –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
+                try:
+                    page_html = page.content()
+                except Exception:
+                    page_html = html_content or ""
+                with open(os.path.join(bundle_dir, "page.html"), "w", encoding="utf-8") as f:
+                    f.write(page_html or "")
+
+                # –ò—Å—Ö–æ–¥–Ω—ã–π URL
+                try:
+                    with open(os.path.join(bundle_dir, "request_url.txt"), "w", encoding="utf-8") as f:
+                        f.write(initial_url or "")
+                except Exception:
+                    pass
+
+                # –§–∏–Ω–∞–ª—å–Ω—ã–π URL
+                try:
+                    with open(os.path.join(bundle_dir, "final_url.txt"), "w", encoding="utf-8") as f:
+                        f.write(final_url or "")
+                except Exception:
+                    pass
+
+                # HTTP —Å—Ç–∞—Ç—É—Å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
+                try:
+                    with open(os.path.join(bundle_dir, "http_status.txt"), "w", encoding="utf-8") as f:
+                        f.write("" if main_http_status is None else str(main_http_status))
+                except Exception:
+                    pass
+
+                # –°—ã—Ä–æ–π payload (–∏—Ç–æ–≥–æ–≤—ã–π card_data)
+                try:
+                    with open(os.path.join(bundle_dir, "payload.json"), "w", encoding="utf-8") as f:
+                        json.dump(data, f, ensure_ascii=False, indent=2)
+                except Exception as e:
+                    print(f"‚ö†Ô∏è Failed to write payload.json: {e}")
+            except Exception as e:
+                print(f"‚ö†Ô∏è Failed to write canonical debug bundle files: {e}")
+
         print(
             f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ: –Ω–∞–∑–≤–∞–Ω–∏–µ='{data.get('title', '')}', –∞–¥—Ä–µ—Å='{data.get('address', '')}'"
         )
@@ -767,29 +1189,44 @@ class YandexMapsInterceptionParser:
                 if title_cand and title_cand not in ['–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', '–†–æ—Å—Å–∏—è', '–Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç—ã', '–ú–æ—Å–∫–≤–∞']:
                     result['title'] = title_cand
                 
-                # –ò—â–µ–º –∞–¥—Ä–µ—Å
+                # –ò—â–µ–º –∞–¥—Ä–µ—Å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á + –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤)
+                addr_val = None
                 if 'address' in data:
                     addr = data['address']
                     if isinstance(addr, dict):
-                        result['address'] = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
+                        addr_val = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
                     else:
-                        result['address'] = str(addr)
+                        addr_val = str(addr)
+                if not addr_val:
+                    addr_val = data.get('address_name') or data.get('fullAddress') or data.get('full_address') or ''
+                if addr_val and isinstance(addr_val, str) and len(addr_val.strip()) > 2:
+                    _set_if_empty(result, "address", addr_val.strip())
                 
                 # –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                 if 'rating' in data:
                     rating = data['rating']
                     if isinstance(rating, (int, float)):
-                        result['rating'] = str(rating)
+                        _set_if_empty(result, "rating", str(rating))
                     elif isinstance(rating, dict):
-                        result['rating'] = str(rating.get('value', rating.get('score', rating.get('val', ''))))
+                        _set_if_empty(
+                            result,
+                            "rating",
+                            str(rating.get('value', rating.get('score', rating.get('val', '')))),
+                        )
                 elif 'score' in data:
-                    result['rating'] = str(data['score'])
+                    _set_if_empty(result, "rating", str(data['score']))
                 
                 # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
                 if 'reviewsCount' in data:
-                    result['reviews_count'] = int(data['reviewsCount'])
+                    try:
+                        _set_if_empty(result, "reviews_count", int(data['reviewsCount']))
+                    except (TypeError, ValueError):
+                        pass
                 elif 'reviews_count' in data:
-                    result['reviews_count'] = int(data['reviews_count'])
+                    try:
+                        _set_if_empty(result, "reviews_count", int(data['reviews_count']))
+                    except (TypeError, ValueError):
+                        pass
                 
                 # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                 for value in data.values():
@@ -821,13 +1258,18 @@ class YandexMapsInterceptionParser:
                         # print(f"‚úÖ [Parser] Found title: {title_cand}")
                         result['title'] = title_cand
                 
-                # –ò—â–µ–º –∞–¥—Ä–µ—Å
+                # –ò—â–µ–º –∞–¥—Ä–µ—Å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á + –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤)
+                addr_val = None
                 if 'address' in data:
                     addr = data['address']
                     if isinstance(addr, dict):
-                        result['address'] = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
+                        addr_val = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
                     else:
-                        result['address'] = str(addr)
+                        addr_val = str(addr)
+                if not addr_val:
+                    addr_val = data.get('address_name') or data.get('fullAddress') or data.get('full_address') or ''
+                if addr_val and isinstance(addr_val, str) and len(addr_val.strip()) > 2:
+                    result['address'] = addr_val.strip()
                 
                 # –ò—â–µ–º —Ä–µ–π—Ç–∏–Ω–≥
                 if 'rating' in data:
@@ -857,6 +1299,57 @@ class YandexMapsInterceptionParser:
                 elif 'reviews_count' in data:
                     result['reviews_count'] = int(data['reviews_count'])
                 
+                # –ò—â–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ / —Ä—É–±—Ä–∏–∫–∏
+                if 'rubrics' in data and isinstance(data['rubrics'], list):
+                    names = []
+                    for r in data['rubrics']:
+                        if isinstance(r, dict):
+                            n = r.get('name') or r.get('label')
+                            if n:
+                                names.append(str(n))
+                    if names:
+                        result['categories'] = names
+                elif 'categories' in data:
+                    cats = data['categories']
+                    if isinstance(cats, list) and cats:
+                        # –£–∂–µ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏–ª–∏ –æ–±—ä–µ–∫—Ç–æ–≤
+                        result['categories'] = cats
+                    elif isinstance(cats, dict) and cats:
+                        result['categories'] = [cats]
+                elif 'rubric' in data:
+                    rub = data['rubric']
+                    if isinstance(rub, str) and rub.strip():
+                        result['categories'] = [rub.strip()]
+                    elif isinstance(rub, dict):
+                        n = rub.get('name') or rub.get('label')
+                        if n:
+                            result['categories'] = [str(n)]
+                
+                # –ò—â–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ / —Ä—É–±—Ä–∏–∫–∏
+                if 'rubrics' in data and isinstance(data['rubrics'], list):
+                    names = []
+                    for r in data['rubrics']:
+                        if isinstance(r, dict):
+                            n = r.get('name') or r.get('label')
+                            if n:
+                                names.append(str(n))
+                    if names:
+                        _extend_unique(result, 'categories', names)
+                elif 'categories' in data:
+                    cats = data['categories']
+                    if isinstance(cats, list) and cats:
+                        _extend_unique(result, 'categories', cats)
+                    elif isinstance(cats, dict) and cats:
+                        _extend_unique(result, 'categories', [cats])
+                elif 'rubric' in data:
+                    rub = data['rubric']
+                    if isinstance(rub, str) and rub.strip():
+                        _extend_unique(result, 'categories', [rub.strip()])
+                    elif isinstance(rub, dict):
+                        n = rub.get('name') or rub.get('label')
+                        if n:
+                            _extend_unique(result, 'categories', [str(n)])
+                
                 # –ò—â–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω
                 if 'phones' in data:
                     phones = data['phones']
@@ -874,6 +1367,52 @@ class YandexMapsInterceptionParser:
                     extract_nested(value)
         
         extract_nested(json_data)
+
+        # Fallback –ø–æ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –ø—É—Ç—è–º (payload.company.*)
+        try:
+            addr_nested = (
+                _get_nested(json_data, "payload.company.address.formatted")
+                or _get_nested(json_data, "payload.company.address_name")
+                or _get_nested(json_data, "payload.company.fullAddress")
+            )
+            _set_if_empty(result, "address", addr_nested)
+        except Exception:
+            pass
+
+        try:
+            rating_nested = (
+                _get_nested(json_data, "payload.company.ratingData.rating")
+                or _get_nested(json_data, "payload.company.ratingData.score")
+            )
+            _set_if_empty(result, "rating", rating_nested)
+        except Exception:
+            pass
+
+        try:
+            cnt = _get_nested(json_data, "payload.company.ratingData.count")
+            if isinstance(cnt, (int, float, str)):
+                try:
+                    cnt_int = int(cnt)
+                    _set_if_empty(result, "reviews_count", cnt_int)
+                except ValueError:
+                    pass
+        except Exception:
+            pass
+
+        try:
+            rubrics = _get_nested(json_data, "payload.company.rubrics") or []
+            names = []
+            if isinstance(rubrics, list):
+                for r in rubrics:
+                    if isinstance(r, dict):
+                        n = r.get("name") or r.get("label")
+                        if n:
+                            names.append(str(n))
+            if names:
+                _extend_unique(result, "categories", names)
+        except Exception:
+            pass
+
         return result
     
     def _extract_organization_data(self, json_data: Any) -> Dict[str, Any]:
@@ -887,21 +1426,35 @@ class YandexMapsInterceptionParser:
                 if 'name' in data or 'title' in data:
                     result['title'] = data.get('name') or data.get('title', '')
                 
+                # –ê–¥—Ä–µ—Å: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á + –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã (—Ä–∞–∑–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –Ø–Ω–¥–µ–∫—Å–∞)
+                addr_val = None
                 if 'address' in data:
                     addr = data['address']
                     if isinstance(addr, dict):
-                        result['address'] = addr.get('formatted', '') or addr.get('full', '') or str(addr)
+                        addr_val = addr.get('formatted', '') or addr.get('full', '') or addr.get('text', '') or str(addr)
                     else:
-                        result['address'] = str(addr)
+                        addr_val = str(addr)
+                if not addr_val and 'address_name' in data:
+                    addr_val = data.get('address_name') or ''
+                if not addr_val and 'fullAddress' in data:
+                    addr_val = data.get('fullAddress') or ''
+                if not addr_val and 'full_address' in data:
+                    addr_val = data.get('full_address') or ''
+                if addr_val and isinstance(addr_val, str) and len(addr_val.strip()) > 2:
+                    _set_if_empty(result, "address", addr_val.strip())
                 
                 if 'rating' in data:
                     rating = data['rating']
                     if isinstance(rating, (int, float)):
-                        result['rating'] = str(rating)
+                        _set_if_empty(result, "rating", str(rating))
                     elif isinstance(rating, dict):
-                         result['rating'] = str(rating.get('value', rating.get('score', rating.get('val', ''))))
+                         _set_if_empty(
+                             result,
+                             "rating",
+                             str(rating.get('value', rating.get('score', rating.get('val', '')))),
+                         )
                 elif 'score' in data:
-                    result['rating'] = str(data['score'])
+                    _set_if_empty(result, "rating", str(data['score']))
                 
                 # Support modularPin rating (Yandex Update)
                 if 'modularPin' in data and isinstance(data['modularPin'], dict):
@@ -912,7 +1465,14 @@ class YandexMapsInterceptionParser:
                              break
                 
                 if 'reviewsCount' in data or 'reviews_count' in data:
-                    result['reviews_count'] = int(data.get('reviewsCount') or data.get('reviews_count', 0))
+                    try:
+                        _set_if_empty(
+                            result,
+                            "reviews_count",
+                            int(data.get('reviewsCount') or data.get('reviews_count', 0)),
+                        )
+                    except (TypeError, ValueError):
+                        pass
                 
                 if 'phones' in data:
                     phones = data['phones']
@@ -927,6 +1487,31 @@ class YandexMapsInterceptionParser:
                 if 'description' in data or 'about' in data:
                     result['description'] = data.get('description') or data.get('about', '')
                 
+                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ / —Ä—É–±—Ä–∏–∫–∏
+                if 'rubrics' in data and isinstance(data['rubrics'], list):
+                    names = []
+                    for r in data['rubrics']:
+                        if isinstance(r, dict):
+                            n = r.get('name') or r.get('label')
+                            if n:
+                                names.append(str(n))
+                    if names:
+                        _extend_unique(result, 'categories', names)
+                elif 'categories' in data:
+                    cats = data['categories']
+                    if isinstance(cats, list) and cats:
+                        _extend_unique(result, 'categories', cats)
+                    elif isinstance(cats, dict) and cats:
+                        _extend_unique(result, 'categories', [cats])
+                elif 'rubric' in data:
+                    rub = data['rubric']
+                    if isinstance(rub, str) and rub.strip():
+                        _extend_unique(result, 'categories', [rub.strip()])
+                    elif isinstance(rub, dict):
+                        n = rub.get('name') or rub.get('label')
+                        if n:
+                            _extend_unique(result, 'categories', [str(n)])
+                
                 # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                 for key, value in data.items():
                     extract_nested(value, f"{path}.{key}")
@@ -936,6 +1521,52 @@ class YandexMapsInterceptionParser:
                     extract_nested(item, path)
         
         extract_nested(json_data)
+
+        # Fallback –ø–æ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–º –ø—É—Ç—è–º (payload.company.*)
+        try:
+            addr_nested = (
+                _get_nested(json_data, "payload.company.address.formatted")
+                or _get_nested(json_data, "payload.company.address_name")
+                or _get_nested(json_data, "payload.company.fullAddress")
+            )
+            _set_if_empty(result, "address", addr_nested)
+        except Exception:
+            pass
+
+        try:
+            rating_nested = (
+                _get_nested(json_data, "payload.company.ratingData.rating")
+                or _get_nested(json_data, "payload.company.ratingData.score")
+            )
+            _set_if_empty(result, "rating", rating_nested)
+        except Exception:
+            pass
+
+        try:
+            cnt = _get_nested(json_data, "payload.company.ratingData.count")
+            if isinstance(cnt, (int, float, str)):
+                try:
+                    cnt_int = int(cnt)
+                    _set_if_empty(result, "reviews_count", cnt_int)
+                except ValueError:
+                    pass
+        except Exception:
+            pass
+
+        try:
+            rubrics = _get_nested(json_data, "payload.company.rubrics") or []
+            names = []
+            if isinstance(rubrics, list):
+                for r in rubrics:
+                    if isinstance(r, dict):
+                        n = r.get("name") or r.get("label")
+                        if n:
+                            names.append(str(n))
+            if names:
+                _extend_unique(result, "categories", names)
+        except Exception:
+            pass
+
         return result
     
     def _is_reviews_data(self, json_data: Any) -> bool:
@@ -1429,7 +2060,8 @@ def parse_yandex_card(
     keep_open_on_captcha: bool = False,
     session_registry: Optional[Dict[str, BrowserSession]] = None,
     session_id: Optional[str] = None,
-    **kwargs: Any,
+    debug_bundle_id: Optional[str] = None,
+    **session_kwargs: Any,
 ) -> Dict[str, Any]:
     """
     –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç c –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π human-in-the-loop.
@@ -1440,6 +2072,20 @@ def parse_yandex_card(
     manager = BrowserSessionManager()
     session: Optional[BrowserSession] = None
 
+    # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö kwargs –¥–ª—è —Å–µ—Å—Å–∏–∏
+    unknown = set(session_kwargs.keys()) - ALLOWED_SESSION_KWARGS
+    if unknown:
+        msg = f"Unknown session kwargs in parse_yandex_card: {unknown}"
+        env = os.getenv("FLASK_ENV", "").lower()
+        is_debug_env = env in ("development", "dev", "debug", "test", "testing")
+        if is_debug_env:
+            raise ValueError(msg)
+        else:
+            print(f"‚ö†Ô∏è {msg}")
+            # –í production ‚Äî –ø—Ä–æ—Å—Ç–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª—é—á–∏
+            for k in list(unknown):
+                session_kwargs.pop(k, None)
+
     # 1. –†–µ–∂–∏–º resume: –±–µ—Ä—ë–º —Å–µ—Å—Å–∏—é –∏–∑ registry –ø–æ session_id
     if session_id and session_registry is not None:
         session = manager.get(session_registry, session_id)
@@ -1451,19 +2097,19 @@ def parse_yandex_card(
     else:
         # 2. –ü–µ—Ä–≤—ã–π –∑–∞—Ö–æ–¥: –æ—Ç–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
         session = manager.open_session(
-            headless=kwargs.get("headless", True),
-            cookies=kwargs.get("cookies"),
-            user_agent=kwargs.get("user_agent"),
-            viewport=kwargs.get("viewport"),
-            locale=kwargs.get("locale", "ru-RU"),
-            timezone_id=kwargs.get("timezone_id", "Europe/Moscow"),
-            proxy=kwargs.get("proxy"),
-            launch_args=kwargs.get("launch_args"),
-            init_scripts=kwargs.get("init_scripts"),
+            headless=session_kwargs.get("headless", True),
+            cookies=session_kwargs.get("cookies"),
+            user_agent=session_kwargs.get("user_agent"),
+            viewport=session_kwargs.get("viewport"),
+            locale=session_kwargs.get("locale", "ru-RU"),
+            timezone_id=session_kwargs.get("timezone_id", "Europe/Moscow"),
+            proxy=session_kwargs.get("proxy"),
+            launch_args=session_kwargs.get("launch_args"),
+            init_scripts=session_kwargs.get("init_scripts"),
             keep_open=keep_open_on_captcha,
         )
 
-    parser = YandexMapsInterceptionParser()
+    parser = YandexMapsInterceptionParser(debug_bundle_id=debug_bundle_id)
 
     result: Dict[str, Any]
     try:
diff --git a/src/worker.py b/src/worker.py
index 4532525..886ea62 100644
--- a/src/worker.py
+++ b/src/worker.py
@@ -2,10 +2,12 @@ import time
 import uuid
 import json
 import re
+import os
+import traceback
 from datetime import datetime, timedelta
 import signal
 import sys
-from typing import Dict
+from typing import Dict, List, Any
 from dotenv import load_dotenv
 
 from browser_session import BrowserSession, BrowserSessionManager
@@ -15,9 +17,21 @@ load_dotenv()
 
 # New imports
 from database_manager import DatabaseManager
+from parsequeue_status import (
+    STATUS_CAPTCHA,
+    STATUS_COMPLETED,
+    STATUS_ERROR,
+    STATUS_PENDING,
+    STATUS_PROCESSING,
+)
 from yandex_business_sync_worker import YandexBusinessSyncWorker
 from external_sources import ExternalReview, ExternalSource, ExternalPost, ExternalStatsPoint, make_stats_id
 from dateutil import parser as date_parser
+from parsed_payload_validation import (
+    build_parsing_meta,
+    FIELDS_CRITICAL,
+    SOURCE_YANDEX_BUSINESS,
+)
 
 # –†–µ–µ—Å—Ç—Ä –∞–∫—Ç–∏–≤–Ω—ã—Ö Playwright-—Å–µ—Å—Å–∏–π –¥–ª—è human-in-the-loop
 ACTIVE_CAPTCHA_SESSIONS: Dict[str, BrowserSession] = {}
@@ -39,12 +53,12 @@ def _handle_worker_error(queue_id: str, error_msg: str):
         cursor.execute(
             """
             UPDATE parsequeue
-            SET status = 'error',
+            SET status = %s,
                 error_message = %s,
                 updated_at = CURRENT_TIMESTAMP
             WHERE id = %s
             """,
-            (error_msg, queue_id),
+            (STATUS_ERROR, error_msg, queue_id),
         )
         conn.commit()
         cursor.close()
@@ -189,32 +203,42 @@ def _parse_date_string(date_str: str) -> datetime | None:
     except Exception:
         return None
 
-def _is_parsing_successful(card_data: dict, business_id: str = None) -> tuple:
+def _validate_parsing_result(card_data: dict) -> tuple:
     """
-    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —É—Å–ø–µ—à–µ–Ω –ª–∏ –ø–∞—Ä—Å–∏–Ω–≥.
-    
+    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–ª—è–º. –ë–µ–∑ –ø–æ–¥–º–µ—à–∏–≤–∞–Ω–∏—è –∏–∑ –ë–î ‚Äî
+    —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—à–ª–æ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ø–Ω–¥–µ–∫—Å).
     Returns:
-        (is_successful: bool, reason: str)
+        (is_successful: bool, reason: str, validation_result: dict | None)
     """
-    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É
+    from parsed_payload_validation import validate_parsed_payload
+
     if card_data.get("error") == "captcha_detected":
-        return False, "captcha_detected"
-    
-    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫—É
+        return False, "captcha_detected", None
     if card_data.get("error"):
-        return False, f"error: {card_data.get('error')}"
-    
-    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π
-    title = card_data.get('title') or card_data.get('overview', {}).get('title')
-    address = card_data.get('address') or card_data.get('overview', {}).get('address')
-    
-    if not title:
-        return False, "missing_title"
-    
-    if not address:
-        return False, "missing_address"
-    
-    return True, "success"
+        return False, f"error: {card_data.get('error')}", None
+
+    validation = validate_parsed_payload(card_data, source=SOURCE_YANDEX_BUSINESS)
+    hard_missing = validation.get("hard_missing") or []
+    quality_score = validation.get("quality_score", 0.0)
+
+    if hard_missing:
+        return False, "missing_in_source:" + ",".join(hard_missing), validation
+
+    # –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ: –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫, –Ω–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø–æ–ª—è –ø–æ—á—Ç–∏ –≤—Å–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.
+    # –ù–µ —Å—á–∏—Ç–∞–µ–º —Ç–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É—Å–ø–µ—à–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
+    missing_fields = set(validation.get("missing_fields") or [])
+    critical_list = []
+    for field in ("address", "rating", "reviews_count", "categories"):
+        if field in missing_fields:
+            critical_list.append(field)
+
+    if quality_score < 0.4:
+        reason = f"low_quality_payload:quality_score={quality_score}"
+        if critical_list:
+            reason = f"{reason} missing={','.join(critical_list)}"
+        return False, reason, validation
+
+    return True, "success", validation
 
 def _has_cabinet_account(business_id: str) -> tuple:
     """
@@ -231,11 +255,9 @@ def _has_cabinet_account(business_id: str) -> tuple:
     
     try:
         cursor.execute("""
-            SELECT id 
-            FROM ExternalBusinessAccounts 
-            WHERE business_id = ? 
-              AND source = 'yandex_business' 
-              AND is_active = 1
+            SELECT id
+            FROM externalbusinessaccounts
+            WHERE business_id = %s AND source = 'yandex_business' AND is_active = TRUE
             LIMIT 1
         """, (business_id,))
         
@@ -257,7 +279,7 @@ def _ensure_column_exists(cursor, conn, table_name, column_name, column_type="TE
 
     try:
         # PRAGMA –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º f-string —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
-        ALLOWED_TABLES = {"ParseQueue", "MapParseResults"}
+        ALLOWED_TABLES = {"parsequeue", "cards"}
         if table_name not in ALLOWED_TABLES:
             raise ValueError(f"–ù–µ—Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞: {table_name}")
         cursor.execute(f"PRAGMA table_info({table_name})")
@@ -291,7 +313,7 @@ def process_queue():
             cursor.execute(
                 """
                 UPDATE parsequeue
-                SET status = 'pending',
+                SET status = %s,
                     captcha_status = 'expired',
                     captcha_required = 0,
                     captcha_url = NULL,
@@ -303,9 +325,10 @@ def process_queue():
                         error_message || '; broken captcha record: missing captcha_started_at',
                         'broken captcha record: missing captcha_started_at'
                     )
-                WHERE status = 'captcha'
+                WHERE status = %s
                   AND captcha_started_at IS NULL
-                """
+                """,
+                (STATUS_PENDING, STATUS_CAPTCHA),
             )
             if cursor.rowcount:
                 conn.commit()
@@ -321,9 +344,9 @@ def process_queue():
             SELECT *
             FROM parsequeue
             WHERE 
-                status = 'pending'
+                status = %s
                 OR (
-                    status = 'captcha'
+                    status = %s
                     AND (
                         resume_requested = 1
                         OR (retry_after IS NULL OR retry_after <= %s)
@@ -332,14 +355,14 @@ def process_queue():
                 )
             ORDER BY 
                 CASE 
-                    WHEN status = 'pending' THEN 1 
-                    WHEN status = 'captcha' THEN 2 
+                    WHEN status = %s THEN 1 
+                    WHEN status = %s THEN 2 
                     ELSE 3 
                 END,
                 created_at ASC 
             LIMIT 1
             """,
-            (now_iso, ttl_cutoff_iso),
+            (STATUS_PENDING, STATUS_CAPTCHA, now_iso, ttl_cutoff_iso, STATUS_PENDING, STATUS_CAPTCHA),
         )
         queue_item = cursor.fetchone()
         
@@ -349,10 +372,10 @@ def process_queue():
         # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Row –≤ —Å–ª–æ–≤–∞—Ä—å (RealDictCursor –≤ pg_db_utils)
         queue_dict = dict(queue_item)
         
-        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "processing"
+        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ processing
         cursor.execute(
             "UPDATE parsequeue SET status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
-            ("processing", queue_dict["id"]),
+            (STATUS_PROCESSING, queue_dict["id"]),
         )
         conn.commit()
     finally:
@@ -406,11 +429,11 @@ def process_queue():
                         captcha_url = NULL,
                         captcha_started_at = NULL,
                         resume_requested = 0,
-                        status = 'pending',
+                        status = %s,
                         updated_at = CURRENT_TIMESTAMP
                     WHERE id = %s
                     """,
-                    (task_id,),
+                    (STATUS_PENDING, task_id),
                 )
                 conn.commit()
             finally:
@@ -567,7 +590,7 @@ def process_queue():
             raise ValueError("URL –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞")
         
         url = queue_dict["url"]
-        
+
         # --- –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–°–´–õ–û–ö (SPRAV -> MAPS) ---
         if '/sprav/' in url:
             import re
@@ -582,26 +605,106 @@ def process_queue():
                 url = new_url
                 queue_dict['url'] = new_url # –û–±–Ω–æ–≤–ª—è–µ–º –∏ –≤ —Å–ª–æ–≤–∞—Ä–µ
 
+        url = queue_dict["url"]
+
         cookies = get_yandex_cookies()
-        card_data = parse_yandex_card(
-            url,
-            keep_open_on_captcha=True,
-            session_registry=ACTIVE_CAPTCHA_SESSIONS,
-            cookies=cookies,
-            user_agent=(
-                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
-                "AppleWebKit/537.36 (KHTML, like Gecko) "
-                "Chrome/120.0.0.0 Safari/537.36"
-            ),
-            viewport={"width": 1920, "height": 1080},
-            locale="ru-RU",
-            timezone_id="Europe/Moscow",
-            headless=True,
-        )
-        
-        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞
         business_id = queue_dict.get("business_id")
-        is_successful, reason = _is_parsing_successful(card_data, business_id)
+        debug_dir_root = os.getenv("DEBUG_DIR", "/app/debug_data").rstrip("/")
+
+        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º debug_bundle_id –∏ bundle_dir –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ (–ø—Ä–∏–≤—è–∑–∞–Ω –∫ –±–∏–∑–Ω–µ—Å—É –∏ –∑–∞–¥–∞—á–µ)
+        debug_bundle_id = None
+        bundle_dir = None
+        if business_id:
+            ts_dbg = datetime.now().strftime("%Y%m%d_%H%M%S")
+            debug_bundle_id = f"yandex_{business_id}_{queue_dict['id']}_{ts_dbg}"
+            bundle_dir = os.path.join(debug_dir_root, debug_bundle_id)
+            try:
+                os.makedirs(bundle_dir, exist_ok=True)
+            except Exception as e:
+                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å debug bundle dir {bundle_dir}: {e}")
+            else:
+                print(f"[DEBUG_BUNDLE] {bundle_dir}")
+
+        # –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã–∑–æ–≤ –ø–∞—Ä—Å–µ—Ä–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç Playwright Sync-in-async –∫—Ä–∞—à–∞
+        try:
+            card_data = parse_yandex_card(
+                url,
+                keep_open_on_captcha=True,
+                session_registry=ACTIVE_CAPTCHA_SESSIONS,
+                cookies=cookies,
+                user_agent=(
+                    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
+                    "AppleWebKit/537.36 (KHTML, like Gecko) "
+                    "Chrome/120.0.0.0 Safari/537.36"
+                ),
+                viewport={"width": 1920, "height": 1080},
+                locale="ru-RU",
+                timezone_id="Europe/Moscow",
+                headless=True,
+                debug_bundle_id=debug_bundle_id,
+            )
+        except Exception as e:
+            msg = str(e)
+            if "Playwright Sync API inside the asyncio loop" in msg:
+                # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–µ–π—Å: –∫—Ä—ç—à Playwright Sync –≤–Ω—É—Ç—Ä–∏ asyncio loop.
+                # –ü–∏—à–µ–º exception.txt –≤ bundle (–µ—Å–ª–∏ –º–æ–∂–Ω–æ) –∏ –ø–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ error.
+                bundle_path = None
+                try:
+                    if bundle_dir:
+                        os.makedirs(bundle_dir, exist_ok=True)
+                        bundle_path = bundle_dir
+                        exc_path = os.path.join(bundle_dir, "exception.txt")
+                        with open(exc_path, "w", encoding="utf-8") as f:
+                            f.write("Playwright Sync-in-async crash\n\n")
+                            f.write(repr(e) + "\n\n")
+                            f.write(traceback.format_exc())
+                except Exception as we:
+                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å exception.txt: {we}")
+
+                err_msg = f"playwright_sync_in_async_loop exc={type(e).__name__}"
+                if bundle_path:
+                    err_msg = f"{err_msg} bundle={bundle_path}"
+
+                try:
+                    conn = get_db_connection()
+                    cursor = conn.cursor()
+                    cursor.execute(
+                        """
+                        UPDATE parsequeue
+                        SET status = %s,
+                            error_message = %s,
+                            updated_at = CURRENT_TIMESTAMP
+                        WHERE id = %s
+                        """,
+                        (STATUS_ERROR, err_msg, queue_dict["id"]),
+                    )
+                    conn.commit()
+                    cursor.close()
+                    conn.close()
+                except Exception as db_ex:
+                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å parsequeue –¥–ª—è playwright-sync –æ—à–∏–±–∫–∏: {db_ex}")
+                return
+            # –õ—é–±–∞—è –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ ‚Äî –ø—É—Å—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ–±—â–µ–π –ª–æ–≥–∏–∫–æ–π –Ω–∏–∂–µ
+            raise
+        
+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ (–≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –ø–æ –¥–∞–Ω–Ω—ã–º –Ø–Ω–¥–µ–∫—Å–∞, –±–µ–∑ fallback –∏–∑ –ë–î)
+        is_successful, reason, validation_result = _validate_parsing_result(card_data)
+
+        # –õ–æ–≥ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–µ–π (coverage), –µ—Å–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç—Ä–∞–±–æ—Ç–∞–ª–∞
+        if validation_result:
+            found_fields = validation_result.get("found_fields", []) or []
+            missing_fields = validation_result.get("missing_fields", []) or []
+            hard_missing = validation_result.get("hard_missing", []) or []
+            quality_score = validation_result.get("quality_score", 0.0)
+            print(
+                f"üìä Parsing coverage: found={len(found_fields)} "
+                f"missing={len(missing_fields)} hard_missing={hard_missing} "
+                f"quality={quality_score}"
+            )
+
+            # –°–æ–±–∏—Ä–∞–µ–º _meta –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫ card_data –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ cards
+            meta = build_parsing_meta(card_data, validation_result, source=SOURCE_YANDEX_BUSINESS)
+            card_data["_meta"] = meta
         
         fallback_created = False
         if not is_successful and business_id:
@@ -656,7 +759,7 @@ def process_queue():
                 try:
                     cursor.execute(
                         "UPDATE parsequeue SET status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
-                        ("done", queue_dict["id"]),
+                        (STATUS_COMPLETED, queue_dict["id"]),
                     )
                     cursor.execute("DELETE FROM parsequeue WHERE id = %s", (queue_dict["id"],))
                     conn.commit()
@@ -673,19 +776,20 @@ def process_queue():
                 now_iso = datetime.now().isoformat()
                 cursor.execute(
                     """
-                    UPDATE ParseQueue
-                    SET status = 'captcha',
-                        retry_after = ?,
+                    UPDATE parsequeue
+                    SET status = %s,
+                        retry_after = %s,
                         captcha_required = 1,
-                        captcha_url = ?,
-                        captcha_session_id = ?,
-                        captcha_started_at = ?,
+                        captcha_url = %s,
+                        captcha_session_id = %s,
+                        captcha_started_at = %s,
                         captcha_status = 'waiting',
                         resume_requested = 0,
                         updated_at = CURRENT_TIMESTAMP
-                    WHERE id = ?
+                    WHERE id = %s
                     """,
                     (
+                        STATUS_CAPTCHA,
                         retry_after.isoformat(),
                         card_data.get("captcha_url") or queue_dict.get("url"),
                         captcha_session_id,
@@ -698,23 +802,30 @@ def process_queue():
                 cursor.close()
                 conn.close()
             return
-        
+
         # –®–ê–ì 3: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–æ—Ç–∫—Ä—ã–≤–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)
         if not is_successful and card_data.get("error") != "captcha_detected":
             print(f"‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ—É—Å–ø–µ—à–µ–Ω: {reason}. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
-            
-            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –Ω–∞ error
+
+            # –ë–∞–∑–æ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞
+            err_msg = str(reason)
+
+            # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ debug bundle, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω
+            debug_dir = os.getenv("DEBUG_DIR", "/app/debug_data").rstrip("/")
+            if debug_bundle_id:
+                bundle_path = f"{debug_dir}/{debug_bundle_id}"
+                err_msg = f"{err_msg} bundle={bundle_path}"
             conn = get_db_connection()
             cursor = conn.cursor()
             cursor.execute(
                 """
                 UPDATE parsequeue
-                SET status = 'error',
+                SET status = %s,
                     error_message = %s,
                     updated_at = CURRENT_TIMESTAMP
                 WHERE id = %s
                 """,
-                (f"Parsing failed: {reason}", queue_dict["id"]),
+                (STATUS_ERROR, err_msg, queue_dict["id"]),
             )
             conn.commit()
             cursor.close()
@@ -727,37 +838,27 @@ def process_queue():
         
         try:
             if business_id:
-                # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ MapParseResults
-                print(f"üìä –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ MapParseResults –¥–ª—è business_id={business_id}")
+                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ cards (Postgres source of truth)
+                print(f"üìä –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ cards –¥–ª—è business_id={business_id}")
                 
                 try:
-                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º GigaChat –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –∫–∞–∫ –∏ –≤ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
                     from gigachat_analyzer import analyze_business_data
                     from report import generate_html_report
                     
                     print(f"ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º GigaChat –∞–Ω–∞–ª–∏–∑ –¥–ª—è {business_id}...")
                     analysis_result = analyze_business_data(card_data)
                     
-                    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á–µ—Ç–∞
                     analysis_data = {
                         'score': analysis_result.get('score', 50),
                         'recommendations': analysis_result.get('recommendations', []),
                         'ai_analysis': analysis_result.get('analysis', {})
                     }
                     
-                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
                     report_path = generate_html_report(card_data, analysis_data, {})
                     print(f"üìÑ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {report_path}")
                     
-                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö (JSON)
-                    analysis_json = json.dumps(analysis_data['ai_analysis'], ensure_ascii=False)
-                    
                     rating = card_data.get('overview', {}).get('rating', '') or ''
                     reviews_count = card_data.get('reviews_count') or card_data.get('overview', {}).get('reviews_count') or 0
-                    news_count = len(card_data.get('news') or [])
-                    photos_count = card_data.get('photos_count') or 0
-                    
-                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
                     reviews = card_data.get('reviews', [])
                     if isinstance(reviews, dict) and 'items' in reviews:
                         reviews_list = reviews['items']
@@ -766,149 +867,129 @@ def process_queue():
                     else:
                         reviews_list = []
                     
-                    unanswered_reviews_count = sum(1 for r in reviews_list if not r.get('org_reply') or r.get('org_reply', '').strip() == '' or r.get('org_reply', '').strip() == '‚Äî')
-                    
-                    # Sync reviews_count with parsed count if parsed is higher (fixing UI inconsistency)
                     parsed_reviews_count = len(reviews_list)
-                    if parsed_reviews_count > int(reviews_count):
-                        print(f"‚ö†Ô∏è Parsed more reviews ({parsed_reviews_count}) than header count ({reviews_count}). Updating count.")
+                    if parsed_reviews_count > int(reviews_count or 0):
                         reviews_count = parsed_reviews_count
-
-                    url_lower = (queue_dict["url"] or '').lower()
-                    map_type = 'yandex' if 'yandex' in url_lower else ('google' if 'google' in url_lower else 'other')
-                    
-                    parse_result_id = str(uuid.uuid4())
-                    
-                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ unanswered_reviews_count —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
-                    if DB_TYPE != "postgres":
-                        _ensure_column_exists(cursor, conn, "MapParseResults", "unanswered_reviews_count", "INTEGER")
                     
-                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–æ—Ñ–∞–π–ª–∞ –±–∏–∑–Ω–µ—Å–∞ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
-                    profile_columns = [
-                        ("is_verified", "INTEGER DEFAULT 0"),
-                        ("phone", "TEXT"),
-                        ("website", "TEXT"),
-                        ("messengers", "TEXT"),  # JSON
-                        ("working_hours", "TEXT"),  # JSON
-                        ("competitors", "TEXT"),    # JSON
-                        ("services_count", "INTEGER DEFAULT 0"),
-                        ("profile_completeness", "INTEGER DEFAULT 0"),
-                    ]
-                    if DB_TYPE != "postgres":
-                        for col_name, col_type in profile_columns:
-                            _ensure_column_exists(cursor, conn, "MapParseResults", col_name, col_type)
+                    try:
+                        reviews_count = int(reviews_count or 0)
+                    except (ValueError, TypeError):
+                        reviews_count = 0
+                    photos_count = card_data.get('photos_count') or 0
+                    try:
+                        photos_count = int(photos_count)
+                    except (ValueError, TypeError):
+                        photos_count = 0
                     
-                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∞–π–ª–∞ –∏–∑ card_data
                     phone = card_data.get('phone', '') or ''
                     website = card_data.get('site', '') or card_data.get('website', '') or ''
-                    
-                    # Messengers (—Å–æ–±–∏—Ä–∞–µ–º –∏–∑ social_links)
-                    messengers = []
-                    social_links = card_data.get('social_links', [])
-                    for link in social_links:
-                        link_lower = link.lower()
-                        if 'whatsapp' in link_lower or 'wa.me' in link_lower:
-                            messengers.append({'type': 'whatsapp', 'url': link})
-                        elif 't.me' in link_lower or 'telegram' in link_lower:
-                            messengers.append({'type': 'telegram', 'url': link})
-                        elif 'viber' in link_lower:
-                            messengers.append({'type': 'viber', 'url': link})
-                    messengers_json = json.dumps(messengers, ensure_ascii=False) if messengers else None
-                    
-                    # Working hours (–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON)
                     hours_full = card_data.get('hours_full', [])
-                    hours_json = json.dumps({'schedule': hours_full}, ensure_ascii=False) if hours_full else None
-                    
-                    # Competitors
+                    hours_struct = {'schedule': hours_full} if hours_full else None
                     competitors = card_data.get('competitors', [])
-                    competitors_json = json.dumps(competitors, ensure_ascii=False) if competitors else None
-                    
-                    # Services count
                     products = card_data.get('products', [])
-                    services_count = sum(len(cat.get('items', [])) for cat in products)
+                    news_list = card_data.get('news') or []
                     
-                    # Ensure numeric values are integers
-                    try:
-                        photos_count = int(photos_count)
-                    except (ValueError, TypeError):
-                        photos_count = 0
-                        
-                    try:
-                        reviews_count = int(reviews_count)
-                    except (ValueError, TypeError):
-                        reviews_count = 0
-                        
-                    try:
-                        news_count = int(news_count)
-                    except (ValueError, TypeError):
-                        news_count = 0
-                    
-                    # Verification badge
-                    is_verified = 1 if card_data.get('is_verified') else 0
+                    rating_float = None
+                    if rating not in (None, ''):
+                        try:
+                            rating_float = float(rating)
+                        except (ValueError, TypeError):
+                            pass
                     
-                    # Profile completeness calculation (Service Call)
+                    # –ì–æ—Ç–æ–≤–∏–º overview —Å –º–µ—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥–∞
+                    overview_payload = {
+                        'photos_count': photos_count,
+                        'news_count': len(news_list),
+                        'snapshot_type': 'full',
+                    }
+                    if card_data.get("_meta"):
+                        overview_payload["_meta"] = card_data["_meta"]
+
+                    db_manager = DatabaseManager()
+                    services_saved_count = 0
                     try:
-                        from services.analytics_service import calculate_profile_completeness
-                        
-                        # Prepare data for analysis
-                        analysis_data = {
-                            'phone': phone,
-                            'website': website,
-                            'schedule': hours_json,
-                            'photos_count': photos_count,
-                            'services_count': services_count,
-                            'description': card_data.get('description'),
-                            'messengers': messengers,
-                            'is_verified': is_verified
-                        }
-                        
-                        profile_completeness = calculate_profile_completeness(analysis_data)
-                        print(f"   üìä –†–∞—Å—á–µ—Ç completed service: {profile_completeness}%")
-                        
-                    except ImportError:
-                         print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å services.analytics_service")
-                         profile_completeness = 0
-                    except Exception as comp_err:
-                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–æ—Ñ–∏–ª—è (worker): {comp_err}")
-                        profile_completeness = 0
-                    
-                    # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ (–æ–Ω–∏ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç)
-                    cursor.execute("""
-                        INSERT INTO MapParseResults
-                        (id, business_id, url, map_type, rating, reviews_count, unanswered_reviews_count, 
-                         news_count, photos_count, report_path, 
-                         is_verified, phone, website, messengers, working_hours, competitors, services_count, profile_completeness,
-                         title, address,
-                         created_at)
-                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
-                    """, (
-                        parse_result_id,
-                        business_id,
-                        queue_dict["url"],
-                        map_type,
-                        str(rating),
-                        int(reviews_count or 0),
-                        int(unanswered_reviews_count),
-                        int(news_count or 0),
-                        int(photos_count or 0),
-                        report_path,
-                        is_verified,
-                        phone,
-                        website,
-                        messengers_json,
-                        hours_json,
-                        competitors_json,
-                        services_count,
-                        profile_completeness,
-                        card_data.get('name') or card_data.get('title', ''),
-                        card_data.get('address', '')
-                    ))
-                    
-                    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ MapParseResults: {parse_result_id}")
-                    print(f"   üìä –ü—Ä–æ—Ñ–∞–π–ª: —Ç–µ–ª–µ—Ñ–æ–Ω={bool(phone)}, —Å–∞–π—Ç={bool(website)}, —á–∞—Å—ã={bool(hours_json)}, —É—Å–ª—É–≥={services_count}, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å={profile_completeness}%")
-                    
-                    # Commit main connection to release write lock for DatabaseManager
-                    conn.commit()
+                        db_manager.save_new_card_version(
+                            business_id,
+                            url=queue_dict["url"],
+                            title=(card_data.get('name') or card_data.get('title') or ''),
+                            address=(card_data.get('address') or ''),
+                            phone=phone or None,
+                            site=website or None,
+                            rating=rating_float,
+                            reviews_count=reviews_count,
+                            overview=overview_payload,
+                            products=products or None,
+                            news=news_list or None,
+                            competitors=competitors or None,
+                            hours=hours_struct,
+                            hours_full=hours_full or None,
+                            report_path=report_path,
+                            ai_analysis=analysis_data.get('ai_analysis'),
+                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –∫–∞–∫ [] (–∞ –Ω–µ NULL), —á—Ç–æ–±—ã –æ—Ç–ª–∏—á–∞—Ç—å
+                            # "–Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π" –æ—Ç "–ø–æ–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
+                            recommendations=analysis_data.get('recommendations', []),
+                        )
+
+                        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è –≤ businesses (rich model)
+                        try:
+                            sync_payload = {
+                                "address": card_data.get("address"),
+                                "phone": phone or None,
+                                "site": website or None,
+                                "rating": rating_float,
+                                "reviews_count": reviews_count,
+                                "categories": card_data.get("categories"),
+                                "hours": hours_struct,
+                                "hours_full": hours_full or None,
+                                "description": card_data.get("description") or (card_data.get("overview") or {}).get("description"),
+                                "industry": card_data.get("industry"),
+                                "geo": card_data.get("geo"),
+                                "external_ids": card_data.get("external_ids"),
+                            }
+                            db_manager.update_business_from_card(business_id, sync_payload)
+                            # –£—Å–ª—É–≥–∏ –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏ ‚Üí userservices (–¥–ª—è –≤–∫–ª–∞–¥–∫–∏ ¬´–£—Å–ª—É–≥–∏ –∏ —Ü–µ–Ω—ã¬ª)
+                            owner_id = (db_manager.get_business_by_id(business_id) or {}).get("owner_id")
+                            if owner_id and (card_data.get("products") or card_data.get("services")):
+                                try:
+                                    service_rows = map_card_services(card_data, business_id, owner_id)
+                                    if service_rows:
+                                        services_saved_count = db_manager.upsert_parsed_services(business_id, owner_id, service_rows)
+                                        print(f"Saved services={services_saved_count} for business_id={business_id}")
+                                except Exception as svc_e:
+                                    print(f"‚ö†Ô∏è upsert_parsed_services failed for {business_id}: {svc_e}")
+                        except Exception as sync_e:
+                            print(f"‚ö†Ô∏è Failed to update businesses from card for {business_id}: {sync_e}")
+
+                    except Exception as e:
+                        # –ü–æ–º–µ—á–∞–µ–º –∑–∞–¥–∞—á—É –∫–∞–∫ –æ—à–∏–±–æ—á–Ω—É—é, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–∞–ª–∞ –≤ processing
+                        err_text = f"save_failed:{e.__class__.__name__}:{e}"
+                        _handle_worker_error(queue_dict["id"], err_text)
+                        db_manager.close()
+                        raise
+                    else:
+                        db_manager.close()
+
+                    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –ª–æ–≥: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤
+                    title_snippet = (card_data.get('name') or card_data.get('title') or '')[:80]
+                    _products = card_data.get("products") or []
+                    _news = card_data.get("news") or []
+                    _photos = card_data.get("photos") or []
+                    if isinstance(_photos, int):
+                        _photos = []
+                    _competitors = card_data.get("competitors") or []
+                    _hours_full = card_data.get("hours_full") or []
+                    print(
+                        f"[PARSE_DIAG] business_id={business_id} queue_id={queue_dict.get('id')} "
+                        f"title={title_snippet!r} address_present={bool(card_data.get('address'))} "
+                        f"rating={rating_float} reviews_count={reviews_count} "
+                        f"products_len={len(_products) if isinstance(_products, list) else 0} "
+                        f"news_len={len(_news) if isinstance(_news, list) else 0} "
+                        f"photos_len={len(_photos) if isinstance(_photos, list) else 0} "
+                        f"competitors_len={len(_competitors) if isinstance(_competitors, list) else 0} "
+                        f"hours_full_len={len(_hours_full) if isinstance(_hours_full, list) else 0} "
+                        f"services_saved_count={services_saved_count}"
+                    )
+                    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ cards –¥–ª—è business_id={business_id}")
                     
                     # --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø SyncWorker –î–õ–Ø –°–û–•–†–ê–ù–ï–ù–ò–Ø –î–ï–¢–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• ---
                     try:
@@ -1046,9 +1127,10 @@ def process_queue():
                             if products:
                                 services_count = len(products)
                                 # Fetch owner_id for service syncing
-                                owner_row = cursor.execute("SELECT owner_id FROM Businesses WHERE id=?", (business_id,)).fetchone()
+                                cursor.execute("SELECT owner_id FROM businesses WHERE id = %s", (business_id,))
+                                owner_row = cursor.fetchone()
                                 if owner_row:
-                                    owner_id = owner_row[0]
+                                    owner_id = owner_row[0] if isinstance(owner_row, (list, tuple)) else owner_row.get("owner_id")
                                     sync_worker._sync_services_to_db(db_manager.conn, business_id, products, owner_id)
                                     print(f"üíæ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {services_count} —É—Å–ª—É–≥ (owner_id={owner_id})")
                                 else:
@@ -1093,7 +1175,7 @@ def process_queue():
                         traceback.print_exc()
 
                 except Exception as e:
-                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ MapParseResults: {e}")
+                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ cards: {e}")
                     import traceback
                     traceback.print_exc()
                     try:
@@ -1129,12 +1211,12 @@ def process_queue():
                         reviews_count = None
                 
                 cursor.execute("""
-                    INSERT INTO Cards (
-                        id, user_id, url, title, address, phone, site, rating, 
-                        reviews_count, categories, overview, products, news, 
+                    INSERT INTO cards (
+                        id, user_id, url, title, address, phone, site, rating,
+                        reviews_count, categories, overview, products, news,
                         photos, features_full, competitors, hours, hours_full,
                         created_at
-                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
+                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                 """, (
                     card_id,
                     queue_dict["user_id"],
@@ -1145,15 +1227,21 @@ def process_queue():
                     card_data.get("site"),
                     rating,
                     reviews_count,
-                    str(card_data.get("categories", [])),
-                    str(card_data.get("overview", {})),
-                    str(card_data.get("products", [])),
-                    str(card_data.get("news", [])),
-                    str(card_data.get("photos", [])),
-                    str(card_data.get("features_full", {})),
-                    str(card_data.get("competitors", [])),
+                    json.dumps(card_data.get("categories", [])),
+                    json.dumps(
+                        {
+                            **(card_data.get("overview") or {}),
+                            **({"_meta": card_data["_meta"]} if card_data.get("_meta") else {}),
+                        },
+                        ensure_ascii=False,
+                    ),
+                    json.dumps(card_data.get("products", [])),
+                    json.dumps(card_data.get("news", [])),
+                    json.dumps(card_data.get("photos", [])),
+                    json.dumps(card_data.get("features_full", {})),
+                    json.dumps(card_data.get("competitors", [])),
                     card_data.get("hours"),
-                    str(card_data.get("hours_full", [])),
+                    json.dumps(card_data.get("hours_full", [])),
                     datetime.now().isoformat()
                 ))
                 
@@ -1167,15 +1255,15 @@ def process_queue():
                     analysis_result = analyze_business_data(card_data)
                     
                     cursor.execute("""
-                        UPDATE Cards SET 
-                            ai_analysis = ?, 
-                            seo_score = ?, 
-                            recommendations = ?
-                        WHERE id = ?
+                        UPDATE cards SET
+                            ai_analysis = %s,
+                            seo_score = %s,
+                            recommendations = %s
+                        WHERE id = %s
                     """, (
-                        str(analysis_result.get('analysis', {})),
+                        json.dumps(analysis_result.get('analysis', {})),
                         analysis_result.get('score', 50),
-                        str(analysis_result.get('recommendations', [])),
+                        json.dumps(analysis_result.get('recommendations', [])),
                         card_id
                     ))
                     
@@ -1190,7 +1278,7 @@ def process_queue():
                         }
                         report_path = generate_html_report(card_data, analysis_data)
                         print(f"HTML –æ—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {report_path}")
-                        cursor.execute("UPDATE Cards SET report_path = ? WHERE id = ?", (report_path, card_id))
+                        cursor.execute("UPDATE cards SET report_path = %s WHERE id = %s", (report_path, card_id))
                     except Exception as report_error:
                         print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞ –¥–ª—è –∫–∞—Ä—Ç–æ—á–∫–∏ {card_id}: {report_error}")
                         
@@ -1202,9 +1290,10 @@ def process_queue():
                 try:
                     # Need owner_id for sync
                     cursor = conn.cursor() # Ensure we have cursor
-                    owner_row = cursor.execute("SELECT owner_id FROM Businesses WHERE id=?", (business_id,)).fetchone()
+                    cursor.execute("SELECT owner_id FROM businesses WHERE id = %s", (business_id,))
+                    owner_row = cursor.fetchone()
                     if owner_row:
-                        owner_id = owner_row[0]
+                        owner_id = owner_row[0] if isinstance(owner_row, (list, tuple)) else owner_row.get("owner_id")
                         print(f"üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É—Å–ª—É–≥ –¥–ª—è business_id={business_id} (owner_id={owner_id})...")
                         _sync_parsed_services_to_db(business_id, card_data.get('products'), conn, owner_id)
                         print(f"‚úÖ –£—Å–ª—É–≥–∏ —É—Å–ø–µ—à–Ω–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
@@ -1216,16 +1305,37 @@ def process_queue():
                     traceback.print_exc()
             
             # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "completed" (—á—Ç–æ–±—ã –∑–∞–¥–∞—á–∞ –æ—Å—Ç–∞–ª–∞—Å—å –≤ —Å–ø–∏—Å–∫–µ)
-            warning_msg = None
+            warning_parts = []
+            # –°—Ç–∞—Ä–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–æ HTML fallback (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç)
             if card_data.get('fallback_used'):
-                warning_msg = "‚ö†Ô∏è Fast Endpoint Outdated (Used HTML Fallback)"
-                
-            if warning_msg:
-                 cursor.execute("UPDATE ParseQueue SET status = ?, error_message = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?", ("completed", warning_msg, queue_dict["id"]))
-            else:
-                 cursor.execute("UPDATE ParseQueue SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?", ("completed", queue_dict["id"]))
-            
-            # cursor.execute("DELETE FROM ParseQueue WHERE id = ?", (queue_dict["id"],)) -> –£–¥–∞–ª–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –ø–æ –ø—Ä–æ—Å—å–±–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
+                warning_parts.append("‚ö†Ô∏è Fast Endpoint Outdated (Used HTML Fallback)")
+
+            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º CRITICAL-–ø–æ–ª—è–º –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
+            if validation_result:
+                missing_fields = set(validation_result.get("missing_fields", []) or [])
+                critical_missing = [f for f in FIELDS_CRITICAL if f in missing_fields]
+                if critical_missing:
+                    warning_parts.append(
+                        "warnings_missing_in_source:" + ",".join(critical_missing)
+                    )
+
+            warning_msg = " | ".join(warning_parts) if warning_parts else None
+
+            # –û–±–Ω–æ–≤–ª—è–µ–º completed: error_message = NULL, warnings ‚Äî —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º fallback –ø—Ä–∏ UndefinedColumn
+            try:
+                cursor.execute(
+                    "UPDATE parsequeue SET status = %s, error_message = NULL, warnings = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
+                    (STATUS_COMPLETED, warning_msg, queue_dict["id"]),
+                )
+            except Exception as upd_err:
+                # Fallback —Ç–æ–ª—å–∫–æ –¥–ª—è PostgreSQL UndefinedColumn (pgcode 42703).
+                if getattr(upd_err, "pgcode", None) == "42703":
+                    cursor.execute(
+                        "UPDATE parsequeue SET status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
+                        (STATUS_COMPLETED, queue_dict["id"]),
+                    )
+                else:
+                    raise
             conn.commit()
             
             print(f"‚úÖ –ó–∞—è–≤–∫–∞ {queue_dict['id']} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∏ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.")
@@ -1254,8 +1364,8 @@ def process_queue():
         conn = get_db_connection()
         cursor = conn.cursor()
         try:
-            cursor.execute("UPDATE ParseQueue SET status = ?, error_message = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?", 
-                         ("error", str(e), queue_id))
+            cursor.execute("UPDATE parsequeue SET status = %s, error_message = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
+                         (STATUS_ERROR, str(e), queue_id))
             conn.commit()
             print(f"‚ö†Ô∏è –ó–∞—è–≤–∫–∞ {queue_id} –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ –æ—à–∏–±–∫–∞.")
         except Exception as update_error:
@@ -1275,6 +1385,76 @@ def process_queue():
         except Exception as email_error:
             print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å email: {email_error}")
 
+def map_card_services(card_data: Dict[str, Any], business_id: str, user_id: str) -> List[Dict[str, Any]]:
+    """
+    –ß–∏—Å—Ç—ã–π –º–∞–ø–ø–µ—Ä: –∏–∑ card_data (products/services) –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è userservices.
+    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É: —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å items –∏–ª–∏ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
+    """
+    products = card_data.get("products") or card_data.get("services") or []
+    if not isinstance(products, list):
+        return []
+    rows = []
+    source = "yandex_maps"
+    # –§–æ—Ä–º–∞—Ç: [{"category": "‚Ä¶", "items": [{"name", "price", "description", "id", ...}]}] –∏–ª–∏ –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
+    for cat_block in products:
+        if not isinstance(cat_block, dict):
+            if isinstance(cat_block, (str, int, float)):
+                continue
+            if isinstance(cat_block, list):
+                for item in cat_block:
+                    if isinstance(item, dict) and item.get("name"):
+                        row = _one_service_row(item, business_id, user_id, source)
+                        if row:
+                            rows.append(row)
+            continue
+        category_name = (cat_block.get("category") or "–†–∞–∑–Ω–æ–µ").strip() or "–†–∞–∑–Ω–æ–µ"
+        items = cat_block.get("items") or cat_block.get("products") or []
+        if not isinstance(items, list):
+            continue
+        for item in items:
+            if not isinstance(item, dict) or not item.get("name"):
+                continue
+            row = _one_service_row(item, business_id, user_id, source)
+            if row:
+                row["category"] = category_name
+                rows.append(row)
+    return rows
+
+
+def _one_service_row(item: Dict[str, Any], business_id: str, user_id: str, source: str) -> Dict[str, Any]:
+    """–û–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç —É—Å–ª—É–≥–∏ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ –¥–ª—è userservices."""
+    name = (item.get("name") or "").strip() or None
+    if not name:
+        return {}
+    external_id = item.get("id") or item.get("external_id")
+    if external_id is not None:
+        external_id = str(external_id).strip() or None
+    raw_price = item.get("price") or item.get("price_from") or ""
+    price_from = price_to = None
+    if raw_price is not None and str(raw_price).strip():
+        try:
+            digits = re.sub(r"[^0-9.,]", "", str(raw_price))
+            digits = digits.replace(",", ".")
+            if digits:
+                price_from = float(digits)
+                price_to = price_from
+        except (ValueError, TypeError):
+            pass
+    return {
+        "business_id": business_id,
+        "user_id": user_id,
+        "name": name,
+        "description": (item.get("description") or "").strip() or None,
+        "category": (item.get("category") or "–†–∞–∑–Ω–æ–µ").strip() or "–†–∞–∑–Ω–æ–µ",
+        "source": source,
+        "external_id": external_id,
+        "price_from": price_from,
+        "price_to": price_to,
+        "raw": item,
+        "duration_minutes": item.get("duration_minutes") or item.get("duration"),
+    }
+
+
 def _sync_parsed_services_to_db(business_id: str, products: list, conn, owner_id: str):
     """
     –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∞—Ä—à–µ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ –≤ —Ç–∞–±–ª–∏—Ü—É UserServices.
@@ -1316,7 +1496,7 @@ def _sync_parsed_services_to_db(business_id: str, products: list, conn, owner_id
                 created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                 updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                 user_id TEXT,
-                FOREIGN KEY (business_id) REFERENCES Businesses(id) ON DELETE CASCADE
+                FOREIGN KEY (business_id) REFERENCES businesses(id) ON DELETE CASCADE
             )
         """
         )
@@ -1357,34 +1537,31 @@ def _sync_parsed_services_to_db(business_id: str, products: list, conn, owner_id
             # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —É—Å–ª—É–≥—É –ø–æ –∏–º–µ–Ω–∏ –∏ business_id
             cursor.execute(
                 """
-                SELECT id FROM UserServices 
-                WHERE business_id = ? AND name = ?
-            """,
+                SELECT id FROM userservices
+                WHERE business_id = %s AND name = %s
+                """,
                 (business_id, name),
             )
-            
             row = cursor.fetchone()
-            
-            if row:
-                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é
-                service_id = row[0]
+            service_id = (row[0] if isinstance(row, (list, tuple)) else row.get("id")) if row else None
+
+            if service_id:
                 cursor.execute(
                     """
-                    UPDATE UserServices 
-                    SET price = ?, description = ?, category = ?, updated_at = CURRENT_TIMESTAMP, is_active = 1
-                    WHERE id = ?
-                """,
+                    UPDATE userservices
+                    SET price = %s, description = %s, category = %s, updated_at = CURRENT_TIMESTAMP, is_active = TRUE
+                    WHERE id = %s
+                    """,
                     (price_cents, description, category_name, service_id),
                 )
                 count_updated += 1
             else:
-                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
                 service_id = str(uuid.uuid4())
                 cursor.execute(
                     """
-                    INSERT INTO UserServices (id, business_id, user_id, name, description, category, price, is_active)
-                    VALUES (?, ?, ?, ?, ?, ?, ?, 1)
-                """,
+                    INSERT INTO userservices (id, business_id, user_id, name, description, category, price, is_active)
+                    VALUES (%s, %s, %s, %s, %s, %s, %s, TRUE)
+                    """,
                     (service_id, business_id, owner_id, name, description, category_name, price_cents),
                 )
                 count_new += 1
@@ -1413,11 +1590,11 @@ def _process_sync_yandex_business_task(queue_dict):
             conn = get_db_connection()
             cursor = conn.cursor()
             cursor.execute("""
-                UPDATE ParseQueue 
-                SET status = 'error', 
-                    error_message = ?,
+                UPDATE parsequeue
+                SET status = 'error',
+                    error_message = %s,
                     updated_at = CURRENT_TIMESTAMP
-                WHERE id = ?
+                WHERE id = %s
             """, ("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç business_id –∏–ª–∏ account_id", queue_dict["id"]))
             conn.commit()
             cursor.close()
@@ -1442,16 +1619,18 @@ def _process_sync_yandex_business_task(queue_dict):
         
 
             cursor.execute("""
-                SELECT auth_data_encrypted, external_id 
-                FROM ExternalBusinessAccounts 
-                WHERE id = ? AND business_id = ?
+                SELECT auth_data_encrypted, external_id
+                FROM externalbusinessaccounts
+                WHERE id = %s AND business_id = %s
             """, (account_id, business_id))
             account_row = cursor.fetchone()
-            
             if not account_row:
                 raise Exception("–ê–∫–∫–∞—É–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
-            
-            auth_data_encrypted, external_id = account_row
+            if isinstance(account_row, (list, tuple)):
+                auth_data_encrypted, external_id = account_row[0], (account_row[1] if len(account_row) > 1 else None)
+            else:
+                auth_data_encrypted = account_row.get("auth_data_encrypted")
+                external_id = account_row.get("external_id")
             auth_data_plain = decrypt_auth_data(auth_data_encrypted)
             
             if not auth_data_plain:
@@ -1501,158 +1680,123 @@ def _process_sync_yandex_business_task(queue_dict):
                 worker._upsert_posts(db, posts)
                 print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø—É–±–ª–∏–∫–∞—Ü–∏–π: {len(posts)}")
             
-            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ MapParseResults (–µ—Å–ª–∏ –µ—Å—Ç—å)
-            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ unanswered_reviews_count
-            cursor.execute("PRAGMA table_info(MapParseResults)")
-            columns = [row[1] for row in cursor.fetchall()]
-            has_unanswered = 'unanswered_reviews_count' in columns
-            
-            if has_unanswered:
-                cursor.execute("""
-                    SELECT rating, reviews_count, unanswered_reviews_count, news_count, photos_count
-                    FROM MapParseResults
-                    WHERE business_id = ?
-                    ORDER BY created_at DESC
-                    LIMIT 1
-                """, (business_id,))
-            else:
-                cursor.execute("""
-                    SELECT rating, reviews_count, news_count, photos_count
-                    FROM MapParseResults
-                    WHERE business_id = ?
-                    ORDER BY created_at DESC
-                    LIMIT 1
-                """, (business_id,))
-            existing_data = cursor.fetchone()
-            
-            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞–±–∏–Ω–µ—Ç—É)
-            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–±–∏–Ω–µ—Ç–∞, –Ω–æ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –Ω—É–ª—è–º–∏
-            # –†–µ–π—Ç–∏–Ω–≥
-            rating = org_info.get('rating')
-            if not rating and existing_data and existing_data[0]:
-                rating = existing_data[0]
-            
-            # –û—Ç–∑—ã–≤—ã
-            current_reviews_count = len(reviews) if reviews else 0
-            if current_reviews_count == 0 and existing_data:
-                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω–¥–µ–∫—Å reviews_count –≤ existing_data
-                # –ó–∞–ø—Ä–æ—Å: rating (0), reviews_count (1), ...
-                if existing_data[1] and existing_data[1] > 0:
-                    reviews_count = existing_data[1]
+            # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ cards (Postgres source of truth)
+            cursor.execute("""
+                SELECT rating, reviews_count, overview
+                FROM cards
+                WHERE business_id = %s
+                ORDER BY created_at DESC
+                LIMIT 1
+            """, (business_id,))
+            existing_row = cursor.fetchone()
+            existing_data = None
+            if existing_row:
+                if isinstance(existing_row, (list, tuple)):
+                    existing_data = {'rating': existing_row[0], 'reviews_count': existing_row[1], 'overview': existing_row[2] if len(existing_row) > 2 else None}
                 else:
-                    reviews_count = 0
-            else:
-                reviews_count = current_reviews_count
+                    existing_data = dict(existing_row) if hasattr(existing_row, 'keys') else None
 
-            # –ù–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ
-            current_unanswered = sum(1 for r in reviews if not r.response_text) if reviews else 0
-            if current_reviews_count == 0 and existing_data and has_unanswered:
-                # rating(0), reviews(1), unanswered(2)
-                if existing_data[2] is not None:
-                     reviews_without_response = existing_data[2]
-                else:
-                     reviews_without_response = 0
+            current_reviews_count = len(reviews) if reviews else 0
+            rating = org_info.get('rating')
+            if not rating and existing_data and existing_data.get('rating') is not None:
+                rating = existing_data['rating']
+            if current_reviews_count == 0 and existing_data and (existing_data.get('reviews_count') or 0) > 0:
+                reviews_count = existing_data['reviews_count']
             else:
-                reviews_without_response = current_unanswered
-                
-            # –ù–æ–≤–æ—Å—Ç–∏ (posts)
+                reviews_count = current_reviews_count
+            reviews_without_response = sum(1 for r in reviews if not getattr(r, 'response_text', None)) if reviews else 0
             current_news = len(posts) if posts else 0
-            if current_news == 0 and existing_data:
-                # –ò–Ω–¥–µ–∫—Å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç has_unanswered
-                idx = 3 if has_unanswered else 2
-                if existing_data[idx] and existing_data[idx] > 0:
-                    news_count = existing_data[idx]
-                else:
-                    news_count = 0
-            else:
-                 news_count = current_news
-                 
-            # –§–æ—Ç–æ
+            news_count = current_news
             current_photos = org_info.get('photos_count', 0) if org_info else 0
-            if current_photos == 0 and existing_data:
-                idx = 4 if has_unanswered else 3
-                if existing_data[idx] and existing_data[idx] > 0:
-                     photos_count = existing_data[idx]
-                else:
-                     photos_count = 0
-            else:
-                photos_count = current_photos
-            
-            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ MapParseResults
-            parse_id = str(uuid.uuid4())
+            photos_count = current_photos
+
+            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–µ–∑ –≤ cards, –Ω–µ –∑–∞—Ç–∏—Ä–∞—è rich-–ø–æ–ª—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∫–∞—Ä—Ç–æ—á–∫–∏.
             url = f"https://yandex.ru/sprav/{external_id or 'unknown'}"
-            
-            if has_unanswered:
-                cursor.execute("""
-                    INSERT INTO MapParseResults (
-                        id, business_id, url, map_type, rating, reviews_count, 
-                        unanswered_reviews_count, news_count, photos_count, 
-                        created_at
+            overview_payload = {
+                "photos_count": photos_count,
+                "news_count": news_count,
+                "snapshot_type": "metrics_update",
+            }
+            try:
+                # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∫–∞—Ä—Ç–æ—á–∫—É, —á—Ç–æ–±—ã —É–Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å products/news/photos/...,
+                # –∏–Ω–∞—á–µ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –±—É–¥–µ—Ç –ø—É—Å—Ç–æ–π.
+                existing_card = db.get_latest_card_by_business(business_id)
+                inherit_fields = {}
+                if existing_card:
+                    for key in (
+                        "products",
+                        "news",
+                        "photos",
+                        "features_full",
+                        "competitors",
+                        "hours",
+                        "hours_full",
+                        "categories",
+                        "description",
+                        "industry",
+                        "geo",
+                        "external_ids",
+                    ):
+                        if key in existing_card and existing_card[key] is not None:
+                            inherit_fields[key] = existing_card[key]
+
+                # Safeguard: –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–µ—Ç –Ω–∏ rich-–ø–æ–ª–µ–π, –Ω–∏ –º–µ—Ç—Ä–∏–∫ ‚Äî –Ω–µ –ø–ª–æ–¥–∏–º –ø—É—Å—Ç—ã–µ –≤–µ—Ä—Å–∏–∏.
+                has_rich = bool(inherit_fields)
+                has_metrics = (
+                    rating is not None
+                    or (reviews_count not in (None, 0))
+                    or (photos_count not in (None, 0))
+                    or (news_count not in (None, 0))
+                )
+
+                if has_rich or has_metrics:
+                    db.save_new_card_version(
+                        business_id,
+                        url=url,
+                        rating=float(rating) if rating is not None else None,
+                        reviews_count=int(reviews_count or 0),
+                        overview=overview_payload,
+                        **inherit_fields,
                     )
-                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
-                """, (
-                    parse_id,
-                    business_id,
-                    url,
-                    'yandex',
-                    rating,
-                    reviews_count,
-                    reviews_without_response,
-                    news_count,
-                    photos_count,
-                ))
-            else:
-                cursor.execute("""
-                    INSERT INTO MapParseResults (
-                        id, business_id, url, map_type, rating, reviews_count, 
-                        news_count, photos_count, created_at
+                else:
+                    # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ worker, –Ω–æ —è–≤–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Å–∏—Ç—É–∞—Ü–∏—é –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏.
+                    print(
+                        f"[CARDS_SYNC] Skip creating new card version for business_id={business_id}: "
+                        f"no rich fields and no metrics"
                     )
-                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
-                """, (
-                    parse_id,
-                    business_id,
-                    url,
-                    'yandex',
-                    rating,
-                    reviews_count,
-                    news_count,
-                    photos_count,
-                ))
-            
-            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
+            except Exception as card_err:
+                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ cards (sync): {card_err}")
+
             try:
                 metric_history_id = str(uuid.uuid4())
                 current_date = datetime.now().strftime('%Y-%m-%d')
-                
-                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∑–∞–ø–∏—Å—å –∑–∞ —Å–µ–≥–æ–¥–Ω—è –æ—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
                 cursor.execute("""
-                    SELECT id FROM BusinessMetricsHistory 
-                    WHERE business_id = ? AND metric_date = ? AND source = 'parsing'
+                    SELECT id FROM businessmetricshistory
+                    WHERE business_id = %s AND metric_date = %s AND source = 'parsing'
                 """, (business_id, current_date))
-                
                 existing_metric = cursor.fetchone()
-                
-                if existing_metric:
+                mid = existing_metric[0] if isinstance(existing_metric, (list, tuple)) else (existing_metric.get("id") if existing_metric else None)
+                if mid:
                     cursor.execute("""
-                        UPDATE BusinessMetricsHistory 
-                        SET rating = ?, reviews_count = ?, photos_count = ?, news_count = ?
-                        WHERE id = ?
-                    """, (rating, reviews_count, photos_count, news_count, existing_metric[0]))
+                        UPDATE businessmetricshistory
+                        SET rating = %s, reviews_count = %s, photos_count = %s, news_count = %s
+                        WHERE id = %s
+                    """, (rating, reviews_count, photos_count, news_count, mid))
                 else:
                     cursor.execute("""
-                        INSERT INTO BusinessMetricsHistory (
-                            id, business_id, metric_date, rating, reviews_count, 
+                        INSERT INTO businessmetricshistory (
+                            id, business_id, metric_date, rating, reviews_count,
                             photos_count, news_count, source
                         )
-                        VALUES (?, ?, ?, ?, ?, ?, ?, 'parsing')
+                        VALUES (%s, %s, %s, %s, %s, %s, %s, 'parsing')
                     """, (
-                        metric_history_id, 
-                        business_id, 
-                        current_date, 
-                        rating, 
-                        reviews_count, 
-                        photos_count, 
-                        news_count
+                        metric_history_id,
+                        business_id,
+                        current_date,
+                        rating,
+                        reviews_count,
+                        photos_count,
+                        news_count,
                     ))
             except Exception as e:
                 print(f"Error saving metrics history: {e}")
@@ -1667,28 +1811,25 @@ def _process_sync_yandex_business_task(queue_dict):
             
             # The cursor and conn here refer to the ones created within the try block
             # associated with the DatabaseManager instance.
-            # The subsequent conn/cursor are for the ParseQueue update.
             try:
-                if 'cursor' in locals() and cursor and not cursor.closed: # Check if cursor is not already closed by db.close()
+                if 'cursor' in locals() and cursor and not cursor.closed:
                     cursor.close()
             except Exception:
                 pass
-                
             try:
-                if 'conn' in locals() and conn and not conn.closed: # Check if conn is not already closed by db.close()
+                if 'conn' in locals() and conn and not conn.closed:
                     conn.close()
             except Exception:
                 pass
             
-            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
             conn = get_db_connection()
             cursor = conn.cursor()
             cursor.execute("""
-                UPDATE ParseQueue 
-                SET status = 'done', 
+                UPDATE parsequeue
+                SET status = %s,
                     updated_at = CURRENT_TIMESTAMP
-                WHERE id = ?
-            """, (queue_dict["id"],))
+                WHERE id = %s
+            """, (STATUS_COMPLETED, queue_dict["id"]))
             conn.commit()
             try:
                 if cursor:
@@ -1700,7 +1841,7 @@ def _process_sync_yandex_business_task(queue_dict):
                     conn.close()
             except Exception:
                 pass
-            
+
             print(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}", flush=True)
             signal.alarm(0)  # –û—Ç–º–µ–Ω—è–µ–º —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
             
@@ -1711,11 +1852,11 @@ def _process_sync_yandex_business_task(queue_dict):
             conn = get_db_connection()
             cursor = conn.cursor()
             cursor.execute("""
-                UPDATE ParseQueue 
-                SET status = 'error', 
-                    error_message = ?,
+                UPDATE parsequeue
+                SET status = 'error',
+                    error_message = %s,
                     updated_at = CURRENT_TIMESTAMP
-                WHERE id = ?
+                WHERE id = %s
             """, (str(e), queue_dict["id"]))
             conn.commit()
             try:
@@ -1736,22 +1877,20 @@ def _process_sync_yandex_business_task(queue_dict):
             sys.stdout.flush()
             signal.alarm(0)  # –û—Ç–º–µ–Ω—è–µ–º —Ç–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
             
-            # Safely close db if it was created
             try:
                 if 'db' in locals() and db:
                     db.close()
             except:
                 pass
             
-            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—à–∏–±–∫–∏
             conn = get_db_connection()
             cursor = conn.cursor()
             cursor.execute("""
-                UPDATE ParseQueue 
-                SET status = 'error', 
-                    error_message = ?,
+                UPDATE parsequeue
+                SET status = 'error',
+                    error_message = %s,
                     updated_at = CURRENT_TIMESTAMP
-                WHERE id = ?
+                WHERE id = %s
             """, (str(e), queue_dict["id"]))
             conn.commit()
             try:
@@ -1774,11 +1913,11 @@ def _process_sync_yandex_business_task(queue_dict):
         conn = get_db_connection()
         cursor = conn.cursor()
         cursor.execute("""
-            UPDATE ParseQueue 
-            SET status = 'error', 
-                error_message = ?,
+            UPDATE parsequeue
+            SET status = 'error',
+                error_message = %s,
                 updated_at = CURRENT_TIMESTAMP
-            WHERE id = ?
+            WHERE id = %s
         """, (str(e), queue_dict["id"]))
         conn.commit()
         try:
@@ -1811,19 +1950,18 @@ def _process_cabinet_fallback_task(queue_dict):
         worker = YandexBusinessSyncWorker()
         worker.sync_account(account_id)
         
-        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –≤ ParseQueue
         conn = get_db_connection()
         cursor = conn.cursor()
         cursor.execute("""
-            UPDATE ParseQueue 
-            SET status = 'completed', 
+            UPDATE parsequeue
+            SET status = %s,
                 updated_at = CURRENT_TIMESTAMP
-            WHERE id = ?
-        """, (queue_dict["id"],))
+        WHERE id = %s
+        """, (STATUS_COMPLETED, queue_dict["id"]))
         conn.commit()
         cursor.close()
         conn.close()
-        
+
         print(f"‚úÖ Fallback –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ {business_id}", flush=True)
         
     except Exception as e:
@@ -1873,10 +2011,11 @@ def _process_sync_2gis_task(queue_dict):
             conn = get_db_connection()
             cursor = conn.cursor()
             try:
-                cursor.execute("SELECT name, address FROM Businesses WHERE id = ?", (business_id,))
+                cursor.execute("SELECT name, address FROM businesses WHERE id = %s", (business_id,))
                 row = cursor.fetchone()
                 if row:
-                    name, address = row
+                    name = row[0] if isinstance(row, (list, tuple)) else row.get("name")
+                    address = row[1] if isinstance(row, (list, tuple)) else row.get("address")
                     query = f"{name} {address}"
                     print(f"üîç –ü–æ–∏—Å–∫ –≤ 2–ì–ò–° –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}")
                     items = client.search_organization_by_text(query)
@@ -1896,19 +2035,11 @@ def _process_sync_2gis_task(queue_dict):
         cursor = conn.cursor()
         
         try:
-            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è MapParseResults
-            # –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç Yandex Maps Scraper, API 2GIS –¥–∞–µ—Ç –º–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–∏
-            
-            # Rating & Reviews
             reviews_data = org_data.get('reviews', {})
             rating = reviews_data.get('general_rating')
             reviews_count = reviews_data.get('general_review_count', 0)
-            
-            # Details
             name = org_data.get('name')
-            address = org_data.get('address_name') or org_data.get('adm_div', [{}])[0].get('name')
-            
-            # Phone / Website
+            address = org_data.get('address_name') or (org_data.get('adm_div', [{}])[0].get('name') if org_data.get('adm_div') else None)
             contacts = org_data.get('contact_groups', [])
             phone = None
             website = None
@@ -1918,80 +2049,46 @@ def _process_sync_2gis_task(queue_dict):
                         phone = contact.get('value') or contact.get('text')
                     if contact.get('type') == 'website':
                         website = contact.get('value') or contact.get('text')
-
-            # Schedule
             schedule = org_data.get('schedule')
             schedule_json = json.dumps(schedule, ensure_ascii=False) if schedule else None
-            
-            # Generating ID
-            parse_result_id = str(uuid.uuid4())
-            
-            # Map Parse Results (Profile)
-            # –í Postgres —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —Å—Ö–µ–º–∞ —É–∂–µ –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ (schema_postgres.sql)
-            # –∏ –ø–æ–ª–µ unanswered_reviews_count –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç.
-            profile_columns = [
-                ("is_verified", "INTEGER DEFAULT 0"),
-                ("phone", "TEXT"),
-                ("website", "TEXT"),
-                ("messengers", "TEXT"),
-                ("working_hours", "TEXT"),
-                ("competitors", "TEXT"),
-                ("services_count", "INTEGER DEFAULT 0"),
-                ("profile_completeness", "INTEGER DEFAULT 0"),
-            ]
-            # –î–ª—è Postgres –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ–º ALTER TABLE –Ω–∞ –ª–µ—Ç—É ‚Äî —Ç–æ–ª—å–∫–æ –º–∏–≥—Ä–∞—Ü–∏–∏.
 
-            cursor.execute("""
-                INSERT INTO MapParseResults
-                (id, business_id, url, map_type, rating, reviews_count, unanswered_reviews_count, 
-                 news_count, photos_count, report_path, 
-                 is_verified, phone, website, messengers, working_hours, competitors, services_count, profile_completeness,
-                 title, address,
-                 created_at)
-                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
-            """, (
-                parse_result_id,
-                business_id,
-                target_url or "",
-                "2gis",
-                str(rating) if rating else None,
-                int(reviews_count or 0),
-                0, # API doesn't give unanswered count easily
-                0, # No news in API
-                0, # Photos might be available but let's skip for MVP
-                None, # report path
-                0, # verification status unknown
-                phone,
-                website,
-                None, # messengers
-                schedule_json,
-                None, # competitors
-                0, # services count
-                0, # completeness
-                name,
-                address
-            ))
-            
-            # External Stats (Rating History)
+            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ cards (Postgres)
+            db_2gis = DatabaseManager()
+            try:
+                db_2gis.save_new_card_version(
+                    business_id,
+                    url=target_url or "",
+                    title=name or "",
+                    address=address or "",
+                    phone=phone,
+                    site=website,
+                    rating=float(rating) if rating is not None else None,
+                    reviews_count=int(reviews_count or 0),
+                    hours=schedule_json,
+                )
+            finally:
+                db_2gis.close()
+
             if rating is not None:
                 today = datetime.now().strftime('%Y-%m-%d')
                 stats_id = make_stats_id(business_id, ExternalSource.TWO_GIS, today)
-                
-                # Check if exists to update or insert
                 cursor.execute("""
-                    INSERT OR REPLACE INTO ExternalBusinessStats
+                    INSERT INTO externalbusinessstats
                     (id, business_id, source, date, rating, reviews_total, updated_at)
-                    VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
+                    VALUES (%s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
+                    ON CONFLICT (id) DO UPDATE SET
+                    rating = EXCLUDED.rating,
+                    reviews_total = EXCLUDED.reviews_total,
+                    updated_at = CURRENT_TIMESTAMP
                 """, (stats_id, business_id, "2gis", today, float(rating), int(reviews_count)))
                 print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ 2–ì–ò–° –æ–±–Ω–æ–≤–ª–µ–Ω–∞: –†–µ–π—Ç–∏–Ω–≥ {rating}, –û—Ç–∑—ã–≤–æ–≤ {reviews_count}")
 
-            # Update Queue Status
             cursor.execute("""
-                UPDATE ParseQueue 
-                SET status = 'done', 
+                UPDATE parsequeue
+                SET status = %s,
                     updated_at = CURRENT_TIMESTAMP
-                WHERE id = ?
-            """, (queue_dict["id"],))
+                WHERE id = %s
+            """, (STATUS_COMPLETED, queue_dict["id"]))
             
             conn.commit()
             print(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å 2–ì–ò–° —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {business_id}")
