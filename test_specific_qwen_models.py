#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Qwen –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
"""

import os
import requests
from dotenv import load_dotenv

load_dotenv()

def test_qwen_model(model_name):
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å Qwen"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –¢–µ—Å—Ç —Å SEO –ø—Ä–æ–º–ø—Ç–æ–º
    payload = {
        "inputs": "–ê–Ω–∞–ª–∏–∑ SEO –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö. –î–∞–π 3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–∑–∏—Ü–∏–π:",
        "parameters": {
            "max_length": 300,
            "temperature": 0.7,
            "do_sample": True,
            "top_p": 0.9,
            "repetition_penalty": 1.1
        }
    }
    
    try:
        print(f"ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º: {model_name}")
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{model_name}",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ {model_name} - –†–ê–ë–û–¢–ê–ï–¢!")
            if isinstance(result, list) and len(result) > 0:
                generated = result[0].get('generated_text', '')
                print(f"   –ü—Ä–∏–º–µ—Ä: {generated[:200]}...")
            return True
        elif response.status_code == 503:
            print(f"‚è≥ {model_name} - –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
            return False
        else:
            print(f"‚ùå {model_name} - –û—à–∏–±–∫–∞ {response.status_code}: {response.text[:100]}")
            return False
            
    except Exception as e:
        print(f"‚ùå {model_name} - –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
        return False

def main():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ Qwen"""
    print("üîç –¢–µ—Å—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Qwen")
    print("=" * 50)
    
    # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ Qwen, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –Ω–∞—Ö–æ–¥–∏–ª–∏
    qwen_models = [
        "Qwen/Qwen2.5-7B-Instruct",
        "Qwen/Qwen2.5-14B-Instruct", 
        "Qwen/Qwen2.5-32B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2.5-7B-Chat",
        "Qwen/Qwen2.5-14B-Chat",
        "Qwen/Qwen2.5-32B-Chat",
        "Qwen/Qwen2.5-72B-Chat",
        "Qwen/Qwen2.5-7B",
        "Qwen/Qwen2.5-14B",
        "Qwen/Qwen2.5-32B",
        "Qwen/Qwen2.5-72B",
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        "Qwen/Qwen2.5-7B-Instruct-GGUF",
        "Qwen/Qwen2.5-14B-Instruct-GGUF",
        "Qwen/Qwen2.5-32B-Instruct-GGUF",
        # –ú–æ–¥–µ–ª–∏ –æ—Ç –¥—Ä—É–≥–∏—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        "TheBloke/Qwen2.5-7B-Instruct-GGUF",
        "TheBloke/Qwen2.5-14B-Instruct-GGUF", 
        "TheBloke/Qwen2.5-32B-Instruct-GGUF",
        "TheBloke/Qwen2.5-7B-Chat-GGUF",
        "TheBloke/Qwen2.5-14B-Chat-GGUF",
        "TheBloke/Qwen2.5-32B-Chat-GGUF"
    ]
    
    print(f"üìã –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(qwen_models)} –º–æ–¥–µ–ª–µ–π Qwen...")
    print()
    
    working_models = []
    
    for model in qwen_models:
        if test_qwen_model(model):
            working_models.append(model)
        print()
    
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print("=" * 30)
    if working_models:
        print("‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏ Qwen:")
        for i, model in enumerate(working_models, 1):
            print(f"{i}. {model}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (—Å–∞–º—É—é –±—ã—Å—Ç—Ä—É—é)
        best_model = working_models[0]
        print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {best_model}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        update_model_config(best_model)
        
    else:
        print("‚ùå –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å Qwen –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("\nüí° –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ API...")
        search_qwen_models()

def search_qwen_models():
    """–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π Qwen —á–µ—Ä–µ–∑ API"""
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    headers = {
        "Authorization": f"Bearer {hf_token}"
    }
    
    search_queries = [
        "Qwen2.5-7B-Instruct",
        "Qwen2.5-14B-Instruct",
        "Qwen2.5-32B-Instruct"
    ]
    
    print("üîç –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π Qwen —á–µ—Ä–µ–∑ API...")
    
    for query in search_queries:
        try:
            print(f"\nüìù –ü–æ–∏—Å–∫: {query}")
            response = requests.get(
                "https://huggingface.co/api/models",
                headers=headers,
                params={
                    "search": query,
                    "limit": 5,
                    "sort": "downloads",
                    "direction": "-1"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                models = response.json()
                for model in models:
                    model_id = model.get('id', '')
                    downloads = model.get('downloads', 0)
                    print(f"  üìä {model_id} (–∑–∞–≥—Ä—É–∑–æ–∫: {downloads})")
                    
                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                    if test_qwen_model(model_id):
                        print(f"üéØ –ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—Ç–∞—é—â–∞—è –º–æ–¥–µ–ª—å: {model_id}")
                        update_model_config(model_id)
                        return
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")

def update_model_config(model_name):
    """–û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    print(f"\n‚öôÔ∏è –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è {model_name}...")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º model_config.py
    config_content = f'''# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π Hugging Face –¥–ª—è –ò–ò-–∞–Ω–∞–ª–∏–∑–∞

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
AVAILABLE_MODELS = {{
    "{model_name}": {{
        "name": "{model_name}",
        "description": "–ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å Qwen 2.5 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞",
        "max_length": 2048,
        "temperature": 0.6,
        "do_sample": True,
        "top_p": 0.9,
        "repetition_penalty": 1.1
    }},
    "gpt2": {{
        "name": "gpt2",
        "description": "–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞",
        "max_length": 200,
        "temperature": 0.8,
        "do_sample": True,
        "top_p": 0.9,
        "repetition_penalty": 1.1
    }},
    "facebook/bart-base": {{
        "name": "facebook/bart-base",
        "description": "–ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞",
        "max_length": 1024,
        "temperature": 0.7,
        "do_sample": True,
        "top_p": 0.9
    }}
}}

# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
PROMPTS = {{
    "seo_analysis": """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞—Ä—Ç–æ—á–∫—É –±–∏–∑–Ω–µ—Å–∞ –¥–ª—è SEO –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö. –î–∞–Ω–Ω—ã–µ: {{text}}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –î–∞–π 5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø–æ–∑–∏—Ü–∏–π –≤ –Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∞—Ö. –£—á–∏—Ç—ã–≤–∞–π —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è 2025 –≥–æ–¥–∞:

1. –ù–ê–ó–í–ê–ù–ò–ï –ö–û–ú–ü–ê–ù–ò–ò: –¢–æ–ª—å–∫–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–µ–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
2. –£–°–õ–£–ì–ò: –î–æ–±–∞–≤–ª—è–π –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é (–º–µ—Ç—Ä–æ, —Ä–∞–π–æ–Ω)
3. –ê–î–†–ï–°: –ü–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å —Å –º–µ—Ç—Ä–æ/–æ—Å—Ç–∞–Ω–æ–≤–∫–∞–º–∏
4. –ö–û–ù–¢–ï–ù–¢: –ú–∏–Ω–∏–º—É–º 10 —Ñ–æ—Ç–æ, –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
5. –ê–ö–¢–ò–í–ù–û–°–¢–¨: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ø–æ—Å—Ç—ã, –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Ç–∑—ã–≤—ã

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
1) –ù–∞–∑–≤–∞–Ω–∏–µ: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]
2) –£—Å–ª—É–≥–∏: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è] 
3) –ö–æ–Ω—Ç–∞–∫—Ç—ã: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]
4) –ö–æ–Ω—Ç–µ–Ω—Ç: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]
5) –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è]

–ù–µ —Å–æ–≤–µ—Ç—É–π Google Pay/Apple Pay - –æ–Ω–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –†–æ—Å—Å–∏–∏.""",
    "rating_analysis": "–ê–Ω–∞–ª–∏–∑ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏ –æ—Ç–∑—ã–≤–æ–≤. –î–∞–Ω–Ω—ã–µ: {text}. –û—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –¥–∞–π 2-3 —Å–æ–≤–µ—Ç–∞ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é.",
    "general_analysis": "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å–∞. –î–∞–Ω–Ω—ã–µ: {text}. –î–∞–π 3-4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é."
}}

# –¢–µ–∫—É—â–∞—è –∞–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
CURRENT_MODEL = "{model_name}"

def get_model_config(model_name=None):
    """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏"""
    if model_name is None:
        model_name = CURRENT_MODEL
    
    return AVAILABLE_MODELS.get(model_name, AVAILABLE_MODELS["{model_name}"])

def get_prompt(prompt_type="seo_analysis", text=""):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    return PROMPTS.get(prompt_type, PROMPTS["seo_analysis"]).format(text=text)
'''
    
    try:
        with open('src/model_config.py', 'w', encoding='utf-8') as f:
            f.write(config_content)
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è {model_name}")
        
        # –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º ai_analyzer.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        update_ai_analyzer(model_name)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

def update_ai_analyzer(model_name):
    """–û–±–Ω–æ–≤–ª—è–µ–º ai_analyzer.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print(f"üîÑ –û–±–Ω–æ–≤–ª—è–µ–º ai_analyzer.py –¥–ª—è {model_name}...")
    
    try:
        with open('src/ai_analyzer.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ó–∞–º–µ–Ω—è–µ–º rule-based –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏
        new_call_function = f'''def call_huggingface_analysis(text: str) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ {model_name}
    """
    try:
        from model_config import get_model_config, get_prompt
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
        model_config = get_model_config("{model_name}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = get_prompt("seo_analysis", text)
        
        # –í—ã–∑—ã–≤–∞–µ–º Hugging Face API
        import requests
        import os
        
        hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
        if not hf_token:
            return {{"error": "HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω"}}
        
        headers = {{
            "Authorization": f"Bearer {{hf_token}}",
            "Content-Type": "application/json"
        }}
        
        payload = {{
            "inputs": prompt,
            "parameters": {{
                "max_length": model_config.get("max_length", 2048),
                "temperature": model_config.get("temperature", 0.6),
                "do_sample": model_config.get("do_sample", True),
                "top_p": model_config.get("top_p", 0.9),
                "repetition_penalty": model_config.get("repetition_penalty", 1.1)
            }}
        }}
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{model_name}",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                generated_text = result[0].get('generated_text', '')
                return {{
                    "generated_text": generated_text,
                    "analysis_type": "ai_model",
                    "model_used": "{model_name}"
                }}
            else:
                return {{"error": "–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏"}}
        else:
            return {{"error": f"–û—à–∏–±–∫–∞ API {{response.status_code}}: {{response.text}}"}}
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {{e}}")
        return {{"error": str(e)}}'''
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≤ —Ñ–∞–π–ª–µ
        import re
        pattern = r'def call_huggingface_analysis\(text: str\) -> Dict\[str, Any\]:.*?return \{"error": str\(e\)\}'
        new_content = re.sub(pattern, new_call_function, content, flags=re.DOTALL)
        
        with open('src/ai_analyzer.py', 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("‚úÖ ai_analyzer.py –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ai_analyzer.py: {e}")

if __name__ == "__main__":
    main() 