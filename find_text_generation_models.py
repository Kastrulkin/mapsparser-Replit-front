#!/usr/bin/env python3
"""
–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞
"""
import requests
import os
from dotenv import load_dotenv

load_dotenv()

def find_text_generation_models():
    """–ò—â–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    
    hf_token = os.getenv('HUGGINGFACE_API_TOKEN')
    if not hf_token:
        print("‚ùå HUGGINGFACE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    headers = {
        "Authorization": f"Bearer {hf_token}",
        "Content-Type": "application/json"
    }
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    specific_models = [
        "gpt2",
        "gpt2-medium", 
        "gpt2-large",
        "gpt2-xl",
        "facebook/bart-base",
        "facebook/bart-large",
        "facebook/bart-large-cnn",
        "t5-base",
        "t5-large",
        "t5-3b",
        "microsoft/DialoGPT-medium",
        "microsoft/DialoGPT-large",
        "EleutherAI/gpt-neo-125M",
        "EleutherAI/gpt-neo-1.3B",
        "EleutherAI/gpt-neo-2.7B",
        "bigscience/bloom-560m",
        "bigscience/bloom-1b1",
        "bigscience/bloom-3b",
        "microsoft/DialoGPT-medium",
        "microsoft/DialoGPT-large",
        "microsoft/DialoGPT-xl"
    ]
    
    print("üîç –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
    print("=" * 60)
    
    found_models = []
    
    for model_id in specific_models:
        try:
            response = requests.get(
                f"https://huggingface.co/api/models/{model_id}",
                headers=headers
            )
            
            if response.status_code == 200:
                model_data = response.json()
                
                downloads = model_data.get('downloads', 0)
                likes = model_data.get('likes', 0)
                tags = model_data.get('tags', [])
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –º–æ–¥–µ–ª—å —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                if any(tag in ['text-generation', 'text2text-generation', 'causal-lm'] for tag in tags):
                    found_models.append({
                        'id': model_id,
                        'downloads': downloads,
                        'likes': likes,
                        'tags': tags,
                        'cardData': model_data.get('cardData', {})
                    })
                    
                    print(f"‚úÖ {model_id}")
                    print(f"   üì• Downloads: {downloads:,}")
                    print(f"   ‚ù§Ô∏è  Likes: {likes}")
                    print(f"   üè∑Ô∏è  Tags: {', '.join(tags[:5])}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
                    if any(tag in ['russian', 'multilingual'] for tag in tags):
                        print(f"   üåç –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
                    
            else:
                print(f"‚ùå {model_id}: {response.status_code}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {model_id}: {e}")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    found_models.sort(key=lambda x: x['downloads'], reverse=True)
    
    print("\n" + "=" * 60)
    print("üèÜ –õ–£–ß–®–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –¢–ï–ö–°–¢–û–í–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò:")
    print("=" * 60)
    
    for i, model in enumerate(found_models[:10], 1):
        print(f"\n{i}. {model['id']}")
        print(f"   üì• Downloads: {model['downloads']:,}")
        print(f"   ‚ù§Ô∏è  Likes: {model['likes']}")
        print(f"   üè∑Ô∏è  Tags: {', '.join(model['tags'][:5])}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
        card_data = model.get('cardData', {})
        if 'model-index' in card_data:
            print(f"   üìä –†–∞–∑–º–µ—Ä: {card_data['model-index'].get('results', [{}])[0].get('metrics', {}).get('parameters', 'N/A')}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è SEO –∞–Ω–∞–ª–∏–∑–∞
    print("\n" + "=" * 60)
    print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø SEO –ê–ù–ê–õ–ò–ó–ê:")
    print("=" * 60)
    
    if found_models:
        print(f"\nüéØ –î–õ–Ø –í–ê–®–ï–ì–û –î–ï–¢–ê–õ–¨–ù–û–ì–û –ü–†–û–ú–ü–¢–ê –†–ï–ö–û–ú–ï–ù–î–£–Æ:")
        
        # –ò—â–µ–º –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        russian_models = [m for m in found_models if any(tag in ['russian', 'multilingual'] for tag in m['tags'])]
        
        if russian_models:
            best_russian = russian_models[0]
            print(f"   1. üåç {best_russian['id']} - –ª—É—á—à–∞—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞")
            print(f"      - Downloads: {best_russian['downloads']:,}")
            print(f"      - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
        
        # –ò—â–µ–º –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
        large_models = [m for m in found_models if m['downloads'] > 1000000]
        if large_models:
            best_large = large_models[0]
            print(f"   2. üöÄ {best_large['id']} - –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤")
            print(f"      - Downloads: {best_large['downloads']:,}")
            print(f"      - –ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –æ–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ
        current_model = "facebook/bart-base"
        current_in_list = [m for m in found_models if current_model in m['id']]
        if current_in_list:
            current_data = current_in_list[0]
            print(f"   3. ‚öôÔ∏è  {current_data['id']} - —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å")
            print(f"      - Downloads: {current_data['downloads']:,}")
            print(f"      - –£–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –≤ —Å–∏—Å—Ç–µ–º–µ")
        
        print(f"\n‚öôÔ∏è  –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –î–õ–ò–ù–ù–´–• –ü–†–û–ú–ü–¢–û–í:")
        print(f"   - max_length: 2048-4096 (–¥–ª—è –≤–∞—à–µ–≥–æ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)")
        print(f"   - temperature: 0.3-0.5 (–¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)")
        print(f"   - do_sample: True")
        print(f"   - top_p: 0.9")
        print(f"   - repetition_penalty: 1.1 (–∏–∑–±–µ–∂–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–æ–≤)")
        
        print(f"\nüìù –í–ê–® –ü–†–û–ú–ü–¢ –û–ß–ï–ù–¨ –î–ï–¢–ê–õ–¨–ù–´–ô:")
        print(f"   ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ø–Ω–¥–µ–∫—Å –ö–∞—Ä—Ç 2025")
        print(f"   ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º")
        print(f"   ‚úÖ –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
        print(f"   ‚úÖ –§–æ–∫—É—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —Ä—ã–Ω–∫–µ")
        print(f"   ‚ö†Ô∏è  –ù—É–∂–Ω–∞ –º–æ–¥–µ–ª—å —Å –±–æ–ª—å—à–∏–º max_length")

if __name__ == "__main__":
    find_text_generation_models() 